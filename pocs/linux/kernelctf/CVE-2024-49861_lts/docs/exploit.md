# Exploit detail about CVE-2024-49861
If you want to get some base information about CVE-2024-49861, please read [vulnerability.md](./vulnerability.md) first.

## Background
eBPF, which stands for extended Berkeley Packet Filter, is a revolutionary technology developed for Linux that enables a variety of tracing and performance analysis tasks directly in the operating system's kernel. Originally designed for network packet filtering, eBPF has evolved into a versatile tool with applications far beyond its initial purpose.

One of the key features of eBPF is its ability to run sandboxed programs within the Linux kernel without having to change the kernel source code or load custom kernel modules. This allows developers to safely and efficiently extend kernel functionality for purposes such as performance monitoring, networking, and security enhancements. Programs written for eBPF are first compiled into an intermediate representation and then verified by the kernel before execution to ensure they do not hang the system or perform unsafe operations.


## Cause anaylysis
In the eBPF verifier, when the eBPF program calls the helper function provided by the kernel, if the passed parameter contains a memory pointer, the function definition corresponding to the helper will define whether to read or write the memory pointer. Here are two examples of helper functions:

```
const struct bpf_func_proto bpf_get_current_comm_proto = {
	.func		= bpf_get_current_comm,
	.gpl_only	= false,
	.ret_type	= RET_INTEGER,
	.arg1_type	= ARG_PTR_TO_UNINIT_MEM,
	.arg2_type	= ARG_CONST_SIZE,
};

static const struct bpf_func_proto bpf_strncmp_proto = {
	.func		= bpf_strncmp,
	.gpl_only	= false,
	.ret_type	= RET_INTEGER,
	.arg1_type	= ARG_PTR_TO_MEM | MEM_RDONLY,
	.arg2_type	= ARG_CONST_SIZE,
	.arg3_type	= ARG_PTR_TO_CONST_STR,
};
```
So if a helper function pointer parameter does not have MEM_UNINIT, it means that the helper function will not write the content pointed to by the pointer. eBPF verifier will not perform the corresponding check. 

In the definitions of the helper functions bpf_strtoul_proto and bpf_strtol_proto, the memory parameter args4, which is returned as the result, is not set to MEM_UNINIT:
```c
const struct bpf_func_proto bpf_strtol_proto = {
	.func		= bpf_strtol,
	.gpl_only	= false,
	.ret_type	= RET_INTEGER,
	.arg1_type	= ARG_PTR_TO_MEM | MEM_RDONLY,
	.arg2_type	= ARG_CONST_SIZE,
	.arg3_type	= ARG_ANYTHING,
	.arg4_type	= ARG_PTR_TO_LONG,
};

const struct bpf_func_proto bpf_strtoul_proto = {
	.func		= bpf_strtoul,
	.gpl_only	= false,
	.ret_type	= RET_INTEGER,
	.arg1_type	= ARG_PTR_TO_MEM | MEM_RDONLY,
	.arg2_type	= ARG_CONST_SIZE,
	.arg3_type	= ARG_ANYTHING,
	.arg4_type	= ARG_PTR_TO_LONG,
};

```
But in fact, the memory corresponding to args4 will be modified:
```
BPF_CALL_4(bpf_strtol, const char *, buf, size_t, buf_len, u64, flags,
	   long *, res)
{
	long long _res;
	int err;

	err = __bpf_strtoll(buf, buf_len, flags, &_res);
	if (err < 0)
		return err;
	if (_res != (long)_res)
		return -ERANGE;
	*res = _res;
	return err;
}

BPF_CALL_4(bpf_strtoul, const char *, buf, size_t, buf_len, u64, flags,
	   unsigned long *, res)
{
	unsigned long long _res;
	bool is_negative;
	int err;

	err = __bpf_strtoull(buf, buf_len, flags, &_res, &is_negative);
	if (err < 0)
		return err;
	if (is_negative)
		return -EINVAL;
	if (_res != (unsigned long)_res)
		return -ERANGE;
	*res = _res;
	return err;
}
```

This results in some memory being modified by these two helper functions without being checked by the verifier.

## Exploit

I used the following steps to exploit it:

1. Create an array map with value_size `0x10000` and max_entries `1`. Let's assume this is `map A`.
2. Create a ringbuf map with max_entries of `0x4000`. Let's assume this is `map B`.
3. Create an array map with value_size `0x10000` and max_entries `1`. Let's assume this is `map C`.
4. Malloc a memory of size `0x10000` and make the following modifications: 
   1.  Copy the string "4096" to the memory offset 0. 
   2.  Copy the integer `0x40000` to the memory offset 0x10.
Use `update_map_element` to modify element 0 of map A using this memory 
5. Froze map A. 
6. Run the following ebpf programï¼š

	1. Use the helper function `ringbuf_reserve` to request a memory of length 0x2800 from `map B`. We assume this is `memory A`
	2. Get the memory of element 0 from map A through the helper function `map_lookup_elem`. We assume this is `memory B`.  (`memory B` was initialized in `step 4`)
	3. Use `memory B` as the first parameter of the `strtol` function. Add 0x10 to the `memory B` and use it as the fourth parameter of the `strtol` function. Call helper function `strtol`. (After executing this step, we will modify `memory B + 0x10`. Due to the vulnerability, the verifier will not realize that the memory will be modified.)
	4. Load `memory B+0x10` and call the helper function `ringbuf_reserve` with it as the second parameter. Due to the following code, the verifier will think that the value of the second parameter is `0x10000` Because we froze `map A` in step 5 :
   ```
   static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,
			    int off, int bpf_size, enum bpf_access_type t,
			    int value_regno, bool strict_alignment_once, bool is_ldsx)
   ...
   } else if (reg->type == PTR_TO_MAP_VALUE) {
		...
		} else if (t == BPF_READ && value_regno >= 0) {
			struct bpf_map *map = reg->map_ptr;

			/* if map is read-only, track its contents as scalars */
			if (tnum_is_const(reg->var_off) &&
			    bpf_map_is_rdonly(map) &&
			    map->ops->map_direct_value_addr) {
				int map_off = off + reg->var_off.value;
				u64 val = 0;

				err = bpf_map_direct_read(map, map_off, size,
							  &val, is_ldsx);
				if (err)
					return err;

				regs[value_regno].type = SCALAR_VALUE;
				__mark_reg_known(&regs[value_regno], val);
			} else {
				mark_reg_unknown(env, regs, value_regno);
			}
		}
		...
   ```
	5. After the previous step, we get a memory, we assume it is `memory C`. Interestingly, because of the vulnerability, when executing this ebpf code, calling the `strtol` function will modify the memory of `memory B + 0x10`. But the verifier does not realize that the memory of `memory B + 0x10` has been modified. Because the above code, the verifier still thinks that it is `0x10000`. Therefore, the verifier thinks that the legal length of `memory C` is `0x10000`, but in actual execution, due to the modification of strtol, the actual length of `memory C` is `0x1000`. This means that we can bypass the verifier's check and perform memory out-of-bounds read and write to `memory C`. 
	6. Get `map C`'s ops (`struct bpf_map->ops`)and rcu(`struct bpf_map->rcu`) by using memory out-of-bounds of `memory C`. (`Map B` and `map C` are adjacent in memory) Calculate the kaslr offset through the leaked address by `map C`'s ops. Because `struct bpf_map->rcu` is a two-way pointer pointing to itself, we can get the address of `map C` through this address.
	7. Change `map C -> ops` to `&map C->value`(`struct bpf_array->value`). Change the new `map C -> ops -> map_delete_elem` to the address of the ROP gadget of `pop rbx ; ret`.
	8. Store the obtained kaslr offset into `memory A` for subsequent use.

7. Run another eBPF program:

	1. Store the ROP gadget on the stack
	2. Delete any element in map C through the helper function `map_delete_elem`. This will jmp to the ROP gadget `pop rbx ; ret`. The stack will look like follow.So when it jmp to `pop rbx ; ret`, it will finally jmp to the ROP gadget we stored on the stack.  
    
```
	RSP -> | Return address of map_delete_elem |

           |       ROP gadget we pad           |
```

## Why do I need to run two ebpf programs?
Because even though we have modified `map C -> ops -> map_delete_elem` when executing the first eBPF program, we cannot directly hijack the control flow because of the following code:

```
static int do_misc_fixups(struct bpf_verifier_env *env)
{
	...
	if (prog->jit_requested && BITS_PER_LONG == 64 &&
		    (insn->imm == BPF_FUNC_map_lookup_elem ||
		     insn->imm == BPF_FUNC_map_update_elem ||
		     insn->imm == BPF_FUNC_map_delete_elem ||
		     insn->imm == BPF_FUNC_map_push_elem   ||
		     insn->imm == BPF_FUNC_map_pop_elem    ||
		     insn->imm == BPF_FUNC_map_peek_elem   ||
		     insn->imm == BPF_FUNC_redirect_map    ||
		     insn->imm == BPF_FUNC_for_each_map_elem ||
		     insn->imm == BPF_FUNC_map_lookup_percpu_elem)) {
			aux = &env->insn_aux_data[i + delta];
			if (bpf_map_ptr_poisoned(aux))
				goto patch_call_imm;

			map_ptr = BPF_MAP_PTR(aux->map_ptr_state);
			ops = map_ptr->ops;
			...
			switch (insn->imm) {
			...
			case BPF_FUNC_map_delete_elem:
				insn->imm = BPF_CALL_IMM(ops->map_delete_elem);
				continue;
			...
```
This code means that as long as our eBPF code passes the verifier, the verifier will directly hardcode ops->map_delete_elem into the eBPF code. Therefore, only after modifying ops->map_delete_elem and running a new eBPF code, can the control flow be hijacked.
