## Requirements to trigger the vulnerability

- Kernel configuration: CONFIG_TLS and CONFIG_CRYPTO_CRYPTD
- User namespaces required: no

## Commit which introduced the vulnerability

https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8590541473188741055d27b955db0777569438e3

## Commit which fixed the vulnerability

https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=13114dc5543069f7b97991e3b79937b6da05f5b0

## Affected kernel versions

Introduced in 6.6.18 and cos-109-17800-147-54. Fixed in 6.6.20 and cos-109-17800-218-20.

## Affected component, subsystem

net/tls

## Description

When TLS submits a decryption request in async mode to the crypto API, this request is handled by cryptd and number of queued requests exceeds the maximum queue size (cryptd.cryptd_max_cpu_qlen) the API will enter "backlog mode" and crypto_aead_decrypt() will return EBUSY in tls_do_decryption():

```
static int tls_do_decryption(struct sock *sk,
                             struct scatterlist *sgin,
                             struct scatterlist *sgout,
                             char *iv_recv,
                             size_t data_len,
                             struct aead_request *aead_req,
                             struct tls_decrypt_arg *darg)
{
...

        ret = crypto_aead_decrypt(aead_req);

        if (ret == -EBUSY) {
                ret = tls_decrypt_async_wait(ctx);
                ret = ret ?: -EINPROGRESS;
        }
        if (ret == -EINPROGRESS) {
                if (darg->async)
                        return 0;

                ret = crypto_wait_req(ret, &ctx->async_wait);
        }
        darg->async = false;

        return ret;
}


tls_do_decryption() will then wait for the completion of the decryption work and if there was an error (e.g. invalid ciphertext causing EBADMSG) this error will be returned to the caller:

```
static int tls_decrypt_sg(struct sock *sk, struct iov_iter *out_iov,
                          struct scatterlist *out_sg,
                          struct tls_decrypt_arg *darg)
{
...
        err = tls_do_decryption(sk, sgin, sgout, dctx->iv,
                                data_len + prot->tail_size, aead_req, darg);
        if (err)
                goto exit_free_pages;

...

exit_free_pages:
        /* Release the pages in case iov was mapped to pages */
        for (; pages > 0; pages--)
                put_page(sg_page(&sgout[pages]));
exit_free:
        kfree(mem);
exit_free_skb:
        consume_skb(clear_skb);
        return err;
}

```

Error returned from tls_do_decryption() will cause tls_decrypt_sg() to free sgout pages and AEAD request object (mem), like it would do to handle error in the non-async mode.
The problem is that in async mode tls_decrypt_done() already freed these items, resulting in a use-after-free/double-free vulnerability.
