# Attacking Objects

- Vulnerable object: `crypto_async_request`
- Attacking object: `user_key_payload`
- Primitive: Race condition/UAF to function pointer partial overwrite 

# TL;DR

- Trigger the race condition
- Replace the vulnerable `crypto_async_request` object with a `user_key_payload` object
- Use the key `datalen` field (u16) to overwrite the lower two bytes of the `req->complete()` function pointer, making it point to a ROP-gadget
- Hijack control flow when `req->complete()` is called by the cryptd worker

# Vulnerability Analysis 

For the vulnerability analysis, refer to `vulnerability.md`.

# Exploitation

As mentioned in `vulnerability.md`, to trigger this bug we must ensure AEAD crypto requests are handled by cryptd, the Linux asynchronous crypto daemon.

When TLS is configured to operate synchronously (for example, when [TLS 1.3 is used](https://elixir.bootlin.com/linux/v6.1.148/source/net/tls/tls_sw.c#L2918)), the recvmsg path allocates a crypto request and passes it to [tls_do_decryption()](https://elixir.bootlin.com/linux/v6.1.148/source/net/tls/tls_sw.c#L251). The code assumes decryption completes synchronously and frees the request immediately after the call. However, if cryptd handles the request asynchronously, the freed object can remain on cryptd's per-CPU queue and be accessed by the crypto worker, causing a UAF.

To trigger the vulnerability, we need to register a custom cryptd algorithm. This can be done using the following function:

```c
int crypto_register_algo(char *type, char *name) {
    struct sockaddr_alg sa = {};
    int s = socket(AF_ALG, SOCK_SEQPACKET, 0); // [1]
    if (s < 0) {
        perror("socket(AF_ALG)");
        return -1;
    }
    sa.salg_family = AF_ALG;
    strcpy(sa.salg_type, type);
    strcpy(sa.salg_name, name);
    bind(s, (struct sockaddr *)&sa, sizeof(sa)); // [2]
    close(s);
    return 0;
}

// [...]

crypto_register_algo("aead", "cryptd(ccm(aes))");
```

We first create an `AF_ALG` socket `[1]`, then call `bind()` to register the algorithm by specifying its type and name. `[2]` This calls [alg_bind()](https://elixir.bootlin.com/linux/v6.1.148/source/crypto/af_alg.c#L142) in kernel space and registers the new crypto algorithm; it will be used to handle AEAD `AES-CCM` requests instead of the synchronous implementation.

>After the `cryptd(ccm(aes))` algorithm is registered, inspecting `/proc/crypto` shows that `cryptd(ccm(aes))` has a higher priority than `ccm(aes)`, therefore it
>will be selected by [crypto_find_alg()](https://elixir.bootlin.com/linux/v6.1.148/source/crypto/api.c#L577) -> ... -> [__crypto_alg_lookup()](https://elixir.bootlin.com/linux/v6.1.148/source/crypto/api.c#L54) instead of the synchronous counterpart.

An attacker can exploit the race between TLS and cryptd to overwrite the crypto request ([allocated by tls_decrypt_sg()](https://elixir.bootlin.com/linux/v6.1.148/source/net/tls/tls_sw.c#L1624) in `kmalloc-1k`) with user-controlled data and hijack control flow when the `req->complete()` function pointer is called by the crypto worker.

However, exploitation is not straightforward; several issues must be addressed. 

The first problem is that the race window is very tight, so we must act quickly or use techniques to widen it.

The second problem arises from the layout of the [crypto_async_request](https://elixir.bootlin.com/linux/v6.1.148/source/include/linux/crypto.h#L189) structure, specifically its linked list field:

```c
struct crypto_async_request {
        struct list_head list;
        crypto_completion_t complete;
        void *data;
        struct crypto_tfm *tfm;
        u32 flags;
};
```

After rescheduling, when [cryptd_queue_worker()](https://elixir.bootlin.com/linux/v6.1.148/source/crypto/cryptd.c#L162) calls [crypto_dequeue_request()](https://elixir.bootlin.com/linux/v6.1.148/source/crypto/algapi.c#L967), the object is [unlinked](https://elixir.bootlin.com/linux/v6.1.148/source/crypto/algapi.c#L980) using [list_del()](https://elixir.bootlin.com/linux/v6.1.148/source/include/linux/list.h#L146):

```c
struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue)
{
	struct list_head *request;

	// [...]

	request = queue->list.next;
	list_del(request);

	return list_entry(request, struct crypto_async_request, list);
}
```

The COS kernel is compiled with `CONFIG_BUG_ON_DATA_CORRUPTION=y`, therefore, overwriting the list with invalid pointers will trigger a kernel panic ([crypto_dequeue_request()](https://elixir.bootlin.com/linux/v6.1.148/source/crypto/algapi.c#L967) -> [list_del()](https://elixir.bootlin.com/linux/v6.1.148/source/include/linux/list.h#L146) -> [__list_del_entry()](https://elixir.bootlin.com/linux/v6.1.148/source/include/linux/list.h#L132) -> [__list_del_entry_valid()](https://elixir.bootlin.com/linux/v6.1.148/source/lib/list_debug.c#L42) -> ☠️) due to the following check:


```c
bool __list_del_entry_valid(struct list_head *entry)
{
	struct list_head *prev, *next;

	prev = entry->prev;
	next = entry->next;

	if (CHECK_DATA_CORRUPTION(next == NULL,
			"list_del corruption, %px->next is NULL\n", entry) ||
	    CHECK_DATA_CORRUPTION(prev == NULL,
			"list_del corruption, %px->prev is NULL\n", entry) ||
	    CHECK_DATA_CORRUPTION(next == LIST_POISON1,
			"list_del corruption, %px->next is LIST_POISON1 (%px)\n",
			entry, LIST_POISON1) ||
	    CHECK_DATA_CORRUPTION(prev == LIST_POISON2,
			"list_del corruption, %px->prev is LIST_POISON2 (%px)\n",
			entry, LIST_POISON2) ||
	    CHECK_DATA_CORRUPTION(prev->next != entry,
			"list_del corruption. prev->next should be %px, but was %px. (prev=%px)\n",
			entry, prev->next, prev) ||
	    CHECK_DATA_CORRUPTION(next->prev != entry,
			"list_del corruption. next->prev should be %px, but was %px. (next=%px)\n",
			entry, next->prev, next))
		return false;

	return true;

}
```

This means that, to corrupt the object without crashing the kernel, we must either preserve the original linked list or overwrite the structure with another object with a valid list at the same location.

The final problem is that we must corrupt `req->complete()`, so we need at least one controlled qword at offset 0x10 (the third qword in the attacking object).

`msg_msg` might seem ideal for this use case: its first field is a linked list, and the third qword, `m_type` - which overlaps with `req->complete()` - is user-controllable.

```c
struct msg_msg {
	struct list_head m_list;
	long m_type;
	size_t m_ts;
	struct msg_msgseg *next;
	void *security;
};
```

However, `m_type` can only be a positive value (see [this check](https://elixir.bootlin.com/linux/v6.1.148/source/ipc/msg.c#L861)), so this object is unusable.

Turns out that a `user_key_payload` structure is exactly what we need. This structure is defined as follows:

```c
struct user_key_payload {
	struct rcu_head	rcu;		/* RCU destructor */
	unsigned short	datalen;	/* length of this data */
	char		data[] __aligned(__alignof__(u64)); /* actual data */
};
```

This object is perfect for our purposes:

- It is an elastic object, so it can be allocated in the same cache as the vulnerable request object (`kmalloc-1k`).
- It is allocated using `kmalloc()` (not `kzalloc()`), so when the crypto request is overwritten, the original linked list is preserved (the key's `rcu_head` field is not initialized).
- We can store the ROP-chain in the key payload.

The problem is that the actual key payload starts at offset 0x18 (the fourth qword), while the `req->complete()` function pointer in `crypto_async_request` is the third qword.

Fortunately, we can still corrupt the lower two bytes of `req->complete()` using the key's `datalen` field (a u16).

`req->complete()` corresponds to `cryptd_aead_decrypt` (`0xffffffff8185d940` in the COS 113 kernel image). By overwriting the lower two bytes of this pointer with the key length, we can make it point to a ROP-gadget and trick the kernel into executing it when the crypto worker calls `req->complete()`.

Since the request object is allocated in `kmalloc-1k`, if we want to avoid cross-cache, the usable key payload size is limited to the range `[0x1e8, 0x3e8]` (`[0x200, 0x400]` minus the key header size of 0x18 bytes).

With a key of 581 bytes (0x0245) we can corrupt the original pointer, setting it to `0xffffffff81850245`. This address, points to the following assembly code:

```asm
gef➤  x/9i 0xffffffff81850245
   0xffffffff81850245 <shash_async_final+5>:	mov    rax,QWORD PTR [rdi+0x50]
   0xffffffff81850249 <shash_async_final+9>:	mov    rsi,QWORD PTR [rdi+0x40]
   0xffffffff8185024d <shash_async_final+13>:	lea    rdx,[rdi+0x50]
   0xffffffff81850251 <shash_async_final+17>:	mov    rax,QWORD PTR [rax+0x20]
   0xffffffff81850255 <shash_async_final+21>:	test   DWORD PTR [rax+0x2c],esi
   0xffffffff81850258 <shash_async_final+24>:	jne    0xffffffff81850266 <shash_async_final+38>
   0xffffffff8185025a <shash_async_final+26>:	mov    rax,QWORD PTR [rax-0x50]
   0xffffffff8185025e <shash_async_final+30>:	mov    rdi,rdx
   0xffffffff81850261 <shash_async_final+33>:	jmp    0xffffffff82604d20 <__x86_indirect_thunk_array> // jmp rax
```

When `req->complete()` is called, and the gadget executed, RDI points to the crypto request, now overwritten by a `user_key_payload` structure. `RDI + 0x50`
points to user-controlled data. This lets us hijack control flow and use a write-where gadget to overwrite `core_pattern`.

Finally, we trigger a segmentation fault so the binary referenced by `core_pattern` is executed, resulting in our exploit being executed by the kernel with root privileges.

# Exploit Analysis

**step(0): Initialization**

We pin the process to CPU 0, use a prefetch side-channel to bypass KASLR, and register a custom cryptd algorithm, `cryptd(ccm(aes))`. This will be used by TLS when the TLS cipher type is set to [TLS_CIPHER_AES_CCM_128](https://elixir.bootlin.com/linux/v6.1.148/source/include/uapi/linux/tls.h#L75).

**step(1): Fork, prepare the ROP chain and block on TLS recv**

We fork and, in the child process prepare the ROP-chain. Then, we call recvmsg on the TLS RX socket - it will block waiting for data. When the parent task sends data, the child will be woken up and we will have a tight window to exploit the bug.

**step(2): Trigger the vulnerability by sending a TLS packet**

From the parent task, we first saturate kmalloc-1k slabs (using [simple_xattr](https://elixir.bootlin.com/linux/v6.1.148/source/include/linux/xattr.h#L87) objects), then send a TLS packet via the TX socket.

**step(3): Exploit the race condition by reclaiming the crypto request object with a user_key_payload**

The child task wakes up, TLS allocates the crypto request, passes it to `tls_do_decryption()`, and then frees the request structure. The object is now freed but still accessible in the cryptd per-CPU queue. We must act quickly and spray `user_key_payload` objects with the `datalen` field set to `0x0245` before the context switch.

The context switch occurs and the crypto worker first unlinks the request from the queue, then calls `req->complete()`, executing the super gadget. Since the gadget involves multiple levels of indirection, we resolve them using `cpu_entry_area` to store pointers to itself (CEA is not randomized in kernel 6.1.*, so we don't need a prefetch side-channel to derive the address).

When the super gadget is executed, we jump right into the `user_key_payload` where we stored the ROP-chain, using the following stack-pivot gadget `PUSH_RDI_JMP_RBP_PTR_0X48` (where `RDI = key + 0x50` and `RBP = key`). 

In the ROP chain we use a write-where gadget to corrupt `core_pattern`. Finally, we trigger a segmentation fault so the binary referenced by `core_pattern` is executed with root privileges, allowing us to read the flag.

# Additional notes

The exploit stability is 70-80% on the remote COS 113 instance and can be improved by adjusting the prefetch side channel thresholds and the `simple_xattr`/`user_key_payload` spray.
