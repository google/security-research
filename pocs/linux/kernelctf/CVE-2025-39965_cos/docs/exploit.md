Exploit
=======

Background
----------

The XFRM module in the Linux kernel is a framework for applying transformations to IP packets. These transformations can be authentication, encryption or compression algorithms. The former two are used to implement IPsec, while the latter is used to implement the IP Payload Compression Protocol.

An XFRM state is associated with the connection between two endpoints and describes the algorithm used as well as any configuration parameters and state needed by the algorithm to transform the packets of this connection.

In IPsec terminology an XFRM state is called a Security Association (SA) and the list of all SAs is called the Security Association Database (SAD). The exploit code commonly refers to XFRM states as SAs (e.g. in variable names and comments).

In the Linux kernel on the other hand variables pointing to an XFRM state are of type `struct xfrm_state *` and usually have the variable name `x`.

Each IPsec packet has an integer header called Security Parameter Index (SPI), which is used to identify the connection and thus the SA in the recipient's SAD to be used for transforming the packet. Accordingly `xfrm_state` has a field `.id.spi` which contains the SPI of the connection.

A process with `CAP_NET_ADMIN` can create, read, update and delete XFRM states in the kernel's SA database by sending the appropriate messages to a netlink socket.

Vulnerability
-------------

To quickly retrieve `xfrm_state` objects the kernel maintains multiple hash tables to those objects. One of these hash tables is `net->xfrm.state_byspi` that indexes the SAs by the combination of SPI, destination address, IPsec protocol and IP family.

The function `xfrm_alloc_spi` generates a random unused SPI in the range `low`…`high` and writes it to the field `.id.spi` of an `xfrm_state` object. It also inserts the state into the hash table `net->xfrm.state_byspi`.

Commit [94f39804d8](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=94f39804d891) ("xfrm: Duplicate SPI Handling) introduced the vulnerability by inadvertently allowing `xfrm_alloc_spi` to generate an SPI with the value of 0 (note that this function contains a bug that is unrelated to this exloit: it reuses the iteration variable `h` for the hash):

```C
int xfrm_alloc_spi(struct xfrm_state *x, u32 low, u32 high,
		           struct netlink_ext_ack *extack)
{
	struct net *net = xs_net(x);
	unsigned int h;
	struct xfrm_state *x0;
    // ...
    u32 range = high - low + 1;
	__be32 newspi = 0;

    // ...

	for (h = 0; h < range; h++) {
		u32 spi = (low == high) ? low : get_random_u32_inclusive(low, high);
		newspi = htonl(spi);

		// ...

		x0 = xfrm_state_lookup_spi_proto(net, newspi, x->id.proto);
		if (!x0) {
			x->id.spi = newspi;
			h = xfrm_spi_hash(net, &x->id.daddr, newspi, x->id.proto, x->props.family);
			XFRM_STATE_INSERT(byspi, &x->byspi, net->xfrm.state_byspi + h, x->xso.type);

            // ...

            goto unlock;
		}

        // ...

		if (low == high)
			break;
	}

    // ...

unlock:

    // ...
}
```

The kernel uses the special value 0 (a reserved SPI according to the IPsec spec) to indicate that an `xfrm_state` does not have an SPI. Usually when a new `xfrm_state` is created it only gets added to `net->xfrm.state_byspi` if its SPI is not zero:

```C
static void __xfrm_state_insert(struct xfrm_state *x)
{
	struct net *net = xs_net(x);
	unsigned int h;

    // ...

	if (x->id.spi) {
		h = xfrm_spi_hash(net, &x->id.daddr, x->id.spi, x->id.proto,
				          x->props.family);

		XFRM_STATE_INSERT(byspi, &x->byspi, net->xfrm.state_byspi + h,
				          x->xso.type);
	}

    // ...
}
```

Accordingly entries are only removed from `net->xfrm.state_byspi` if their SPI is not zero:

```C
int __xfrm_state_delete(struct xfrm_state *x)
{
	struct net *net = xs_net(x);
	int err = -ESRCH;

	if (x->km.state != XFRM_STATE_DEAD) {

        // ...

		if (x->id.spi)
			hlist_del_rcu(&x->byspi);

        // ...

		xfrm_state_put(x);
		err = 0;
	}

	return err;
}
```

Therefore, if an `xfrm_state` gets assigned an SPI of zero by `xfrm_alloc_spi` and is later deleted, a pointer to the freed object remains in the hash table.

High-level exploit strategy
---------------------------

* Free a `xfrm_state` object, that is still accessible via the `net->xfrm.state_byspi` hash table (use-after-free).
* Reclaim it as a `msg_msg` (cross-cache spray).
* Free and recreate a neighboring `xfrm_state` in the hash table. This repairs the `hlist` and leaks a pointer to the neighboring `xfrm_state`.
* Make the field `.coaddr` of the UAF `xfrm_state` point to the `.coaddr` of the neighboring `xfrm_state`. This step utilizes an ordinary (i.e. same-cache) heap spray.
* Use the setup of the last step as an arbitrary read/write primitive to leak the KASLR offset and elevate privileges in a data-only way.
* Get the flag!

Exploitation steps
------------------

### The parent process

The cross-cache spray (steps 4 and 6) has a probability of 5/21 to hit a slot that makes the rest of the exploit steps possible. To increase the reliability of the exploit the main function spawns a child process that executes the exploitation steps below. If the exploitation attempt fails the child's net namespace and every XFRM state the child created are deleted on the child's exit. The parent then spawns another child process until one attempt succeeds.

### Step 1: Create a net namespace

Every message to a netlink socket of type `NETLINK_XFRM` requires `CAP_NET_ADMIN`. First we create a new user namespace and a net namespace in which we have this capability.

### Step 2: Pin the CPU

The cross-cache spray requires us to fill the per-cpu list `kmem_cache.cpu_slab[i].partial` of the `xfrm_state` kmem_cache. To execute the cross-cache spray reliably, every `xfrm_state` we delete needs to be freed from the same CPU core. The freeing is done from a kworker in `xfrm_state_gc_task`, but if we pin our process (which causes `xfrm_state_gc_task` to run by deleting the `xfrm_state`) to a CPU core then it is very likely that `xfrm_state_gc_task` will be executed on the same core.

### Step 3: Create a netlink socket

To interact with the XFRM state database in the kernel we need to open a netlink socket of type `NETLINK_XFRM`. The same attack should also be possible by using the deprecated [`PF_KEY`](https://elixir.bootlin.com/linux/v6.17.5/source/net/key/af_key.c) interface instead, which will trigger the same functions in [`xfrm_state.c`](https://elixir.bootlin.com/linux/v6.17.5/source/net/xfrm/xfrm_state.c) that the netlink socket does.

### Step 4: Prepare the cross-cache spray

`xfrm_state` objects are allocated from a dedicated `kmem_cache`, meaning that we need to perform a cross-cache spray to reclaim a freed `xfrm_state` as a different object type.

For an introduction to cross-cache sprays and details about the SLUB allocator see [Game of Cross Cache](https://i.blackhat.com/Asia-24/Presentations/Asia-24-Wu-Game-of-Cross-Cache.pdf). Note that my exploit uses slightly simpler steps for the cross-cache spray than those shown in that presentation, because it assumes that the `xfrm_state` cache is empty at the start of the exploit.

We allocate 10 (2*`kmem_cache.cpu_partial_slabs`) slabs full of `xfrm_state` objects so that we can later free them in step 6. These are created by sending a `XFRM_MSG_NEWAE` message to the netlink socket. We then create the `xfrm_state` that we trigger the vulnerability on by sending `XFRM_MSG_ALLOCSPI` with parameters `min` and `max` set to 0, which will cause `xfrm_alloc_spi` to generate a "random" SPI of 0. After allocating this `xfrm_state`, which we will call `vuln_sa` from now on, we allocate 21 (`objs_per_slab`) more `xfrm_state` objects to fill the active slab (`kmem_cache.cpu_slab[i].slab`).

Note that we cannot know which of the 21 slots in the last slab contains `vuln_sa`, since kernelCTF instances are built with `CONFIG_SLAB_FREELIST_RANDOM`, which randomizes the order in which slots within a slab are used.

To make step 6 work correctly we need to have some slabs on the per-node partial list (`kmem_cache.node[i]->partial`). To achieve this we free one `xfrm_state` per slab in the first 6 (`kmem_cache.cpu_partial_slabs`+1) slabs. This will cause the slabs to get added to the per-cpu list `kmem_cache.cpu_slab[i].partial`. Because this list can contain at most `kmem_cache.cpu_partial_slabs` slabs adding the sixth slab will cause the other five to be flushed from the per-cpu list to the per-node list.

### Step 5: Free `vuln_sa`

We send another `XFRM_MSG_NEWAE` message with the same fields as `vuln_sa` except for the SPI. For the SPI of the new `xfrm_state`, which we will call `prev_sa`, we choose `(1<<26) | (1<<16)`, because it hashes to the same value as 0 in `__xfrm_spi_hash` (assuming `hmask` is smaller than `1<<26`):

```C
static inline unsigned int
__xfrm_spi_hash(const xfrm_address_t *daddr, __be32 spi, u8 proto,
		        unsigned short family, unsigned int hmask)
{
	unsigned int h = (__force u32)spi ^ proto;
	switch (family) {
	case AF_INET:
		h ^= __xfrm4_addr_hash(daddr);
		break;
	case AF_INET6:
		h ^= __xfrm6_addr_hash(daddr);
		break;
	}
	return (h ^ (h >> 10) ^ (h >> 20)) & hmask;
}
```

Looking at `xfrm_state_add` we see that this has multiple effects:

```C
int xfrm_state_add(struct xfrm_state *x)
{
	struct net *net = xs_net(x);
	struct xfrm_state *x1, *to_put;
	int family;
	// ...
	int use_spi = xfrm_id_proto_match(x->id.proto, IPSEC_PROTO_ANY);

	family = x->props.family;

	// ...

	x1 = __xfrm_state_locate(x, use_spi, family);

	// ...

	if (use_spi && !x1)
		x1 = __find_acq_core(net, &x->mark, family, x->props.mode,
				             x->props.reqid, x->if_id, x->pcpu_num, x->id.proto,
				             &x->id.daddr, &x->props.saddr, 0); // (1)

	__xfrm_state_bump_genids(x);
	__xfrm_state_insert(x); // (2)

	// ...

	if (x1) {
		xfrm_state_delete(x1); // (3)
		xfrm_state_put(x1); // (4)
	}

	// ...
}
```

`prev_sa` will be inserted into `net->xfrm.state_byspi` and the other hash tables (2). It will be added to the same hash bucket in `net->xfrm.state_byspi` that `vuln_sa` is in, because of the way we chose its SPI and because it has the same values for `daddr` and `proto`.

Because `__find_acq_core` returns `vuln_sa` here, it will be removed from the database (3). Note that it still remains in `net->xfrm.state_byspi` because of the bug.

`vuln_sa` will be freed, because we drop its last reference (4).

The hash bucket, which `vuln_sa` and `prev_sa` are in, now looks like this:


```
                ┌──────────────┐              ┌──────────────┐
		        │   prev_sa    │              │   vuln_sa    │
	     	    ├──────────────┤              ├──────────────┤
     		    │       ⋮      │              │       ⋮       │
hlist_head ───► │   .byspi     │ ◄──► ⋯ ◄──► │   .byspi     │ ◄──► ⋯
                │       ⋮      │              │       ⋮       │
                └──────────────┘              └──────────────┘
```

As the hash bucket is implemented as a doubly linked list the arrows represent the `.pprev` and `.next` pointers of the structs `hlist_head` and `hlist_node`.

### Step 6: Execute the cross-cache spray

To transfer the slab containing `vuln_sa` to another `kmem_cache`, we first need to free all objects within it. These other objects are the `xfrm_states` that were allocated after `vuln_sa`, except for the most recent one, which ended up in the active slab.
The now empty slab will still remain in the list `kmem_cache.cpu_slab[i].partial` of the `xfrm_state` cache. The list currently also contains the sixth slab added in step 4, because the slab that causes the other slabs to be flushed to the per-node list will itself not be flushed.
To free the slab back to the page allocator, we need to free an object in 4 (`kmem_cache.cpu_partial_slabs`-1) more slabs.

When adding the last of those slabs to the per-cpu list the other 5 slabs in the list will again be flushed. The partially filled slabs will be added to the per-node list. The fully empty slab (containing `vuln_sa`) will instead be returned to the page allocator.

Had we not already flushed some slabs to the per-node list in step 4 the per-node list would only contain 4 slabs before the fully empty slab gets flushed. As this is less than `min_partial.min_partial` (5) this would have caused the fully empty slab to be added to the per-node list instead of being returned to the page allocator (c.f. [`__put_partials`](https://elixir.bootlin.com/linux/v6.17-rc7/source/mm/slub.c#L3187)).

Slabs in the `xfrm_state` cache are 16 kB in size, so they are returned as order-2 pages. The most reliable way to reclaim this page for sprayed objects is to allocate the objects from a cache that uses the same page order. The general purpose cache that uses order-2 pages is `kmalloc-cg-1k`. Note that is valid for kernelCTF instances, but depends on the number of CPU cores the machine has. For example on a single-core VM we would need to target `kmalloc-cg-2k` instead. To allocate from `kmalloc-cg-1k` we need to spray objects of size 513-1024 bytes.

The slots in the `xfrm_state` cache are 768 bytes in size so the sprayed objects that are allocated into slots of size 1024 bytes will usually not be aligned to the freed `vuln_sa`. The set of possible offsets between the address of `vuln_sa` and the address of the slot that contains the first bytes of `vuln_sa` is:

$$ \{768 i \mod 1024 \; | \; i ∈ \{0, 1, 2, ..., 20\}\} = \{0, 256, 512, 768\} $$

The next exploitation steps require us to overwrite multiple fields of `vuln_sa`, the first being `.byspi` (offset 40) and the last being `.coaddr` (offset 392), but on the other hand we must not overwrite `.mtimer` (offset 560), because `xfrm_state_find` crashes if `.mtimer` does not point to a valid `struct hrtimer`.

We can achieve this by correctly guessing the offset from the sprayed object to `vuln_sa` and chosing the size of the sprayed object such that it only partially overlaps `vuln_sa`. The exploit assumes that the offset is 256 and sprays `msg_msg` objects of size 656 bytes (this equals 256+392+8 bytes, with 8 being the size of the pointer `.coaddr`). The sprayed message contains only null bytes, because zero is a valid value for most fields of `xfrm_state` and this also simplifies step 8. Out of the 21 slots that `vuln_sa` can be in 5 will result in our guess being correct.

Instead of guessing the offset we could have also completed this step in a single try, by spawning 21 child processes with a new net namespace each and delete a zero-SPI `xfrm_state` in each of those to fill the whole slab with vulnerable objects instead of creating a single `vuln_sa`.

### Step 7: Free and recreate `prev_sa`

The current state of the hash bucket we looked at earlier is this:

```
                ┌──────────────┐      ┌──────────────┐
		        │   prev_sa    │      │   vuln_sa    │
	     	    ├──────────────┤      ├──────────────┤
     		    │       ⋮      │      │       ⋮       │
hlist_head ───► │   .byspi     │ ───► │   .byspi     │
                │       ⋮      │      │       ⋮       │
                └──────────────┘      └──────────────┘
```

`prev_sa` is named after its position as the entry preceding `vuln_sa` in this list.

If the list contained any SAs between `prev_sa` and `vuln_sa` they must have been added after `vuln_sa` and thus have been freed at the beginning of step 6. The `byspi.next` and `byspi.pprev` pointers of `vuln_sa` have been overwritten by null bytes at the end of step 6.

We then delete `prev_sa` by sending `XFRM_MSG_DELSA` and recreate it again by sending `XFRM_MSG_ADDSA` with the same values as before. This will repair the `byspi.pprev` pointer of `vuln_sa`, i.e. make it point to the `byspi.next` pointer of `prev_sa` again:

```C
static inline void __hlist_del(struct hlist_node *n)
{
	struct hlist_node *next = n->next;
	struct hlist_node **pprev = n->pprev;

	WRITE_ONCE(*pprev, next);
	if (next)
		WRITE_ONCE(next->pprev, pprev);
}
```

The `byspi.next` pointer of `vuln_sa` staying a null pointer is fine, because that is a valid value in `hlist_node` signaling the end of the list (as opposed to `list_head` where a null pointer would be invalid).

### Step 8: Check sprayed messages

Repairing the `byspi.pprev` pointer allows us to gain three vital bits of information:

* which of our sprayed messages overlaps the beginning of `vuln_sa`
* whether the guessed offset in step 6 was correct
* the address of `prev_sa`

We peek at every message by using the `msgrcv` syscall with the `MSG_COPY` flag. If any message contains non-null bytes that message must overlap the field `.byspi.pprev` of `vuln_sa`.
If the non-null bytes are at the expected offset in the message, then we guessed the offset in step 6 correctly.
By subtracting the offset of the `byspi.next` in `xfrm_struct` from the value of the leaked `byspi.pprev` pointer we get the address of `prev_sa`.

If none of the messages contain non-null bytes or the pointer is not at the expected offset, the child process exits and the parent process starts a new one after the net namespace of the child with all the allocated `xfrm_state`s has been deleted.

### Step 9: Setup the read/write primitive

With the information from step 8 we can perform a heap spray to change multiple fields in `vuln_sa` to setup our arbitrary read/write primitive.
We free the `msg_msg` struct that overlaps `vuln_sa` by receiving the message and then spray new `msg_msg` objects that overwrite the following fields in `vuln_sa`:

* `.refcnt`, `.props.family`, `.id.spi`, `.id.proto`, `.id.daddr`, because those values are checked when looking up an entry in `net->xfrm.state_byspi`
* `.km.state`, because its value is checked in `xfrm_update`
* `.byspi.pprev`, to keep the newly repaired `hlist` intact
* `.coaddr` to make it point to the `.coaddr` field of `prev_sa`

Making `.coaddr` point to another `.coaddr` pointer instead of an `struct xfrm_address_t` is the central corruption that turns the UAF into a powerful read/write primitive. By targeting `prev_sa.coaddr` instead of directly writing the value of the target address to `vuln_sa.coaddr` the read/write primitive becomes reusable without the need to repeat the exploitation steps above.

Sending `XFRM_MSG_GETSA` to the netlink socket allows us to read 16 bytes at the address pointed to by `.coaddr`, while sending `XFRM_MSG_UPDATESA` allows us to write those 16 bytes.
To read at an arbitrary address or write an arbitrary value to an arbitrary address we use `vuln_sa` to write the target address to `prev_sa.coaddr` and then use `prev_sa` to read/write the value we are interested in. To write fewer bytes we can first read 16 bytes at the target address and then write the bytes back with only the bytes changed that we intended to.

The setup for the read/write primitive looks like this:

```
                ┌──────────────┐      ┌──────────────┐
		        │   prev_sa    │      │   vuln_sa    │
	     	    ├──────────────┤      ├──────────────┤
     		    │       ⋮      │      │       ⋮       │
hlist_head ───► │   .byspi     │ ◄──► │   .byspi     │
                │       ⋮      │      │       ⋮       │
r/w target ◄─── │   .coaddr    │ ◄─── │   .coaddr    │
                │       ⋮      │      │       ⋮       │
                └──────────────┘      └──────────────┘
```

### Step 10: Leak the ASLR offset

We can easily use this primitive to leak the KASLR offset by reading the field `prev_sa.type` which will contain an pointer to `ipcomp_type`, because we chose IPComp as the protocol when creating `prev_sa`. `ipcomp_type` is at a fixed offset from the kernel image base.

### Step 11: Find the task struct

From the kernel image base we can calculate the address of `init_task` and use the read primitive to walk the list of all `task_struct`s until we find our own process' `task_struct` by matching on the `.comm` field.

### Step 12: Escalate privileges

We use the write primitive to overwrite the pointers `.real_cred`, `.cred`, `.fs` and `.nsproxy` to escalate to root credentials and escape from the nsjail. Using the new privileges we can finally read the flag.
