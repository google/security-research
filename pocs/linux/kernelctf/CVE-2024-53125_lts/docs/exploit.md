# Exploit detail about CVE-2024-53125
If you want to get some base information about CVE-2024-53125, please read [vulnerability.md](./vulnerability.md) first.

## Background
eBPF, which stands for extended Berkeley Packet Filter, is a revolutionary technology developed for Linux that enables a variety of tracing and performance analysis tasks directly in the operating system's kernel. Originally designed for network packet filtering, eBPF has evolved into a versatile tool with applications far beyond its initial purpose.

One of the key features of eBPF is its ability to run sandboxed programs within the Linux kernel without having to change the kernel source code or load custom kernel modules. This allows developers to safely and efficiently extend kernel functionality for purposes such as performance monitoring, networking, and security enhancements. Programs written for eBPF are first compiled into an intermediate representation and then verified by the kernel before execution to ensure they do not hang the system or perform unsafe operations.


## Cause anaylysis
From this [commit](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/kernel/bpf/verifier.c?id=75748837b7e56919679e02163f45d5818c644d03), the eBPF verifier introduce the id of `SCALAR_VALUE`. The purpose of introducing id is to propagate scalar ranges through register assignments. 

`subreg_ref` is used to track subreg. This is the comment about `subreg_def` in the code `struct bpf_reg_state`:

```
	/* Tracks subreg definition. The stored value is the insn_idx of the
	 * writing insn. This is safe because subreg_def is used before any insn
	 * patching which only happens after main verification finished.
	 */
```
In the eBPF verifier, when an instruction is considered to operate only on a 32-bit register, the target register will be set to `subreg_def`. This part of the code is mainly implemented in `__check_reg_arg`:

```
static int __check_reg_arg(struct bpf_verifier_env *env, struct bpf_reg_state *regs, u32 regno,
			   enum reg_arg_type t)
{
	...

	reg = &regs[regno];
	rw64 = is_reg64(env, insn, regno, reg, t);
	if (t == SRC_OP) {
		...
		if (rw64)
			mark_insn_zext(env, reg); //Here use subreg_def
		...
	} else {
		/* check whether register used as dest operand can be written to */
		if (regno == BPF_REG_FP) {
			verbose(env, "frame pointer is read only\n");
			return -EACCES;
		}
		reg->live |= REG_LIVE_WRITTEN;
		reg->subreg_def = rw64 ? DEF_NOT_SUBREG : env->insn_idx + 1; //Here set subreg_def
		if (t == DST_OP)
			mark_reg_unknown(env, regs, regno);
	}
	return 0;
}
```
And `subreg_def` is used in function `mark_insn_zext` :
```
static void mark_insn_zext(struct bpf_verifier_env *env,
			   struct bpf_reg_state *reg)
{
	s32 def_idx = reg->subreg_def;

	if (def_idx == DEF_NOT_SUBREG)
		return;

	env->insn_aux_data[def_idx - 1].zext_dst = true;
	/* The dst will be zero extended, so won't be sub-register anymore. */
	reg->subreg_def = DEF_NOT_SUBREG;
}
```
`mark_insn_zext` is used to mark such instructions: if the instruction is a 64-bit instruction and the source register has been previously set with `subreg_ref` (which means that the source register has been used as a 32-bit destination register), then mark the instruction specified by `subreg_ref` with `zext_dst = true`.

In the function `opt_subreg_zext_lo32_rnd_hi32`, `zext_dst` is used to determine whether to add a 0-extension instruction after the instruction:
```
static int opt_subreg_zext_lo32_rnd_hi32(struct bpf_verifier_env *env,
					 const union bpf_attr *attr)
{
	...
	rnd_hi32 = attr->prog_flags & BPF_F_TEST_RND_HI32;
	zext_patch[1] = BPF_ZEXT_REG(0);
	rnd_hi32_patch[1] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_AX, 0);
	rnd_hi32_patch[2] = BPF_ALU64_IMM(BPF_LSH, BPF_REG_AX, 32);
	rnd_hi32_patch[3] = BPF_ALU64_REG(BPF_OR, 0, BPF_REG_AX);
	for (i = 0; i < len; i++) {
		...
		if (!aux[adj_idx].zext_dst) {
			u8 code, class;
			u32 imm_rnd;

			if (!rnd_hi32)
				continue;

			...
			imm_rnd = get_random_u32();
			rnd_hi32_patch[0] = insn;
			rnd_hi32_patch[1].imm = imm_rnd;
			rnd_hi32_patch[3].dst_reg = load_reg;
			patch = rnd_hi32_patch;
			patch_len = 4;
			goto apply_patch_buffer;
		}
		...
		zext_patch[0] = insn;
		zext_patch[1].dst_reg = load_reg;
		zext_patch[1].src_reg = load_reg;
		patch = zext_patch;
		patch_len = 2;
apply_patch_buffer:
		new_prog = bpf_patch_insn_data(env, adj_idx, patch, patch_len);
		...
	}

	return 0;
}
```
When `zext_dst` is not set and `prog_flags` has `BPF_F_TEST_RND_HI32`, the verifier will add an instruction after the corresponding instruction to set the high 32 bits of the instruction's destination register to a random number.

Based on the above code, let's consider the following eBPF code:
```
		//We assume that BPF_REG_7 is a pointer to a map value.
1		BPF_LDX_MEM(BPF_W, BPF_REG_1, BPF_REG_7, 0),//Load BPF_REG_1 from map value. Here will finally set BPF_REG_1 -> subreg_def
        ...
2       BPF_MOV32_REG(BPF_REG_2, BPF_REG_1),      //set BPF_REG_2->id. And here will generate the random hi32.
3       BPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0x10, Y), //Trigger the vulnerability. 'find_equal_scalars' function will set BPF_REG_2 -> subreg_def = BPF_REG_1 -> subreg_def
		...
        BPF_MOV64_IMM(BPF_REG_0, 0),
        BPF_EXIT_INSN(),
Y:
4		BPF_ALU64_IMM(BPF_RSH, BPF_REG_2, 0x3f),
        ...
```

In instruction 1, the verifier will mark `BPF_REG_1->subreg_ref` because this is a 32-bit read instruction. In instruction 2, the verifier will set `BPF_REG_2` and `BPF_REG_1` to the same id in the function `check_alu_op`. Also, because this is a 32-bit mov instruction, instruction 2 will also set `BPF_REG_2->subreg_ref`.

Instruction 3, the function `find_equal_scalars` will eventually be triggered. Because `find_equal_scalars` will directly call `copy_register_state` to completely copy `BPF_REG_1` to `BPF_REG_2`, the subreg_def of `BPF_REG_2` will point to instruction 1, just like BPF_REG_1. This means that in instruction 4, the function `mark_insn_zext` will be called to mark `zext_dst = true` of instruction 1. Instruction 2 will eventually be extended by two instructions in the function `opt_subreg_zext_lo32_rnd_hi32` to randomize the upper 32 bits of `BPF_REG_2`. So when it reaches instruction 4, the verifier thinks that the value of `BPF_REG_2` is `0x10`, but in fact `BPF_REG_2` will be `0x10|(random_num<<32)`.


## Exploit

I used the following steps to exploit it:

1. Create an array map with value_size `0x10000` and max_entries `1`. Let's assume this is `map A`.
2. Create a ringbuf map with max_entries of `0x4000`. Let's assume this is `map B`.
3. Create an array map with value_size `0x10000` and max_entries `1`. Let's assume this is `map C`.
4. Malloc a memory of size `0x10000` and make the following modifications:  
   1.  Copy the integer `0x10` to the memory offset 0.

5. Use `update_map_element` to modify element 0 of map A using this memory 

6. Run the following ebpf programï¼š

	1. Get the memory of element 0 from `map A` through the helper function `map_lookup_elem`. We assume this is `memory A`.  (`memory A` was initialized in `step 4`)
	2. Use the helper function `ringbuf_reserve` to request a memory of length 0x2800 from `map B`. We assume this is `memory B`
	3. Load `memory A + 0` to register `BPF_REG_1`.
	4. Trigger the vulnerability through the POC in `Cause anaylysis`. After triggering the vulnerability, the verifier thinks that `BPF_REG_2` is `0x10`, but in fact `BPF_REG_2` is `0x10|(random_num<<32)`
   
    5. Do the following operations:

		1. `BPF_REG_2` = `BPF_REG_2 >> 0x3f`
		2. `BPF_REG_2` = `BPF_REG_2 << 0x10`
		3. `BPF_REG_2` = `BPF_REG_2 xor 0x10010`
	
		After above operations, if the highest bit of the random number is 1, the actual value of BPF_REG_2 will be 0x10, and the verifier will think that the actual value of BPF_REG_2 is 0x10010
	
	6. Call the `ringbuf_reserve` helper function for map B with `BPF_REG_2` as the second parameter. After calling this function, if the highest bit of the random number is 1, we will actually request a ringbuf memory of size `0x10` from map B. However, the verifier will think that we requested a ringbuf memory of size 0x10010. The verifier will save the memory size in `mem_size` of `BPF_REG_0` for later checking of memory access in the code. We assume that the memory requested here is `memory C`. Now we can perform out-of-bounds reads and writes to `memory C` (because the size we actually requested is smaller than the size that the verifier thinks, thus bypassing the check in the verifier).
	7. Get `map C`'s ops (`struct bpf_map->ops`)and rcu(`struct bpf_map->rcu`) by using memory out-of-bounds read of `memory C`. (`Map B` and `map C` are adjacent in memory) Calculate the kaslr offset through the leaked address by `map C`'s ops. Because `struct bpf_map->rcu` is a two-way pointer pointing to itself, we can get the address of `map C` through this address.
	8.  Change `map C -> ops` to `&map C->value`(`struct bpf_array->value`). Change the new `map C -> ops -> map_delete_elem` to the address of the ROP gadget of `pop rbx ; ret`.
	9.  Store the obtained kaslr offset into `memory A` for subsequent use.

7. Run another eBPF program:

	1. Store the ROP gadget on the stack
	2. Delete any element in map C through the helper function `map_delete_elem`.  This will jmp to the ROP gadget `pop rbx ; ret`. The stack will look like as follow. So when it jmp to `pop rbx ; ret`, it will finally jmp to the ROP gadget we stored on the stack.  

```
	RSP -> | Return address of map_delete_elem |
           |       ROP gadget we pad           |
```


## Why do I need to run two ebpf programs?
Because even though we have modified `map C -> ops -> map_delete_elem` when executing the first eBPF program, we cannot directly hijack the control flow because of the following code:

```
static int do_misc_fixups(struct bpf_verifier_env *env)
{
	...
	if (prog->jit_requested && BITS_PER_LONG == 64 &&
		    (insn->imm == BPF_FUNC_map_lookup_elem ||
		     insn->imm == BPF_FUNC_map_update_elem ||
		     insn->imm == BPF_FUNC_map_delete_elem ||
		     insn->imm == BPF_FUNC_map_push_elem   ||
		     insn->imm == BPF_FUNC_map_pop_elem    ||
		     insn->imm == BPF_FUNC_map_peek_elem   ||
		     insn->imm == BPF_FUNC_redirect_map    ||
		     insn->imm == BPF_FUNC_for_each_map_elem ||
		     insn->imm == BPF_FUNC_map_lookup_percpu_elem)) {
			aux = &env->insn_aux_data[i + delta];
			if (bpf_map_ptr_poisoned(aux))
				goto patch_call_imm;

			map_ptr = BPF_MAP_PTR(aux->map_ptr_state);
			ops = map_ptr->ops;
			...
			switch (insn->imm) {
			...
			case BPF_FUNC_map_delete_elem:
				insn->imm = BPF_CALL_IMM(ops->map_delete_elem);
				continue;
			...
```
This code means that as long as our eBPF code passes the verifier, the verifier will directly hardcode `ops->map_delete_elem` into the eBPF code. Therefore, only after modifying ops->map_delete_elem and running a new eBPF code, can the control flow be hijacked.
