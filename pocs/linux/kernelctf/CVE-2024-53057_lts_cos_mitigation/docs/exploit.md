# CVE-2024-53057
## Overview

The vulnerability allows a use-after-free on a `drr_class` during `drr_dequeue()`. Due to the mitigations, we always replace a freed `drr_class` with another `drr_class`. This is done twice while building a vulnerable qdisc hierarchy. Sending a packet through this hierarchy creates a dangling `rb_node` pointer to the `privdata[]` field of a TBF `Qdisc`. The TBF `Qdisc` is replaced with a netem `Qdisc`, creating a type confusion between `tbf_sched_data` and `netem_sched_data` in `privdata[]`. This lets us read and modify an `rb_node`, granting limited read and write primitives. From there, arbitrary read and write primitives are constructed and used for LPE and container escape by modifying the exploit's `task_struct`.

## Changes from CVE-2024-45016 Exploit

This exploit is essentially the same as my [`CVE-2024-45016` exploit](https://github.com/google/security-research/tree/master/pocs/linux/kernelctf/CVE-2024-45016_lts_cos_mitigation). `trigger_vuln()` is updated to use the new vulnerability. This vulnerability can only be triggered on one qdisc per net namespace, so two net namespaces are created for each of the vulnerable hierarchies we need to build and the exploit is updated to switch between these namespaces as needed.

## Traffic Control Background

The traffic control subsystem under `net/sched` in the Linux kernel tree is responsible for scheduling, shaping, policing and dropping network traffic. When a packet is sent over a network interface using `sendmsg()` and similar syscalls, it will eventually be enqueued at that interface's root qdisc (queueing discipline) in `dev_queue_xmit()`. Afterwards `qdisc_run()` is called to dequeue packets from the qdisc according to the qdisc's scheduling algorithm. There are many different qdiscs available, all of which are represented by the same `Qdisc` object. The `privdata[]` field of this object stores data specific to the qdisc type.

Many qdiscs have a child qdisc from which they enqueue and dequeue the packets, resulting in a hierarchy of qdiscs. Some classful qdiscs like DRR or HFSC enqueue each packet to one of a set of user-managed classes, each of which has a child qdisc. These qdiscs allocate an object for each class created (`drr_class` for DRR and `hfsc_class` for HFSC). When a packet is enqueued to one of these classes, it is added to a list of active classes which will be accessed during dequeue.

The `q.qlen` field of a class's child qdisc counts the number of packets enqueued and determines when to remove the class from the active list. This happens in `qdisc_tree_remove_backlog()` by calling the `qlen_notify` method of the qdisc the class belongs to when the child qdisc's `q.qlen` is changed to zero. A bug which causes an inaccurate `q.qlen` can therefore create a dangling pointer to the class from the active list, leading to a use-after-free on the class during the qdisc's dequeue method.

Each qdisc has an enqueue and dequeue method defined in its `Qdisc_ops`. If a qdisc has a child qdisc, its enqueue method will usually call the enqueue method of the child and so on until the packet is enqueued at a leaf. Similarly, each dequeue method will try to dequeue from a child qdisc until it finds a packet to dequeue.

If a qdisc has multiple classes, a filter determines which class the packet is enqueued to. The `basic` filter can be used to send all packets to a chosen class. Some qdiscs like HFSC also have a default class parameter which will be used if there is no filter.
When there is more than one active class , the qdisc's scheduling algorithm will choose which class to dequeue from. The HFSC algorithm will always dequeue packets from an RSC class over an FSC class, providing a deterministic way to control from which class the next packet is dequeued.

Userspace communicates with the traffic control subsystem through netlink messages. All netlink messages used in the exploit are stored in pre-initialized structs and sent with the custom `tc_*` helper functions.

## Triggering the Vulnerability

Calling the `trigger_vuln()` function on a class whose qdisc has handle `0xffff0000` will cause it to remain on its active list when it is eventually freed (`trigger_vuln()` itself does not free the class):

```
void trigger_vuln (int parent) {
    tc_add_qd(&delay_netem_qdisc_msg, parent, VULN_NETEM_HANDLE);
    loopback_send();
}
```

A netem qdisc configured to delay packets is added as the child of `parent` and has a packet enqueued to it. `parent` will remain on its active list as long as the packet is enqueued. When it is deleted, the bug will cause `qdisc_tree_reduce_backlog()` to skip `qlen_notify()` on it and leave it on the active list when it is freed.

While the class is on the active list, it can be accessed by its qdisc's `dequeue` method, so triggering the vulnerability under a DRR class gives us a use-after-free on a `drr_class` during `drr_dequeue()`.

## `Qdisc` Use-After-Free

### Objective

We want to turn our `drr_class` use-after-free into a use-after-free on the `privdata[]` field of a `Qdisc`, which can be used for type confusion that bypasses the mitigations since we are replacing a `Qdisc` with another `Qdisc` (when working on the exploit, I wasn't aware of the [bypass](https://github.com/google/security-research/blob/master/pocs/linux/kernelctf/CVE-2024-53164_lts_cos_mitigation/docs/exploit.md#additional-notes-for-the-mitigation-instance) that allows a type confusion directly on the class).

Our use-after-free target is the `watchdog` field of the `tbf_sched_data` struct in a TBF qdisc's `privdata[]`. `watchdog` contains a timer node that is added to a per-CPU RB tree of timers when scheduled by `qdisc_watchdog_schedule_ns()`, which happens in `tbf_dequeue()` when a packet needs to be delayed. This timer is deactivated when the qdisc is destroyed in `__qdisc_destroy()`. If we can schedule it after the qdisc has been destroyed, a dangling pointer will be left to it from the timer tree.

We can use the vulnerability to call `tbf_dequeue()` on a destroyed TBF qdisc via a dangling pointer to a parent `drr_class`. However `tbf_dequeue()` will only schedule the watchdog timer if it successfully dequeues a packet from the TBF qdisc's child qdisc. Destroying the TBF qdisc purges all packets and it is not possible to enqueue more (the dangling pointer can only be used to dequeue). Therefore we must trigger the vulnerability on a `drr_class` under the TBF qdisc as well. This `drr_class` is freed and replaced with a `drr_class` that remains reachable after the TBF qdisc is destroyed. A packet is enqueued to it normally and dequeued through the dangling pointer. The vulnerability can only be triggered on one qdisc per network namespace, but we can get around this by splitting the hierarchy across two namespaces connected by the dangling pointers.

After creating the dangling timer node pointer we replace the TBF qdisc with a netem qdisc. Overlapping `netem_sched_data` with `tbf_sched_data` lets us read from and write to the timer node by reading and modifying the netem qdisc’s parameters.

This demonstrates a way to defeat the mitigations when they are working as intended: use same-object use-after-frees to induce further vulnerabilities until a vulnerability which bypasses the mitigations is reached. There are many bugs for which this will not be possible, for instance some same-object use-after-frees do not lead to any novel behaviour at all.

### Creating the vulnerable hierarchy

The `add_qdisc_timer_node()` function creates a dangling timer pointer to a netem qdisc as described above. It constructs the necessary qdisc hierarchy under the passed handle `parent` with an HFSC qdisc with handle `root` at the top and three branches beneath it. The objects in the hierarchy are divided between the `outer` and `inner` namespaces. The root and first and third branches are in the outer namespace while the second branch in the inner namespace. The variables `b1`, `b2`, and `b3` store the handle of each branch's leaf as it is being built. The completed hierarchy is depicted below:

![Hierarchy diagram](hierarchy.svg)

The TBF qdisc which we will create a dangling pointer to is located in the second branch. The TBF qdisc's child DRR qdisc has a dangling pointer to a `drr_class` in the third branch, while the first branch contains a DRR qdisc with a dangling pointer to the TBF qdisc's parent `drr_class`.

We always enqueue packets in the outer namespace. The packets are then enqueued to the third branch due to our choice of filters and the HFSC qdisc's default class parameter and dequeued from the first branch since it is under an RSC class which the HFSC algorithm always prioritizes over FSC classes.

The dequeue path goes along the two dangling pointers, passing through the TBF qdisc to reach the leaf of branch three where the packet was enqueued. When the packet is passed back up to the TBF qdisc, the timer is scheduled:

![Enqueue/dequeue paths diagram](paths.svg)

#### DRR class spray

While building the hierarchy, we perform a `drr_class` spray in `kmalloc-128` for each dangling `drr_class` pointer we create. After each spray we need to determine which of the sprayed classes is under the dangling pointer. The `drr_spray_and_find()` function sprays `drr_class`s and returns the handle of the successfully sprayed class.

The successful class is found by sending a packet to each of the sprayed classes. A `basic` filter is used to make each sprayed class the default class in turn. The sent packet will be dequeued via the dangling pointer, so we know we found the right class if the packet we send is successfully recieved back.

This only works if the packet is enqueued in the outer namespace, which only happens for the `drr_class` under the TBF qdisc. When replacing the other `drr_class` we assume that the first allocation falls under the dangling pointer and retry if this is incorrect (in which case `drr_spray_find()` will fail on the class under the TBF qdisc). We still spray more DRR classes after this to prevent anything else being allocated under the dangling pointer if the first allocation misses.

Dequeuing the packet will decrement the `q.qlen`s of all qdiscs on the dequeue path. This risks removing their classes from their active lists and preventing further packets being dequeued this way. A second DRR class with handle `pin` is therefore added to the same active list as the first vulnerable class and a packet is sent to it. Then `drr_spray_and_find()` will leave all active lists undisturbed when dequeuing a packet.

#### Setting the timer

After the hierarchy is built, we need to send the `stall_tbf_qdisc_msg` netlink message to change the TBF qdisc's `rate` parameter so that the timer will be scheduled during dequeue. This affects the following code which schedules the timer in `tbf_dequeue()`:

```
unsigned int len = qdisc_pkt_len(skb);
toks -= (s64) psched_l2t_ns(&q->rate, len);
qdisc_watchdog_schedule_ns(&q->watchdog, now + max_t(long, -toks, -ptoks));
```

When `rate` is `1` the timer will wait for `len - 1` seconds. We want a large waiting time to prevent other timer nodes on the same CPU being added under our node. The `label` argument determines the length of packet and wait. It is converted to a length using the `LABEL_TO_VALUE()` macro. After the TBF qdisc is destroyed via its parent handle `tbfp`, a packet with this length is sent and schedules the TBF timer as shown in the above diagram.

Unfortunately, on `6.1` kernels the freelist pointer of a TBF qdisc overlaps with the timer's `rb_node`. If the timer is set after the qdisc is freed, the kernel will crash when trying to reallocate the qdisc's memory. Rather than trying to race from another thread, we simply hope that our `sendto()` completes during the RCU delay before the qdisc is freed. A large number of DRR classes are added under the TBF qdisc to increase the delay since their child qdiscs are freed before the TBF qdisc. This is the primary cause of exploit failure against the `6.1` mitigation kernel, causing a crash in about 10% of attempts against the live instance. The `6.6` kernel is not affected.

#### Netem qdisc spray

Once the timer is scheduled, `membarrier(MEMBARRIER_CMD_GLOBAL, 0)` is used to wait for the RCU delay before the TBF qdisc is freed and netem discs sprayed in the `kmalloc-1k` cache. The first netem qdisc in the spray is added as the child of `b3` and each subsequent qdisc is added as a child of the previous one. The handles of the sprayed qdiscs are returned via the `spray_handles` array.

Later in the exploit it will be relevant which bucket in the net device's `qdisc_hash` hash table the netem qdisc is stored in. The hash is calculated from the qdisc's handle. We make sure that all the sprayed netem qdiscs have a handle whose hash matches the passed `spray_hash`.

### Reading from and writing to `netem_sched_data`

A netem qdisc's parameters are stored in the `netem_sched_data` struct in its `->privdata[]` and can be read or modified through netlink messages. There are two blocks of contiguous memory inside `netem_sched_data` which consist largely of readable and writable parameters. The first is a 56-byte block starting at `->latency`:

```
s64 latency;
s64 jitter;
u32 loss;
u32 ecn;
u32 limit;
u32 counter;
u32 gap;
u32 duplicate;
u32 reorder;
u32 corrupt;
u64 rate;
```

Outside of bytes 11 to 15 and 28 to 31, this entire block can be read and modified. Bytes 11 to 15 are the top 5 bytes of `jitter`, which is capped at `INT_MAX`. They can be read but not set to any value greater than `0x000000007f`. Bytes 28 to 31 hold `counter`, which cannot be read or modified through `netem_change()`.

This block contains the fake `rb_node` under our dangling pointer. The `rb_node` is located at `&latency`, so the only valid value we can write to its `->rb_right` child is `NULL`. Any value can be written to the left child and parent, and all three fields can be arbitrarily read.

The second block consists of the 40-byte `tc_netem_slot` structure `->slot_config` near the end of `netem_sched_data`:

```
__s64 min_delay;
__s64 max_delay;
__s32 max_packets;
__s32 max_bytes;
__s64 dist_delay;
__s64 dist_jitter;
```

Writing to `dist_jitter` in bytes 32 to 39 has the same limitation as writing to `jitter`, `max_packets` and `max_bytes` in bytes 16 to 23 can be set to any non-zero value, and all other fields can be arbitrarily set and read.

We use `write_netem_parms()` and `read_netem_parms()` to send the netlink messages necessary to write or read the parameters of a given netem qdisc. The passed buffers are copied to or from the corresponding parameter blocks as closely as possible. Note that `read_netem_parms()` does not read from the second block of parameters as it is not needed for the exploit.

Reading is performed by sending an `RTM_GETQDISC` netlink message, which will be recieved by `qdisc_get_notify()` in the kernel. This function builds a diagnostic dump by calling `tc_fill_qdisc()` on each of the net device's qdiscs. We can then read the dump from the netlink socket and locate a specific qdisc's parameters within it. We can write to a netem qdisc's parameters by sending a `RTM_NEWQDISC` message. As long as there is no mismatch in the qdisc type, the specified `Qdisc` will be modified in place by `netem_change()` rather than being reallocated.

### RB tree rebalancing write primitive

Deleting an `rb_node` with two children can cause a rebalancing which grants a write primitive when we control the right child. A diagram of the rebalancing is included in the kernel code in `__rb_erase_augmented()`:

```
/*
 * Case 3: node's successor is leftmost under
 * node's right child subtree
 *
 *    (n)          (s)
 *    / \          / \
 *  (x) (y)  ->  (x) (y)
 *      /            /
 *    (p)          (p)
 *    /            /
 *  (s)          (c)
 *    \
 *    (c)
 */
```

The address of `p` will be written to the `__rb_parent_color` field of `c` when `p` becomes `c`'s parent. Assuming we control `y`, `p` and `s`, we can write the address of `p` to an arbitrary location specified in the `rb_right` field of `s`.

Afterwards `s` is the new root of the subtree. If we can remove the subtree's parent, the process can be repeated with `s` taking the place of `y`.

The least significant bit of an `rb_node`'s `__rb_parent_color` field stores its color. It is `1` if the node is black and `0` if it is red. The above rebalancing always results in `p` being colored black. Prior to commit `b0687c1119b4` coloring was done using the `|` operation, so the value written to `c` would always end in `1`. This is not an issue if we want to write a pointer for a fake structure we control, since we can place the fake structure at a misaligned address. After this commit `+` is used instead, removing this restriction. `6.1` kernels still use `|` and `6.6` kernels use `+`. To ensure the exploit works across all versions, `p` is always located at an even address and the fake object is placed at an offset of 1 from this address.

## Exploit

### Qdisc setup

We will need to trigger the `Qdisc` use-after-free twice during the exploit, so we create four network namespaces in total. We open a netlink and inet socket in each namespace before unsharing to create the next one. After the exploit task enters a new namespace, the old namespace can still be accessed through the sockets opened in it.

Both of the namespaces have an HFSC qdisc as the root and an FSC class under which `add_qdisc_timer_node()` is called. In the first namespace, this HFSC qdisc is used for the arbitrary write primitive. The HFSC qdisc in the second qdisc is used to hold a packet which we will later use to leak kernel addressses. The handles of the root qdiscs are chosen such that their hashes are distinct from those of the attacker netem qdiscs.

### RB tree setup

Each `add_qdisc_timer_node()` call adds an attacker-controlled `rb_node` to the CPU's timer tree. We use this together with `add_timer_node()`, which sets a timer using `timerfd_settime()`, to construct a tree with two attacker-controlled nodes and fifteen regular timer nodes. Each removal of a regular node from the tree will give us a read or write primitive.

Since the timer tree is shared with all other threads on the CPU, we make the values in our RB nodes as large as possible to lower the chance of interference. To avoid working with these large values in the exploit and writeup, we refer to the nodes using labels from `0` to `16`. The `LABEL_TO_VALUE()` macro converts these labels to the approximate value of the corresponding timer node while preserving their order.

The `add_order` array determines which value to add at each step. The shape of the tree will vary depending on how many nodes have been added by other threads on the CPU, but the substructure depicted below should be present as long as no timer nodes with values larger than ours are added:

```
 \         ( ) regular node
 (9)       < > attacker node
/   \
    (11)     
   /    \
        (13)
       /    \
            (15)
           /    \
         <14>   <16>
``` 

The nodes with labels `9`, `11`, `13` and `15` will each be removed to trigger an infoleak or write. The parent of `9` should also be under our control, since if it is removed after `9` is removed a crash will occur. To prevent that, we add many timerfd nodes with the label `-1`, shielding the top of the subtree from other threads.

Once the TBF `Qdiscs`s containing the attacker nodes have been replaced with netem `Qdiscs`s , their node values are longer relevant. The netem qdiscs inserted with labels 14 and 16 are referred to as `n1` and `n2`, respectively.


### Leaking `Qdisc` heap addresses

Removing the parent of the two attacker controlled nodes results in one of them becoming the parent of the other:

```
 \                   \
 (13)                (13)
/    \              /    \
     (15)     -->        <n2>
    /    \              /
  <n1>   <n2>         <n1>
```

This writes the address of the parent to the child and vice versa. By reading the parameters of all sprayed netem qdiscs and searching for valid kernel addresses, we can determine the handles and addresses on the heap of the two qdiscs which contain timer nodes.

### Arbitrary read

A read primitive is obtained by passing a fake `Qdisc` to `tc_fill_qdisc()` when building a qdisc dump. 24 bytes read from the `Qdisc`’s `->stab.szopts` are returned to userspace within the dump. Two rebalancings are are necessary to set up the read primitive.

#### Rebalancing writes

In addition to the fake `Qdisc`'s `->stab` at offset 32, we must also provide valid addresses for `->ops` at offset 24 and `->dev_queue` at offset 64 to prevent `tc_fill_qdisc()` from crashing. Overlapping the fake `Qdisc` with `n2->slot` lets us control `->ops` and `->stab` but not `->dev_queue`, which will align with `&n2->slot_dist`. We use the rebalancing write primitive to overwrite `&n2->slot_dist` with the address of a fake `dev_queue`.

The addresses of the fake nodes corresponding to nodes `y`,`p`,`s`, and `c` in the rebalancing diagram for this write are:

```
y,p: &n2->latency
s: &n1->latency + 32
c: &n2->slot_dist
```

The role of `y` and `p` is taken by a single fake node. Its address plus one will be written to `&n2->slot_dist`.

Another write is needed to insert the fake `Qdisc` into the net device's qdisc hash table so that `qdisc_get_notify()` calls `tc_fill_qdisc()` on it when building a dump. This is done by overwriting `n2->hash.next` with the address of a fake qdisc.

Due to the limitation of the rebalancing write mentioned above, the fake qdisc linked to by `n2->hash.next` will be at a misaligned offset, limiting which of its fields we can set. Therefore this qdisc will only be used to link to the fake qdisc that is actually used for the read. Here are the `y`,`p`,`s`,`c` addresses for the rebalancing write:

```
y: &n1->latency + 32
p: &n2->latency + 32
s: &n1->slot + 8
c: &n2->hash.next
```

When `n2->hash.next` is overwritten, all qdiscs after `n2` in the hash bucket become inaccessible. This is why we made sure that any qdiscs we need to access after this point have a hash distinct from `n2`.

#### Using arbitrary read

Before each read, the two fake `Qdisc`s have to be written to `n2`'s `privdata[]`. Their values are initialized in `setup_stab_read()` along with the other information needed to perform the read.

The fake `Qdisc` linked to by `n2->hash.next` has its base at `&n2->latency - 7`. The following fields are set:

- `flags` is set to `TCQ_F_INVISIBLE` so that this `Qdisc` is skipped during the dump.
- `hash.next` is set to `n2->slot + 32`, linking the `Qdisc` we want to dump.

The `Qdisc` we want to dump has its base at `&n2->slot - 8`. The following fields have to be set for the read to be successful:

- `flags` is set to zero.
- `ops` is set to `&n2->latency + 232`, so that `ops->ingress_block_get` and `ops->egress_block_get` are `NULL`, preventing them from being called.
- `stab` is set to the target address.
- `hash.next` is set to `NULL` to stop the dump.
- `dev_queue` has value `&n2->latency + 1` from the earlier rebalancing write. The `dev_queue->dev->ifindex` field will be dumped during `tc_fill_qdisc()`. `dev_queue->dev` is set such that `ifindex` is located at `&n2->latency + 48` and `ifindex` is set to a unique value to identify the fake qdisc in the dump.

After writing the fake `Qdisc`s to kernel memory, we can use `read_netem_stab()` to dump the net device's qdiscs and find the 24 bytes of leaked data. The `stab_read_8()` function does this and returns 8 bytes read from the passed kernel address.

### Write-what-where

The `vttree_get_minvt()` call in `hfsc_dequeue()` provides a write-what-where primitive if we control `hfsc_class`, as described in the [writeup](https://github.com/google/security-research/blob/master/pocs/linux/kernelctf/CVE-2023-4623_lts_cos/docs/exploit.md#write-what-where) for CVE-2023-4623. This primitive allows us to write 8 bytes to an arbitrary address, with the restriction that the written value must be larger (as a `u64`) than the value it is replacing. It can be set up with one rebalancing write.

#### Rebalancing write

The rebalancing write primitive is used to replace the root FSC `hfsc_class` of the interface's root qdisc:

```
y: &n1->slot + 8
p: &n1->latency - 16
s: &n1->latency + 32
c: &root_qdisc->privdata.root.vt_tree
```

This inserts a fake `hfsc_class` into the root qdisc's `vt_tree` with its `vt_node` at `&n1->latency - 15`. There is not enough space in the netem qdisc parameters to fake all the fields necessary for the write primitive, so this `hfsc_class` will only be used to link the `hfsc_class` actually used for the write.

#### Using write-what-where

Before each write, a fake `hfsc_class` is placed in `n1->slot_dist`, which is a `disttable` structure consisting of a 4-byte header followed by a buffer of user provided data. It can be reallocated during `netem_change()` with the new contents copied from the `TCA_NETEM_SLOT_DIST` field of the netlink parameters. The `cl_parent` and `cl_vt` fields of this class store the target address and value for the write primitive, respectively.

The stab read primitive is then used to read the newly allocated `n1->slot_dist`. This lets us calculate the address of the fake `hfsc_class` contained in it, which we then insert into the root qdisc's `vt_tree` by changing the `vt_node->rb_right` field of the `hfsc_class` in `n1`'s parameters. Now `vttree_get_minvt()` will find the fake class we placed in `slot_dist`, assign it to `cl` and execute

```
if (cl->cl_parent->cl_cvtmin < cl->cl_vt)
    cl->cl_parent->cl_cvtmin = cl->cl_vt;
```

on it, writing the 8-byte value in `cl_vt` to the address in `cl_parent`.

The write primitive is implemented by `vt_write_8()`, which writes `val` to `addr` through the process outlined above. `setup_vt_write()` is called once to store the address and handle of `n1` for `vt_write_8()`.

### LPE

With the read and write primitives set up, we escalate privileges by modifying the exploit's `task_struct`. The `task_struct`'s address can be found by reading the following chain of pointers, starting at the `sk_buff` structure in the `t_head` field of `netem_sched_data`:

`t_head->sk->sock->file->f_owner->pid->tasks[0]`

Two of these pointers, `t_head` and `f_owner`, have to be manually set. `f_owner` is set by using the `FSETOWN` fcntl on the inet socket. `t_head` is set by enqueueing a delayed packet to a netem qdisc with handle `enq_qd` in the second namespace during qdisc setup. The `handle_to_kaddr()` helper function searches the net device's hash list of qdiscs for this qdisc and returns its address (the address of the net device is obtained by reading `n2->dev_queue->dev`).

The address of `init_task` is then obtained by repeatedly dereferencing `->parent` starting from the exploit `task_struct`. The exploit `task_struct`'s `->cred` and `->fs` are replaced by `init_cred` and `init_fs` to escalate privileges and escape the mount namespace (the write primitive is guaranteed to work here since `init_cred` and `init_fs` are part of the kernel image, which is at a higher address than the heap).