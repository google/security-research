# Vulnerability Overview
This vulnerability exists within the io_uring subsystem, specifically in how fixed buffers are registered and subsequently imported.  

The root cause is an incorrect offset calculation when handling user pointers that are not aligned to the folio size.  

This logic error results in an incorrect bv_len (buffer vector length),  

which subsequently triggers an Out-of-Bounds (OOB) access and the use of uninitialized memory during I/O operations.  

# Root Cause Analysis


## Incorrect Offset Calculation (io_sqe_buffer_register)
In io_sqe_buffer_register, the kernel attempts to calculate the offset of the first page.  

However, the bitmask logic used assumes specific alignment guarantees for user pointers that do not exist.  

When iov->iov_base is not aligned as expected relative to imu->folio_shift, the calculated off variable is incorrect.  

```C
static int io_sqe_buffer_register(struct io_ring_ctx *ctx, struct iovec *iov,
                  struct io_mapped_ubuf **pimu,
                  struct page **last_hpage)
{
    // ...
    /* * VULNERABILITY: 
     * The bitwise AND logic here produces an incorrect offset if the 
     * user pointer (iov_base) alignment does not match the folio logic.
     */
    off = (unsigned long) iov->iov_base & ((1UL << imu->folio_shift) - 1);
    *pimu = imu;
    ret = 0;

    for (i = 0; i < nr_pages; i++) {
        size_t vec_len;

        /* * Because 'off' is potentially wrong, 'vec_len' (the length of 
         * this segment) becomes smaller than it should be.
         */
        vec_len = min_t(size_t, size, (1UL << imu->folio_shift) - off);
        bvec_set_page(&imu->bvec[i], pages[i], vec_len, off);
        off = 0;
    // ...
```

The bvec->bv_len stored in the `io_mapped_ubuf` is smaller than the correct value required to represent the data.  

## OOB Access in (io_import_fixed)

Later, when io_import_fixed is called to perform I/O using the registered buffer, it iterates over the buffer vectors.  

The logic attempts to skip segments (seg_skip) based on the requested offset.  

Because the stored bv_len is artificially small (due to the bug above), the function believes it needs to skip more segments than actually exist to reach the requested offset.  

```C
int io_import_fixed(int ddir, struct iov_iter *iter,
               struct io_mapped_ubuf *imu,
               u64 buf_addr, size_t len)
{
    // ...
    if (offset < bvec->bv_len) {
        iter->bvec = bvec;
        iter->count -= offset;
        iter->iov_offset = offset;
    } else {
        unsigned long seg_skip;

        /* skip first vec */
        offset -= bvec->bv_len;
        
        /* * VULNERABILITY:
         * Because 'bvec->bv_len' was too small, the remaining 'offset' is too large.
         * This causes 'seg_skip' to calculate a value larger than the bvec array length.
         */
        seg_skip = 1 + (offset >> imu->folio_shift);

        /* * 'iter->bvec' now points Out-Of-Bounds (OOB) past the end of the array.
         * This results in the usage of uninitialized memory for io_read/io_write operations.
         */
        iter->bvec = bvec + seg_skip; 
        iter->nr_segs -= seg_skip;
        iter->count -= bvec->bv_len + offset;
        iter->iov_offset = offset & ((1UL << imu->folio_shift) - 1);
    }
    // ...
    return 0;
}
```

## Exploit Strategy

The uninitialized memory usage in `io_import_fixed` can be weaponized to achieve a container escape.

### Triggering the Vulnerability

By triggering the OOB condition, the iter->bvec pointer is made to point to uninitialized memory. We manipulate the kernel heap to ensure that this uninitialized memory region contains a pointer to a page we control or have recently freed.

### Prepare Spray FDs
We set up `io_uring` instances to groom memory.

### Register PBUF Ring
We register the provided buffer ring and map the target area that will overlap.

### Setup Main Exploitation Ring
We set up the main exploitation ring, unregistering previous buffers and replacing them with our newly aligned mapping.

### Spray Target Pages
We allocate multiple pages targeting our sprayed area to make sure page tables are allocated closely.

### Trigger Page Write/Read via IO_URING
We trigger an I/O read and write over the vulnerability to perform uninitialized memory reads. This leaks the relevant Page Table Entry (PTE).

### Calculate and Write Fake PTE
Using the leaked information from our read, we modify the PTE value to point to the kernel's `core_pattern` address and write it back.

### Spray core_pattern payload
With the mutated page table, we write our core_pattern exploitation payload `|/proc/%P/fd/666 %P` into the newly mapped region. 
Finally, when the exploit intentionally triggers a crash with `rip_trigger_crash`, the kernel will execute our arbitrary program as root, giving us a container escape. 
