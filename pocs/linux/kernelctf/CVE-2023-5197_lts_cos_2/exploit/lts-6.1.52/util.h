#include <stdio.h>
#include <errno.h>
#include <stdint.h>
#include <string.h>

#include <linux/netfilter.h>
#include <linux/netfilter/nfnetlink.h>
#include <linux/netfilter/nf_tables.h>

#include <libmnl/libmnl.h>

#include <libnftnl/batch.h>
#include <libnftnl/table.h>
#include <libnftnl/chain.h>
#include <libnftnl/rule.h>
#include <libnftnl/expr.h>

// Macros for printing
#define INFO(fmt, ...) fprintf(stderr, "[*] " fmt "\n", ##__VA_ARGS__)
#define WARN(fmt, ...) fprintf(stderr, "[!] " fmt "\n", ##__VA_ARGS__)
#define ERROR(msg)                                                    \
	fprintf(stderr, "[-] %s:%d: %s: %s", __func__, __LINE__, msg, \
		strerror(errno))

typedef __u8 u8;
typedef __u16 u16;
typedef __u32 u32;
typedef __u64 u64;
typedef unsigned int __bitwise gfp_t;

struct list_head {
	struct list_head *next, *prev;
};

struct nft_pktinfo;
struct nft_regs;
struct nft_ctx;
enum nft_trans_phase;
struct sk_buff;
struct nft_data;
struct net;
struct nft_flow_rule;
struct nft_offload_ctx;
struct flow_stats;
struct nft_expr;

/**
 *	struct nft_expr_ops - nf_tables expression operations
 *
 *	@eval: Expression evaluation function
 *	@size: full expression size, including private data size
 *	@init: initialization function
 *	@activate: activate expression in the next generation
 *	@deactivate: deactivate expression in next generation
 *	@destroy: destruction function, called after synchronize_rcu
 *	@dump: function to dump parameters
 *	@type: expression type
 *	@validate: validate expression, called during loop detection
 *	@data: extra data to attach to this expression operation
 */
struct nft_expr_ops {
	void (*eval)(const struct nft_expr *expr, struct nft_regs *regs,
		     const struct nft_pktinfo *pkt);
	int (*clone)(struct nft_expr *dst, const struct nft_expr *src,
		     gfp_t gfp);
	unsigned int size;

	int (*init)(const struct nft_ctx *ctx, const struct nft_expr *expr,
		    const struct nlattr *const tb[]);
	void (*activate)(const struct nft_ctx *ctx,
			 const struct nft_expr *expr);
	void (*deactivate)(const struct nft_ctx *ctx,
			   const struct nft_expr *expr,
			   enum nft_trans_phase phase);
	void (*destroy)(const struct nft_ctx *ctx, const struct nft_expr *expr);
	void (*destroy_clone)(const struct nft_ctx *ctx,
			      const struct nft_expr *expr);
	int (*dump)(struct sk_buff *skb, const struct nft_expr *expr);
	int (*validate)(const struct nft_ctx *ctx, const struct nft_expr *expr,
			const struct nft_data **data);
	bool (*gc)(struct net *net, const struct nft_expr *expr);
	int (*offload)(struct nft_offload_ctx *ctx, struct nft_flow_rule *flow,
		       const struct nft_expr *expr);
	bool (*offload_action)(const struct nft_expr *expr);
	void (*offload_stats)(struct nft_expr *expr,
			      const struct flow_stats *stats);
	const struct nft_expr_type *type;
	void *data;
};

/**
 *	struct nft_expr - nf_tables expression
 *
 *	@ops: expression ops
 *	@data: expression private data
 */
struct nft_expr {
	const struct nft_expr_ops *ops;
	unsigned char data[] __attribute__((aligned(__alignof__(u64))));
};

/**
 *	struct nft_rule - nf_tables rule
 *
 *	@list: used internally
 *	@handle: rule handle
 *	@genmask: generation mask
 *	@dlen: length of expression data
 *	@udata: user data is appended to the rule
 *	@data: expression data
 */
struct nft_rule {
	struct list_head list;
	u64 handle : 42, genmask : 2, dlen : 12, udata : 1;
	unsigned char data[]
		__attribute__((aligned(__alignof__(struct nft_expr))));
};

/**
 *	struct nft_userdata - user defined data associated with an object
 *
 *	@len: length of the data
 *	@data: content
 *
 *	The presence of user data is indicated in an object specific fashion,
 *	so a length of zero can't occur and the value "len" indicates data
 *	of length len + 1.
 */
struct nft_userdata {
	u8 len;
	unsigned char data[];
};

/**
 * struct callback_head - callback structure for use with RCU and task_work
 * @next: next update requests in a list
 * @func: actual update function to call after the grace period.
 *
 * The struct is aligned to size of pointer. On most architectures it happens
 * naturally due ABI requirements, but some architectures (like CRIS) have
 * weird ABI and we need to ask it explicitly.
 *
 * The alignment is required to guarantee that bit 0 of @next will be
 * clear under normal conditions -- as long as we use call_rcu() or
 * call_srcu() to queue the callback.
 *
 * This guarantee is important for few reasons:
 *  - future call_rcu_lazy() will make use of lower bits in the pointer;
 *  - the structure shares storage space in struct page with @compound_head,
 *    which encode PageTail() in bit 0. The guarantee is needed to avoid
 *    false-positive PageTail().
 */
struct callback_head {
	struct callback_head *next;
	void (*func)(struct callback_head *head);
} __attribute__((aligned(sizeof(void *))));
#define rcu_head callback_head

struct rhash_head {
	struct rhash_head *next;
};

struct rhlist_head {
	struct rhash_head rhead;
	struct rhlist_head *next;
};

/**
 *	struct nft_chain - nf_tables chain
 *
 *	@blob_gen_0: rule blob pointer to the current generation
 *	@blob_gen_1: rule blob pointer to the future generation
 *	@rules: list of rules in the chain
 *	@list: used internally
 *	@rhlhead: used internally
 *	@table: table that this chain belongs to
 *	@handle: chain handle
 *	@use: number of jump references to this chain
 *	@flags: bitmask of enum NFTA_CHAIN_FLAGS
 *	@bound: bind or not
 *	@genmask: generation mask
 *	@name: name of the chain
 *	@udlen: user data length
 *	@udata: user data in the chain
 *	@rcu_head: rcu head for deferred release
 *	@blob_next: rule blob pointer to the next in the chain
 */
struct nft_chain {
	struct nft_rule_blob *blob_gen_0;
	struct nft_rule_blob *blob_gen_1;
	struct list_head rules;
	struct list_head list;
	struct rhlist_head rhlhead;
	struct nft_table *table;
	u64 handle;
	u32 use;
	u8 flags : 5, bound : 1, genmask : 2;
	char *name;
	u16 udlen;
	u8 *udata;
	struct rcu_head rcu_head;

	/* Only used during control plane commit phase: */
	struct nft_rule_blob *blob_next;
};

static void util_generate_name(char *buf, const char *prefix)
{
	static int counter = 0;
	sprintf(buf, "%s%d", prefix, counter++);
}

static int util_create_nft_table(struct nftnl_batch *batch, int seq,
				 const char *name, const void *udata,
				 size_t udata_len)
{
	struct nftnl_table *t;
	struct nlmsghdr *hdr;

	if ((t = nftnl_table_alloc()) == NULL) {
		ERROR("nftnl_table_alloc");
		return -errno;
	}

	nftnl_table_set_u32(t, NFTNL_TABLE_FAMILY, NFPROTO_IPV4);
	nftnl_table_set_str(t, NFTNL_TABLE_NAME, name);

	if (udata_len > 0)
		nftnl_table_set_data(t, NFTNL_TABLE_USERDATA, udata, udata_len);

	hdr = nftnl_nlmsg_build_hdr(nftnl_batch_buffer(batch), NFT_MSG_NEWTABLE,
				    NFPROTO_IPV4, NLM_F_ACK | NLM_F_CREATE,
				    seq);
	nftnl_table_nlmsg_build_payload(hdr, t);
	nftnl_batch_update(batch);

	nftnl_table_free(t);
	return 0;
}

#define INVALID_HOOKNUM 0xffff

static int util_create_nft_chain(struct nftnl_batch *batch, int seq,
				 const char *table, const char *name,
				 uint32_t flags, uint32_t hooknum, int priority)
{
	struct nftnl_chain *c;
	struct nlmsghdr *hdr;

	if ((c = nftnl_chain_alloc()) == NULL) {
		ERROR("nftnl_chain_alloc");
		return -errno;
	}

	nftnl_chain_set_str(c, NFTNL_CHAIN_TABLE, table);
	nftnl_chain_set_str(c, NFTNL_CHAIN_NAME, name);
	nftnl_chain_set_u32(c, NFTNL_CHAIN_FLAGS, flags);

	if (hooknum != INVALID_HOOKNUM) {
		nftnl_chain_set_u32(c, NFTNL_CHAIN_HOOKNUM, hooknum);
		nftnl_chain_set_s32(c, NFTNL_CHAIN_PRIO, priority);
	}

	hdr = nftnl_nlmsg_build_hdr(nftnl_batch_buffer(batch), NFT_MSG_NEWCHAIN,
				    NFPROTO_IPV4, NLM_F_ACK | NLM_F_CREATE,
				    seq);
	nftnl_chain_nlmsg_build_payload(hdr, c);
	nftnl_batch_update(batch);

	nftnl_chain_free(c);
	return 0;
}

static int util_create_nft_rule(struct nftnl_batch *batch, int seq,
				const char *table, const char *chain,
				struct nftnl_expr **exprs, size_t num_exprs,
				void *udata, size_t udata_len)
{
	struct nftnl_rule *r;
	struct nlmsghdr *hdr;

	if ((r = nftnl_rule_alloc()) == NULL) {
		ERROR("nftnl_rule_alloc");
		return -errno;
	}

	nftnl_rule_set_u32(r, NFTNL_RULE_FAMILY, NFPROTO_IPV4);
	nftnl_rule_set_str(r, NFTNL_RULE_TABLE, table);
	nftnl_rule_set_str(r, NFTNL_RULE_CHAIN, chain);

	for (int i = 0; i < num_exprs; ++i)
		nftnl_rule_add_expr(r, exprs[i]);

	if (udata_len > 0)
		nftnl_rule_set_data(r, NFTNL_RULE_USERDATA, udata, udata_len);

	hdr = nftnl_nlmsg_build_hdr(nftnl_batch_buffer(batch), NFT_MSG_NEWRULE,
				    NFPROTO_IPV4,
				    NLM_F_ACK | NLM_F_CREATE | NLM_F_APPEND,
				    seq);
	nftnl_rule_nlmsg_build_payload(hdr, r);
	nftnl_batch_update(batch);

	nftnl_rule_free(r);
	return 0;
}

static struct nftnl_expr *
util_create_immediate_jump_expr(const char *target_chain)
{
	struct nftnl_expr *e;

	if ((e = nftnl_expr_alloc("immediate")) == NULL) {
		ERROR("nftnl_expr_alloc");
		return NULL;
	}

	nftnl_expr_set_u32(e, NFTNL_EXPR_IMM_DREG, NFT_REG_VERDICT);
	nftnl_expr_set_u32(e, NFTNL_EXPR_IMM_VERDICT, NFT_JUMP);
	nftnl_expr_set_str(e, NFTNL_EXPR_IMM_CHAIN, target_chain);

	return e;
}

static struct nftnl_expr *util_create_immediate_return_expr()
{
	struct nftnl_expr *e;

	if ((e = nftnl_expr_alloc("immediate")) == NULL) {
		ERROR("nftnl_expr_alloc");
		return NULL;
	}

	nftnl_expr_set_u32(e, NFTNL_EXPR_IMM_DREG, NFT_REG_VERDICT);
	nftnl_expr_set_u32(e, NFTNL_EXPR_IMM_VERDICT, NFT_RETURN);

	return e;
}

static int util_delete_nft_chain(struct nftnl_batch *batch, int seq,
				 const char *table, const char *name)
{
	struct nftnl_chain *c;
	struct nlmsghdr *hdr;

	if ((c = nftnl_chain_alloc()) == NULL) {
		ERROR("nftnl_chain_alloc");
		return -errno;
	}

	nftnl_chain_set_str(c, NFTNL_CHAIN_TABLE, table);
	nftnl_chain_set_str(c, NFTNL_CHAIN_NAME, name);

	hdr = nftnl_nlmsg_build_hdr(nftnl_batch_buffer(batch), NFT_MSG_DELCHAIN,
				    NFPROTO_IPV4, NLM_F_ACK, seq);
	nftnl_chain_nlmsg_build_payload(hdr, c);
	nftnl_batch_update(batch);

	nftnl_chain_free(c);
	return 0;
}

// seq_end is exclusive
static int util_nftnl_run_callback(struct mnl_socket *mnl, int seq_start,
				   int seq_end, mnl_cb_t callback,
				   void *callback_data)
{
	int ret = 0;

	for (int i = seq_start; i < seq_end; i += ret == 0) {
		ssize_t n;
		char buf[MNL_SOCKET_BUFFER_SIZE];

		n = mnl_socket_recvfrom(mnl, buf, sizeof(buf));
		switch (n) {
		case -1:
			ERROR("mnl_socket_recvfrom");
			return -1;
		case 0:
			break;
		}

		ret = mnl_cb_run(buf, n, i, mnl_socket_get_portid(mnl),
				 callback, callback_data);
		if (ret == -1) {
			WARN("    Failed at sequence %d: %s", i,
			     strerror(errno));
			return -1;
		}
	}

	return 0;
}

static struct nftnl_expr *util_create_notrack_expr()
{
	return nftnl_expr_alloc("notrack");
}

static int util_delete_nft_rule(struct nftnl_batch *batch, int seq,
				const char *table, const char *chain,
				uint64_t handle)
{
	struct nftnl_rule *r;
	struct nlmsghdr *hdr;

	if ((r = nftnl_rule_alloc()) == NULL) {
		ERROR("nftnl_rule_alloc");
		return -errno;
	}

	nftnl_rule_set_u32(r, NFTNL_RULE_FAMILY, NFPROTO_IPV4);
	nftnl_rule_set_str(r, NFTNL_RULE_TABLE, table);
	nftnl_rule_set_str(r, NFTNL_RULE_CHAIN, chain);
	nftnl_rule_set_u64(r, NFTNL_RULE_HANDLE, handle);

	hdr = nftnl_nlmsg_build_hdr(nftnl_batch_buffer(batch), NFT_MSG_DELRULE,
				    NFPROTO_IPV4, NLM_F_ACK, seq);
	nftnl_rule_nlmsg_build_payload(hdr, r);
	nftnl_batch_update(batch);

	nftnl_rule_free(r);
	return 0;
}
