#!/usr/bin/env python3
"""
Vulnerability Metadata Extractor

A specialized tool for analyzing security research repositories
and extracting structured vulnerability information.
"""

import argparse
import csv
import json
import os
import re
import sys
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple


class VulnerabilityExtractor:
    """Extracts and analyzes vulnerability metadata from security research files."""
    
    # CVE identifier pattern - matches official CVE format
    VULNERABILITY_ID_REGEX = re.compile(
        r'\bCVE-(?P<year>\d{4})-(?P<sequence>\d{4,7})\b', 
        re.IGNORECASE
    )
    
    # File types containing vulnerability information
    ANALYZED_FILE_TYPES = frozenset(['.md', '.txt', '.patch', '.rst'])
    
    # Common security research directories
    SECURITY_DOMAINS = ['kernel', 'chromium', 'android', 'exploits', 'hardware', 'network']
    
    def __init__(self, source_repository: str, destination_path: str, target_domains: Optional[List[str]] = None):
        """
        Initialize the vulnerability extractor.
        
        Args:
            source_repository: Path to security research repository
            destination_path: Where to save extracted data
            target_domains: Specific domains to analyze (optional)
        """
        self.source_repo = Path(source_repository).resolve()
        self.output_location = Path(destination_path).resolve()
        self.domains_filter = target_domains or []
        self.vulnerability_records = []
        self._analysis_stats = defaultdict(int)
        
        self._validate_and_setup()
    
    def _validate_and_setup(self) -> None:
        """Validate inputs and prepare output location."""
        if not self.source_repo.exists():
            raise FileNotFoundError(f"Source repository not accessible: {self.source_repo}")
        
        if not self.source_repo.is_dir():
            raise NotADirectoryError(f"Expected directory, got file: {self.source_repo}")
        
        # Ensure output directory exists
        self.output_location.mkdir(parents=True, exist_ok=True)
        
        print(f"Initialized extractor for: {self.source_repo}")
        print(f"Output destination: {self.output_location}")
    
    def _parse_temporal_data(self, filename: str) -> Optional[str]:
        """
        Attempt to extract temporal information from file names.
        
        Args:
            filename: Name of file to analyze
            
        Returns:
            Discovered date string or None
        """
        # Various temporal patterns found in research files
        temporal_patterns = [
            r'(?P<date>\d{4}-\d{2}-\d{2})',      # ISO format
            r'(?P<date>\d{4}_\d{2}_\d{2})',      # Underscore format
            r'(?P<date>\d{2}-\d{2}-\d{4})',      # US format
            r'(?P<date>\d{8})',                   # Compact format
        ]
        
        for pattern in temporal_patterns:
            match = re.search(pattern, filename)
            if match:
                return match.group('date')
        
        return None
    
    def _extract_temporal_markers(self, file_content: str) -> Optional[str]:
        """
        Search for temporal markers within file content.
        
        Args:
            file_content: Text content to analyze
            
        Returns:
            First discovered date or None
        """
        # Temporal marker patterns with context
        content_temporal_patterns = [
            r'(?:Discovered|Found|Reported|Published|Date):\s*(?P<date>\d{4}-\d{2}-\d{2})',
            r'(?:CVE\s+assigned|Issue\s+reported):\s*(?P<date>\d{4}-\d{2}-\d{2})',
            r'\b(?P<date>\d{4}-\d{2}-\d{2})\b',  # Standalone dates
        ]
        
        for pattern in content_temporal_patterns:
            match = re.search(pattern, file_content, re.IGNORECASE | re.MULTILINE)
            if match:
                return match.group('date')
        
        return None
    
    def _determine_security_domain(self, file_location: Path) -> str:
        """
        Classify security domain based on file path structure.
        
        Args:
            file_location: Path to analyze
            
        Returns:
            Security domain classification
        """
        try:
            relative_structure = file_location.relative_to(self.source_repo)
            path_segments = relative_structure.parts
            
            if path_segments:
                primary_domain = path_segments[0].lower()
                
                # Map common variations to standard domains
                domain_mappings = {
                    'linux': 'kernel',
                    'chrome': 'chromium',
                    'browser': 'chromium',
                    'mobile': 'android',
                    'poc': 'exploits',
                    'proof-of-concept': 'exploits',
                }
                
                return domain_mappings.get(primary_domain, primary_domain)
                
        except ValueError:
            # File not within source repository
            pass
        
        return "uncategorized"
    
    def _analyze_single_file(self, target_file: Path) -> List[Dict]:
        """
        Perform vulnerability analysis on a single file.
        
        Args:
            target_file: File to analyze
            
        Returns:
            List of vulnerability records found
        """
        discovered_vulnerabilities = []
        
        try:
            # Read with robust encoding handling
            with open(target_file, 'r', encoding='utf-8', errors='replace') as file_handle:
                content = file_handle.read()
            
            self._analysis_stats['files_processed'] += 1
            
            # Extract vulnerability identifiers
            vulnerability_matches = self.VULNERABILITY_ID_REGEX.finditer(content)
            found_cves = set()  # Track unique CVEs in this file
            
            for match in vulnerability_matches:
                cve_id = match.group(0).upper()  # Normalize to uppercase
                
                if cve_id not in found_cves:
                    found_cves.add(cve_id)
                    
                    # Extract metadata
                    security_domain = self._determine_security_domain(target_file)
                    relative_path = str(target_file.relative_to(self.source_repo))
                    
                    # Temporal analysis
                    file_date = self._parse_temporal_data(target_file.name)
                    content_date = self._extract_temporal_markers(content)
                    primary_date = file_date or content_date
                    
                    # Build vulnerability record
                    vulnerability_record = {
                        'vulnerability_id': cve_id,
                        'security_domain': security_domain,
                        'source_path': relative_path,
                        'analysis_timestamp': datetime.now().isoformat(),
                    }
                    
                    # Add temporal data if available
                    if primary_date:
                        vulnerability_record['discovered_date'] = primary_date
                    
                    # Add contextual information
                    vulnerability_record['file_size_bytes'] = target_file.stat().st_size
                    vulnerability_record['year_extracted'] = int(match.group('year'))
                    vulnerability_record['sequence_number'] = int(match.group('sequence'))
                    
                    discovered_vulnerabilities.append(vulnerability_record)
                    self._analysis_stats['vulnerabilities_found'] += 1
                    
        except (IOError, OSError) as file_error:
            print(f"File access error for {target_file}: {file_error}", file=sys.stderr)
            self._analysis_stats['files_skipped'] += 1
        except Exception as unexpected_error:
            print(f"Unexpected error processing {target_file}: {unexpected_error}", file=sys.stderr)
            self._analysis_stats['files_errored'] += 1
        
        return discovered_vulnerabilities
    
    def _build_domain_list(self) -> List[Path]:
        """
        Construct list of security domains to analyze.
        
        Returns:
            List of directory paths to process
        """
        if self.domains_filter:
            # Use specified domains
            domain_paths = []
            for domain_name in self.domains_filter:
                domain_path = self.source_repo / domain_name
                if domain_path.exists() and domain_path.is_dir():
                    domain_paths.append(domain_path)
                    print(f"Including domain: {domain_name}")
                else:
                    print(f"Warning: Domain '{domain_name}' not found", file=sys.stderr)
            return domain_paths
        else:
            # Auto-discover all security domains
            all_domains = [
                path for path in self.source_repo.iterdir() 
                if path.is_dir() and not path.name.startswith('.') and not path.name.startswith('_')
            ]
            print(f"Auto-discovered {len(all_domains)} domains")
            return all_domains
    
    def execute_analysis(self) -> None:
        """Execute comprehensive vulnerability analysis."""
        print("Initiating vulnerability analysis...")
        
        target_domains = self._build_domain_list()
        
        if not target_domains:
            print("No domains available for analysis", file=sys.stderr)
            return
        
        # Reset statistics
        self._analysis_stats.clear()
        start_time = datetime.now()
        
        for domain_path in target_domains:
            print(f"Analyzing domain: {domain_path.name}")
            
            # Recursively process all relevant files
            for discovered_file in domain_path.rglob('*'):
                if (discovered_file.is_file() and 
                    discovered_file.suffix.lower() in self.ANALYZED_FILE_TYPES):
                    
                    vulnerability_records = self._analyze_single_file(discovered_file)
                    self.vulnerability_records.extend(vulnerability_records)
        
        analysis_duration = datetime.now() - start_time
        
        print(f"Analysis completed in {analysis_duration.total_seconds():.2f} seconds")
        print(f"Processed {self._analysis_stats['files_processed']} files")
        print(f"Found {self._analysis_stats['vulnerabilities_found']} vulnerability references")
    
    def export_structured_data(self, output_filename: str = "vulnerability_data.json") -> None:
        """
        Export vulnerability data in structured JSON format.
        
        Args:
            output_filename: Name for JSON output file
        """
        output_file = self.output_location / output_filename
        
        # Add metadata to export
        export_package = {
            'metadata': {
                'extraction_timestamp': datetime.now().isoformat(),
                'source_repository': str(self.source_repo),
                'total_records': len(self.vulnerability_records),
                'analysis_statistics': dict(self._analysis_stats),
            },
            'vulnerability_records': self.vulnerability_records
        }
        
        try:
            with open(output_file, 'w', encoding='utf-8') as json_file:
                json.dump(export_package, json_file, indent=2, ensure_ascii=False, sort_keys=True)
            print(f"Structured data exported to: {output_file}")
        except IOError as export_error:
            print(f"Export failed: {export_error}", file=sys.stderr)
    
    def export_tabular_data(self, output_filename: str = "vulnerability_data.csv") -> None:
        """
        Export vulnerability data in tabular CSV format.
        
        Args:
            output_filename: Name for CSV output file
        """
        output_file = self.output_location / output_filename
        
        if not self.vulnerability_records:
            print("No vulnerability data available for tabular export", file=sys.stderr)
            return
        
        try:
            # Determine all available fields
            all_fieldnames = set()
            for record in self.vulnerability_records:
                all_fieldnames.update(record.keys())
            
            ordered_fieldnames = sorted(all_fieldnames)
            
            with open(output_file, 'w', newline='', encoding='utf-8') as csv_file:
                csv_writer = csv.DictWriter(csv_file, fieldnames=ordered_fieldnames)
                csv_writer.writeheader()
                csv_writer.writerows(self.vulnerability_records)
            
            print(f"Tabular data exported to: {output_file}")
        except IOError as export_error:
            print(f"Tabular export failed: {export_error}", file=sys.stderr)
    
    def generate_analytics_summary(self) -> Dict:
        """
        Generate comprehensive analytics summary.
        
        Returns:
            Dictionary containing analysis metrics
        """
        if not self.vulnerability_records:
            return {'status': 'no_data'}
        
        # Domain distribution analysis
        domain_distribution = Counter(record['security_domain'] for record in self.vulnerability_records)
        
        # Temporal analysis
        yearly_distribution = Counter()
        for record in self.vulnerability_records:
            if 'year_extracted' in record:
                yearly_distribution[record['year_extracted']] += 1
        
        # Unique vulnerability tracking
        unique_vulnerabilities = set(record['vulnerability_id'] for record in self.vulnerability_records)
        
        analytics_summary = {
            'analysis_timestamp': datetime.now().isoformat(),
            'total_vulnerability_references': len(self.vulnerability_records),
            'unique_vulnerabilities': len(unique_vulnerabilities),
            'domains_analyzed': len(domain_distribution),
            'domain_distribution': dict(domain_distribution),
            'yearly_distribution': dict(yearly_distribution),
            'processing_statistics': dict(self._analysis_stats),
            'coverage_years': list(range(min(yearly_distribution.keys(), default=0), 
                                       max(yearly_distribution.keys(), default=0) + 1)) if yearly_distribution else []
        }
        
        return analytics_summary
    
    def export_visual_report(self, output_filename: str = "vulnerability_analysis_report.html") -> None:
        """Generate comprehensive visual analysis report."""
        output_file = self.output_location / output_filename
        analytics = self.generate_analytics_summary()
        
        if analytics.get('status') == 'no_data':
            print("Insufficient data for visual report generation", file=sys.stderr)
            return
        
        # Build modern HTML report with unique styling
        report_html = self._create_visual_report_template(analytics)
        
        try:
            with open(output_file, 'w', encoding='utf-8') as html_file:
                html_file.write(report_html)
            print(f"Visual report generated: {output_file}")
        except IOError as export_error:
            print(f"Visual report generation failed: {export_error}", file=sys.stderr)
    
    def _create_visual_report_template(self, analytics: Dict) -> str:
        """Create the HTML template for visual reports."""
        return f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vulnerability Analysis Dashboard</title>
    <style>
        * {{ box-sizing: border-box; margin: 0; padding: 0; }}
        body {{ 
            font-family: 'Segoe UI', system-ui, sans-serif; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh; padding: 20px; color: #333;
        }}
        .dashboard {{ 
            max-width: 1200px; margin: 0 auto; background: white; 
            border-radius: 15px; box-shadow: 0 20px 40px rgba(0,0,0,0.1); 
            overflow: hidden;
        }}
        .header {{ 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            color: white; padding: 40px; text-align: center; 
        }}
        .header h1 {{ font-size: 2.5em; margin-bottom: 10px; }}
        .content {{ padding: 40px; }}
        .metrics-container {{ 
            display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); 
            gap: 20px; margin-bottom: 40px; 
        }}
        .metric-box {{ 
            background: #f8f9fa; border-radius: 10px; padding: 20px; 
            text-align: center; border-left: 4px solid #667eea;
        }}
        .metric-value {{ font-size: 2.5em; font-weight: bold; color: #667eea; }}
        .metric-description {{ color: #666; font-size: 0.9em; text-transform: uppercase; }}
        .analysis-section {{ margin-bottom: 40px; }}
        .analysis-section h2 {{ 
            color: #333; margin-bottom: 20px; padding-bottom: 10px; 
            border-bottom: 2px solid #667eea; 
        }}
        .results-table {{ 
            width: 100%; border-collapse: collapse; margin-top: 20px; 
            background: white; border-radius: 8px; overflow: hidden;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }}
        .results-table th {{ 
            background: #667eea; color: white; padding: 15px; 
            text-align: left; font-weight: 600; 
        }}
        .results-table td {{ padding: 15px; border-bottom: 1px solid #eee; }}
        .results-table tr:hover {{ background: #f8f9fa; }}
        .footer {{ 
            background: #f8f9fa; padding: 20px; text-align: center; 
            color: #666; font-size: 0.9em; 
        }}
    </style>
</head>
<body>
    <div class="dashboard">
        <div class="header">
            <h1>🔍 Vulnerability Analysis Dashboard</h1>
            <p>Generated: {analytics['analysis_timestamp']}</p>
        </div>
        
        <div class="content">
            <div class="metrics-container">
                <div class="metric-box">
                    <div class="metric-value">{analytics['total_vulnerability_references']}</div>
                    <div class="metric-description">Total References</div>
                </div>
                <div class="metric-box">
                    <div class="metric-value">{analytics['unique_vulnerabilities']}</div>
                    <div class="metric-description">Unique CVEs</div>
                </div>
                <div class="metric-box">
                    <div class="metric-value">{analytics['domains_analyzed']}</div>
                    <div class="metric-description">Security Domains</div>
                </div>
                <div class="metric-box">
                    <div class="metric-value">{len(analytics['coverage_years'])}</div>
                    <div class="metric-description">Year Coverage</div>
                </div>
            </div>
            
            <div class="analysis-section">
                <h2>📊 Domain Distribution</h2>
                <table class="results-table">
                    <thead>
                        <tr>
                            <th>Security Domain</th>
                            <th>Count</th>
                            <th>Percentage</th>
                        </tr>
                    </thead>
                    <tbody>
{self._generate_domain_rows(analytics)}
                    </tbody>
                </table>
            </div>
        </div>
        
        <div class="footer">
            <p>🛡️ Vulnerability Metadata Extractor - Security Research Analysis</p>
        </div>
    </div>
</body>
</html>"""
    
    def _generate_domain_rows(self, analytics: Dict) -> str:
        """Generate table rows for domain distribution."""
        rows = []
        total_refs = analytics['total_vulnerability_references']
        
        for domain, count in sorted(analytics['domain_distribution'].items(), 
                                  key=lambda x: x[1], reverse=True):
            percentage = (count / total_refs * 100) if total_refs > 0 else 0
            rows.append(f"""
                        <tr>
                            <td>{domain}</td>
                            <td>{count}</td>
                            <td>{percentage:.1f}%</td>
                        </tr>""")
        
        return ''.join(rows)


def create_command_interface():
    """Create and configure command-line interface."""
    interface = argparse.ArgumentParser(
        prog='vulnerability-extractor',
        description='Extract and analyze vulnerability metadata from security research repositories',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Usage Examples:
  %(prog)s --source /path/to/security-research --output ./analysis
  %(prog)s --source ./research --output ./results --domains kernel android --visual-report
  %(prog)s --source ./repo --output ./data --json-name security_vulns.json --csv-name security_vulns.csv
        """
    )
    
    interface.add_argument(
        '--source',
        dest='source_repository',
        required=True,
        metavar='PATH',
        help='Path to security research repository for analysis'
    )
    
    interface.add_argument(
        '--output',
        dest='output_directory',
        required=True,
        metavar='PATH',
        help='Directory for saving analysis results'
    )
    
    interface.add_argument(
        '--domains',
        dest='target_domains',
        nargs='*',
        metavar='DOMAIN',
        help='Specific security domains to analyze (e.g., kernel android chromium)'
    )
    
    interface.add_argument(
        '--visual-report',
        dest='generate_visual_report',
        action='store_true',
        help='Generate comprehensive HTML visual report'
    )
    
    interface.add_argument(
        '--json-name',
        dest='json_filename',
        default='vulnerability_data.json',
        metavar='FILENAME',
        help='Custom name for JSON output file'
    )
    
    interface.add_argument(
        '--csv-name',
        dest='csv_filename',
        default='vulnerability_data.csv',
        metavar='FILENAME',
        help='Custom name for CSV output file'
    )
    
    interface.add_argument(
        '--verbose',
        dest='verbose_mode',
        action='store_true',
        help='Enable detailed progress output'
    )
    
    return interface


def main():
    """Main application entry point."""
    command_interface = create_command_interface()
    arguments = command_interface.parse_args()
    
    if arguments.verbose_mode:
        print("🔍 Vulnerability Metadata Extractor")
        print("=" * 50)
    
    try:
        # Initialize extractor
        extractor = VulnerabilityExtractor(
            source_repository=arguments.source_repository,
            destination_path=arguments.output_directory,
            target_domains=arguments.target_domains
        )
        
        # Execute analysis
        extractor.execute_analysis()
        
        # Export data in multiple formats
        extractor.export_structured_data(arguments.json_filename)
        extractor.export_tabular_data(arguments.csv_filename)
        
        # Generate visual report if requested
        if arguments.generate_visual_report:
            extractor.export_visual_report()
        
        # Display summary analytics
        analytics = extractor.generate_analytics_summary()
        if analytics.get('status') != 'no_data':
            print("\n" + "=" * 50)
            print("📊 ANALYSIS SUMMARY")
            print("=" * 50)
            print(f"Total vulnerability references: {analytics['total_vulnerability_references']}")
            print(f"Unique vulnerabilities: {analytics['unique_vulnerabilities']}")
            print(f"Security domains analyzed: {analytics['domains_analyzed']}")
            
            if arguments.verbose_mode:
                print("\nTop security domains:")
                domain_items = sorted(analytics['domain_distribution'].items(), 
                                    key=lambda x: x[1], reverse=True)
                for domain, count in domain_items[:5]:
                    print(f"  • {domain}: {count} references")
        
    except FileNotFoundError as missing_file:
        print(f"❌ File system error: {missing_file}", file=sys.stderr)
        sys.exit(1)
    except NotADirectoryError as directory_error:
        print(f"❌ Directory error: {directory_error}", file=sys.stderr)
        sys.exit(1)
    except KeyboardInterrupt:
        print("\n⚠️ Analysis interrupted by user", file=sys.stderr)
        sys.exit(130)
    except Exception as unexpected_error:
        print(f"❌ Unexpected error during analysis: {unexpected_error}", file=sys.stderr)
        if arguments.verbose_mode:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 